{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9597474348855566,
  "eval_steps": 2500,
  "global_step": 15000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.001973164956590371,
      "grad_norm": 4.065863609313965,
      "learning_rate": 1.2e-05,
      "loss": 8.5733,
      "step": 10
    },
    {
      "epoch": 0.003946329913180742,
      "grad_norm": 19.026479721069336,
      "learning_rate": 3.2000000000000005e-05,
      "loss": 9.3493,
      "step": 20
    },
    {
      "epoch": 0.005919494869771113,
      "grad_norm": 20.191579818725586,
      "learning_rate": 5.2000000000000004e-05,
      "loss": 7.2961,
      "step": 30
    },
    {
      "epoch": 0.007892659826361484,
      "grad_norm": 22.61883544921875,
      "learning_rate": 7.2e-05,
      "loss": 3.6746,
      "step": 40
    },
    {
      "epoch": 0.009865824782951855,
      "grad_norm": 0.6877894401550293,
      "learning_rate": 9.200000000000001e-05,
      "loss": 0.5356,
      "step": 50
    },
    {
      "epoch": 0.011838989739542225,
      "grad_norm": 1.2964304685592651,
      "learning_rate": 9.99604064933351e-05,
      "loss": 0.0602,
      "step": 60
    },
    {
      "epoch": 0.013812154696132596,
      "grad_norm": 0.19653260707855225,
      "learning_rate": 9.989441731556026e-05,
      "loss": 0.0476,
      "step": 70
    },
    {
      "epoch": 0.01578531965272297,
      "grad_norm": 0.2958870530128479,
      "learning_rate": 9.982842813778542e-05,
      "loss": 0.0419,
      "step": 80
    },
    {
      "epoch": 0.017758484609313337,
      "grad_norm": 0.4015800654888153,
      "learning_rate": 9.976243896001056e-05,
      "loss": 0.0475,
      "step": 90
    },
    {
      "epoch": 0.01973164956590371,
      "grad_norm": 0.14008447527885437,
      "learning_rate": 9.969644978223572e-05,
      "loss": 0.0375,
      "step": 100
    },
    {
      "epoch": 0.021704814522494082,
      "grad_norm": 0.1713663786649704,
      "learning_rate": 9.963046060446087e-05,
      "loss": 0.0324,
      "step": 110
    },
    {
      "epoch": 0.02367797947908445,
      "grad_norm": 0.23615480959415436,
      "learning_rate": 9.956447142668603e-05,
      "loss": 0.0354,
      "step": 120
    },
    {
      "epoch": 0.025651144435674823,
      "grad_norm": 0.40411773324012756,
      "learning_rate": 9.949848224891119e-05,
      "loss": 0.0433,
      "step": 130
    },
    {
      "epoch": 0.027624309392265192,
      "grad_norm": 0.25219351053237915,
      "learning_rate": 9.943249307113634e-05,
      "loss": 0.0337,
      "step": 140
    },
    {
      "epoch": 0.029597474348855565,
      "grad_norm": 0.17559149861335754,
      "learning_rate": 9.93665038933615e-05,
      "loss": 0.0334,
      "step": 150
    },
    {
      "epoch": 0.03157063930544594,
      "grad_norm": 0.19418179988861084,
      "learning_rate": 9.930051471558664e-05,
      "loss": 0.0365,
      "step": 160
    },
    {
      "epoch": 0.033543804262036306,
      "grad_norm": 0.1635347455739975,
      "learning_rate": 9.92345255378118e-05,
      "loss": 0.0434,
      "step": 170
    },
    {
      "epoch": 0.035516969218626675,
      "grad_norm": 0.1518578976392746,
      "learning_rate": 9.916853636003696e-05,
      "loss": 0.0303,
      "step": 180
    },
    {
      "epoch": 0.03749013417521705,
      "grad_norm": 0.3194509744644165,
      "learning_rate": 9.910254718226212e-05,
      "loss": 0.0334,
      "step": 190
    },
    {
      "epoch": 0.03946329913180742,
      "grad_norm": 0.15588369965553284,
      "learning_rate": 9.903655800448727e-05,
      "loss": 0.0312,
      "step": 200
    },
    {
      "epoch": 0.04143646408839779,
      "grad_norm": 0.17036013305187225,
      "learning_rate": 9.897056882671243e-05,
      "loss": 0.0303,
      "step": 210
    },
    {
      "epoch": 0.043409629044988164,
      "grad_norm": 0.16290807723999023,
      "learning_rate": 9.890457964893757e-05,
      "loss": 0.037,
      "step": 220
    },
    {
      "epoch": 0.04538279400157853,
      "grad_norm": 0.3662589192390442,
      "learning_rate": 9.883859047116273e-05,
      "loss": 0.0308,
      "step": 230
    },
    {
      "epoch": 0.0473559589581689,
      "grad_norm": 0.25107958912849426,
      "learning_rate": 9.877260129338789e-05,
      "loss": 0.0322,
      "step": 240
    },
    {
      "epoch": 0.04932912391475927,
      "grad_norm": 0.12956728041172028,
      "learning_rate": 9.870661211561304e-05,
      "loss": 0.029,
      "step": 250
    },
    {
      "epoch": 0.05130228887134965,
      "grad_norm": 0.1515127420425415,
      "learning_rate": 9.86406229378382e-05,
      "loss": 0.0306,
      "step": 260
    },
    {
      "epoch": 0.053275453827940016,
      "grad_norm": 0.08909157663583755,
      "learning_rate": 9.857463376006334e-05,
      "loss": 0.0273,
      "step": 270
    },
    {
      "epoch": 0.055248618784530384,
      "grad_norm": 0.14489609003067017,
      "learning_rate": 9.850864458228852e-05,
      "loss": 0.0301,
      "step": 280
    },
    {
      "epoch": 0.05722178374112076,
      "grad_norm": 0.15205712616443634,
      "learning_rate": 9.844265540451366e-05,
      "loss": 0.0288,
      "step": 290
    },
    {
      "epoch": 0.05919494869771113,
      "grad_norm": 0.2631711959838867,
      "learning_rate": 9.837666622673882e-05,
      "loss": 0.0388,
      "step": 300
    },
    {
      "epoch": 0.0611681136543015,
      "grad_norm": 0.22725822031497955,
      "learning_rate": 9.831067704896397e-05,
      "loss": 0.0283,
      "step": 310
    },
    {
      "epoch": 0.06314127861089187,
      "grad_norm": 0.25227412581443787,
      "learning_rate": 9.824468787118913e-05,
      "loss": 0.0346,
      "step": 320
    },
    {
      "epoch": 0.06511444356748224,
      "grad_norm": 0.33630478382110596,
      "learning_rate": 9.817869869341429e-05,
      "loss": 0.0323,
      "step": 330
    },
    {
      "epoch": 0.06708760852407261,
      "grad_norm": 0.3153383135795593,
      "learning_rate": 9.811270951563945e-05,
      "loss": 0.0285,
      "step": 340
    },
    {
      "epoch": 0.06906077348066299,
      "grad_norm": 0.2871260941028595,
      "learning_rate": 9.80467203378646e-05,
      "loss": 0.032,
      "step": 350
    },
    {
      "epoch": 0.07103393843725335,
      "grad_norm": 0.4306485652923584,
      "learning_rate": 9.798073116008974e-05,
      "loss": 0.031,
      "step": 360
    },
    {
      "epoch": 0.07300710339384373,
      "grad_norm": 0.35715290904045105,
      "learning_rate": 9.79147419823149e-05,
      "loss": 0.0365,
      "step": 370
    },
    {
      "epoch": 0.0749802683504341,
      "grad_norm": 0.3812767267227173,
      "learning_rate": 9.784875280454006e-05,
      "loss": 0.0271,
      "step": 380
    },
    {
      "epoch": 0.07695343330702446,
      "grad_norm": 0.26134130358695984,
      "learning_rate": 9.778276362676522e-05,
      "loss": 0.0268,
      "step": 390
    },
    {
      "epoch": 0.07892659826361484,
      "grad_norm": 0.4133641719818115,
      "learning_rate": 9.771677444899037e-05,
      "loss": 0.0214,
      "step": 400
    },
    {
      "epoch": 0.08089976322020521,
      "grad_norm": 0.35518789291381836,
      "learning_rate": 9.765078527121553e-05,
      "loss": 0.0348,
      "step": 410
    },
    {
      "epoch": 0.08287292817679558,
      "grad_norm": 0.23859168589115143,
      "learning_rate": 9.758479609344067e-05,
      "loss": 0.0225,
      "step": 420
    },
    {
      "epoch": 0.08484609313338595,
      "grad_norm": 0.1274799108505249,
      "learning_rate": 9.751880691566583e-05,
      "loss": 0.0322,
      "step": 430
    },
    {
      "epoch": 0.08681925808997633,
      "grad_norm": 0.26633569598197937,
      "learning_rate": 9.745281773789099e-05,
      "loss": 0.0325,
      "step": 440
    },
    {
      "epoch": 0.08879242304656669,
      "grad_norm": 0.16241362690925598,
      "learning_rate": 9.738682856011615e-05,
      "loss": 0.0189,
      "step": 450
    },
    {
      "epoch": 0.09076558800315707,
      "grad_norm": 0.2809752821922302,
      "learning_rate": 9.73208393823413e-05,
      "loss": 0.0351,
      "step": 460
    },
    {
      "epoch": 0.09273875295974743,
      "grad_norm": 0.1610521823167801,
      "learning_rate": 9.725485020456646e-05,
      "loss": 0.0272,
      "step": 470
    },
    {
      "epoch": 0.0947119179163378,
      "grad_norm": 0.2268197238445282,
      "learning_rate": 9.71888610267916e-05,
      "loss": 0.0332,
      "step": 480
    },
    {
      "epoch": 0.09668508287292818,
      "grad_norm": 0.4001970589160919,
      "learning_rate": 9.712287184901676e-05,
      "loss": 0.0391,
      "step": 490
    },
    {
      "epoch": 0.09865824782951854,
      "grad_norm": 0.2915096580982208,
      "learning_rate": 9.705688267124192e-05,
      "loss": 0.0308,
      "step": 500
    },
    {
      "epoch": 0.10063141278610892,
      "grad_norm": 0.22438327968120575,
      "learning_rate": 9.699089349346707e-05,
      "loss": 0.0303,
      "step": 510
    },
    {
      "epoch": 0.1026045777426993,
      "grad_norm": 0.37904778122901917,
      "learning_rate": 9.692490431569223e-05,
      "loss": 0.0249,
      "step": 520
    },
    {
      "epoch": 0.10457774269928966,
      "grad_norm": 0.2555304169654846,
      "learning_rate": 9.685891513791738e-05,
      "loss": 0.0347,
      "step": 530
    },
    {
      "epoch": 0.10655090765588003,
      "grad_norm": 0.38144996762275696,
      "learning_rate": 9.679292596014255e-05,
      "loss": 0.0288,
      "step": 540
    },
    {
      "epoch": 0.1085240726124704,
      "grad_norm": 0.20993950963020325,
      "learning_rate": 9.67269367823677e-05,
      "loss": 0.031,
      "step": 550
    },
    {
      "epoch": 0.11049723756906077,
      "grad_norm": 0.23715180158615112,
      "learning_rate": 9.666094760459286e-05,
      "loss": 0.0229,
      "step": 560
    },
    {
      "epoch": 0.11247040252565114,
      "grad_norm": 0.21417081356048584,
      "learning_rate": 9.6594958426818e-05,
      "loss": 0.0238,
      "step": 570
    },
    {
      "epoch": 0.11444356748224152,
      "grad_norm": 0.15197651088237762,
      "learning_rate": 9.652896924904316e-05,
      "loss": 0.0178,
      "step": 580
    },
    {
      "epoch": 0.11641673243883188,
      "grad_norm": 0.1929442584514618,
      "learning_rate": 9.646298007126832e-05,
      "loss": 0.0318,
      "step": 590
    },
    {
      "epoch": 0.11838989739542226,
      "grad_norm": 0.41761666536331177,
      "learning_rate": 9.639699089349347e-05,
      "loss": 0.0274,
      "step": 600
    },
    {
      "epoch": 0.12036306235201263,
      "grad_norm": 0.11619316786527634,
      "learning_rate": 9.633100171571863e-05,
      "loss": 0.0248,
      "step": 610
    },
    {
      "epoch": 0.122336227308603,
      "grad_norm": 0.22251170873641968,
      "learning_rate": 9.626501253794377e-05,
      "loss": 0.027,
      "step": 620
    },
    {
      "epoch": 0.12430939226519337,
      "grad_norm": 0.09499253332614899,
      "learning_rate": 9.619902336016893e-05,
      "loss": 0.0257,
      "step": 630
    },
    {
      "epoch": 0.12628255722178375,
      "grad_norm": 0.1664445549249649,
      "learning_rate": 9.61330341823941e-05,
      "loss": 0.027,
      "step": 640
    },
    {
      "epoch": 0.1282557221783741,
      "grad_norm": 0.24367094039916992,
      "learning_rate": 9.606704500461925e-05,
      "loss": 0.0286,
      "step": 650
    },
    {
      "epoch": 0.13022888713496447,
      "grad_norm": 0.37860047817230225,
      "learning_rate": 9.60010558268444e-05,
      "loss": 0.0383,
      "step": 660
    },
    {
      "epoch": 0.13220205209155486,
      "grad_norm": 0.27808237075805664,
      "learning_rate": 9.593506664906956e-05,
      "loss": 0.0302,
      "step": 670
    },
    {
      "epoch": 0.13417521704814522,
      "grad_norm": 0.5030608177185059,
      "learning_rate": 9.58690774712947e-05,
      "loss": 0.032,
      "step": 680
    },
    {
      "epoch": 0.13614838200473559,
      "grad_norm": 0.2692074179649353,
      "learning_rate": 9.580308829351987e-05,
      "loss": 0.0212,
      "step": 690
    },
    {
      "epoch": 0.13812154696132597,
      "grad_norm": 0.20047977566719055,
      "learning_rate": 9.573709911574503e-05,
      "loss": 0.0234,
      "step": 700
    },
    {
      "epoch": 0.14009471191791634,
      "grad_norm": 0.31775280833244324,
      "learning_rate": 9.567110993797019e-05,
      "loss": 0.0273,
      "step": 710
    },
    {
      "epoch": 0.1420678768745067,
      "grad_norm": 0.3303787410259247,
      "learning_rate": 9.560512076019533e-05,
      "loss": 0.0314,
      "step": 720
    },
    {
      "epoch": 0.1440410418310971,
      "grad_norm": 0.12664154171943665,
      "learning_rate": 9.553913158242048e-05,
      "loss": 0.0239,
      "step": 730
    },
    {
      "epoch": 0.14601420678768745,
      "grad_norm": 0.47534018754959106,
      "learning_rate": 9.547314240464564e-05,
      "loss": 0.024,
      "step": 740
    },
    {
      "epoch": 0.1479873717442778,
      "grad_norm": 0.32985588908195496,
      "learning_rate": 9.54071532268708e-05,
      "loss": 0.0198,
      "step": 750
    },
    {
      "epoch": 0.1499605367008682,
      "grad_norm": 0.24753154814243317,
      "learning_rate": 9.534116404909596e-05,
      "loss": 0.0266,
      "step": 760
    },
    {
      "epoch": 0.15193370165745856,
      "grad_norm": 0.12777896225452423,
      "learning_rate": 9.52751748713211e-05,
      "loss": 0.0234,
      "step": 770
    },
    {
      "epoch": 0.15390686661404893,
      "grad_norm": 0.33154746890068054,
      "learning_rate": 9.520918569354626e-05,
      "loss": 0.0274,
      "step": 780
    },
    {
      "epoch": 0.15588003157063932,
      "grad_norm": 0.4101495146751404,
      "learning_rate": 9.514319651577141e-05,
      "loss": 0.0301,
      "step": 790
    },
    {
      "epoch": 0.15785319652722968,
      "grad_norm": 0.335781455039978,
      "learning_rate": 9.507720733799658e-05,
      "loss": 0.0256,
      "step": 800
    },
    {
      "epoch": 0.15982636148382004,
      "grad_norm": 0.19609051942825317,
      "learning_rate": 9.501121816022173e-05,
      "loss": 0.0249,
      "step": 810
    },
    {
      "epoch": 0.16179952644041043,
      "grad_norm": 0.0322728231549263,
      "learning_rate": 9.494522898244689e-05,
      "loss": 0.025,
      "step": 820
    },
    {
      "epoch": 0.1637726913970008,
      "grad_norm": 0.3582468628883362,
      "learning_rate": 9.487923980467203e-05,
      "loss": 0.0212,
      "step": 830
    },
    {
      "epoch": 0.16574585635359115,
      "grad_norm": 0.1436515748500824,
      "learning_rate": 9.48132506268972e-05,
      "loss": 0.0272,
      "step": 840
    },
    {
      "epoch": 0.16771902131018154,
      "grad_norm": 0.21535547077655792,
      "learning_rate": 9.474726144912235e-05,
      "loss": 0.0274,
      "step": 850
    },
    {
      "epoch": 0.1696921862667719,
      "grad_norm": 0.4305109977722168,
      "learning_rate": 9.46812722713475e-05,
      "loss": 0.0236,
      "step": 860
    },
    {
      "epoch": 0.17166535122336227,
      "grad_norm": 0.30902451276779175,
      "learning_rate": 9.461528309357266e-05,
      "loss": 0.0216,
      "step": 870
    },
    {
      "epoch": 0.17363851617995266,
      "grad_norm": 0.2684849500656128,
      "learning_rate": 9.45492939157978e-05,
      "loss": 0.0284,
      "step": 880
    },
    {
      "epoch": 0.17561168113654302,
      "grad_norm": 0.33269092440605164,
      "learning_rate": 9.448330473802297e-05,
      "loss": 0.0262,
      "step": 890
    },
    {
      "epoch": 0.17758484609313338,
      "grad_norm": 0.26289913058280945,
      "learning_rate": 9.441731556024813e-05,
      "loss": 0.0267,
      "step": 900
    },
    {
      "epoch": 0.17955801104972377,
      "grad_norm": 0.25735533237457275,
      "learning_rate": 9.435132638247329e-05,
      "loss": 0.0195,
      "step": 910
    },
    {
      "epoch": 0.18153117600631413,
      "grad_norm": 0.26094165444374084,
      "learning_rate": 9.428533720469843e-05,
      "loss": 0.0264,
      "step": 920
    },
    {
      "epoch": 0.1835043409629045,
      "grad_norm": 0.23225848376750946,
      "learning_rate": 9.421934802692359e-05,
      "loss": 0.022,
      "step": 930
    },
    {
      "epoch": 0.18547750591949486,
      "grad_norm": 0.13653703033924103,
      "learning_rate": 9.415335884914874e-05,
      "loss": 0.0141,
      "step": 940
    },
    {
      "epoch": 0.18745067087608525,
      "grad_norm": 0.11131361871957779,
      "learning_rate": 9.40873696713739e-05,
      "loss": 0.0175,
      "step": 950
    },
    {
      "epoch": 0.1894238358326756,
      "grad_norm": 0.45423778891563416,
      "learning_rate": 9.402138049359906e-05,
      "loss": 0.0231,
      "step": 960
    },
    {
      "epoch": 0.19139700078926597,
      "grad_norm": 0.21682612597942352,
      "learning_rate": 9.39553913158242e-05,
      "loss": 0.0193,
      "step": 970
    },
    {
      "epoch": 0.19337016574585636,
      "grad_norm": 0.17798598110675812,
      "learning_rate": 9.388940213804936e-05,
      "loss": 0.0258,
      "step": 980
    },
    {
      "epoch": 0.19534333070244672,
      "grad_norm": 0.07925529032945633,
      "learning_rate": 9.382341296027451e-05,
      "loss": 0.01,
      "step": 990
    },
    {
      "epoch": 0.19731649565903708,
      "grad_norm": 0.17520853877067566,
      "learning_rate": 9.375742378249967e-05,
      "loss": 0.0226,
      "step": 1000
    },
    {
      "epoch": 0.19928966061562747,
      "grad_norm": 0.25525087118148804,
      "learning_rate": 9.369143460472483e-05,
      "loss": 0.0178,
      "step": 1010
    },
    {
      "epoch": 0.20126282557221783,
      "grad_norm": 0.2605873942375183,
      "learning_rate": 9.362544542694999e-05,
      "loss": 0.0224,
      "step": 1020
    },
    {
      "epoch": 0.2032359905288082,
      "grad_norm": 0.1589055210351944,
      "learning_rate": 9.355945624917514e-05,
      "loss": 0.0282,
      "step": 1030
    },
    {
      "epoch": 0.2052091554853986,
      "grad_norm": 0.2545035183429718,
      "learning_rate": 9.34934670714003e-05,
      "loss": 0.0343,
      "step": 1040
    },
    {
      "epoch": 0.20718232044198895,
      "grad_norm": 0.13214002549648285,
      "learning_rate": 9.342747789362545e-05,
      "loss": 0.0217,
      "step": 1050
    },
    {
      "epoch": 0.2091554853985793,
      "grad_norm": 0.478635311126709,
      "learning_rate": 9.336148871585061e-05,
      "loss": 0.0278,
      "step": 1060
    },
    {
      "epoch": 0.2111286503551697,
      "grad_norm": 0.24505625665187836,
      "learning_rate": 9.329549953807576e-05,
      "loss": 0.0302,
      "step": 1070
    },
    {
      "epoch": 0.21310181531176006,
      "grad_norm": 0.6091981530189514,
      "learning_rate": 9.322951036030092e-05,
      "loss": 0.0263,
      "step": 1080
    },
    {
      "epoch": 0.21507498026835042,
      "grad_norm": 0.3161824345588684,
      "learning_rate": 9.316352118252607e-05,
      "loss": 0.0257,
      "step": 1090
    },
    {
      "epoch": 0.2170481452249408,
      "grad_norm": 0.24152427911758423,
      "learning_rate": 9.309753200475123e-05,
      "loss": 0.019,
      "step": 1100
    },
    {
      "epoch": 0.21902131018153118,
      "grad_norm": 0.29823237657546997,
      "learning_rate": 9.303154282697639e-05,
      "loss": 0.0182,
      "step": 1110
    },
    {
      "epoch": 0.22099447513812154,
      "grad_norm": 0.24467706680297852,
      "learning_rate": 9.296555364920153e-05,
      "loss": 0.0242,
      "step": 1120
    },
    {
      "epoch": 0.22296764009471193,
      "grad_norm": 0.1165204644203186,
      "learning_rate": 9.289956447142669e-05,
      "loss": 0.0272,
      "step": 1130
    },
    {
      "epoch": 0.2249408050513023,
      "grad_norm": 0.16341714560985565,
      "learning_rate": 9.283357529365184e-05,
      "loss": 0.0218,
      "step": 1140
    },
    {
      "epoch": 0.22691397000789265,
      "grad_norm": 0.30358219146728516,
      "learning_rate": 9.2767586115877e-05,
      "loss": 0.0285,
      "step": 1150
    },
    {
      "epoch": 0.22888713496448304,
      "grad_norm": 0.17787054181098938,
      "learning_rate": 9.270159693810216e-05,
      "loss": 0.0246,
      "step": 1160
    },
    {
      "epoch": 0.2308602999210734,
      "grad_norm": 0.3796854317188263,
      "learning_rate": 9.263560776032732e-05,
      "loss": 0.0322,
      "step": 1170
    },
    {
      "epoch": 0.23283346487766376,
      "grad_norm": 0.3885878920555115,
      "learning_rate": 9.256961858255246e-05,
      "loss": 0.0306,
      "step": 1180
    },
    {
      "epoch": 0.23480662983425415,
      "grad_norm": 0.29953938722610474,
      "learning_rate": 9.250362940477762e-05,
      "loss": 0.0165,
      "step": 1190
    },
    {
      "epoch": 0.23677979479084452,
      "grad_norm": 0.8077224493026733,
      "learning_rate": 9.243764022700277e-05,
      "loss": 0.0263,
      "step": 1200
    },
    {
      "epoch": 0.23875295974743488,
      "grad_norm": 0.2731541693210602,
      "learning_rate": 9.237165104922793e-05,
      "loss": 0.0217,
      "step": 1210
    },
    {
      "epoch": 0.24072612470402527,
      "grad_norm": 0.14695002138614655,
      "learning_rate": 9.230566187145309e-05,
      "loss": 0.0215,
      "step": 1220
    },
    {
      "epoch": 0.24269928966061563,
      "grad_norm": 0.22118249535560608,
      "learning_rate": 9.223967269367824e-05,
      "loss": 0.0158,
      "step": 1230
    },
    {
      "epoch": 0.244672454617206,
      "grad_norm": 0.36121729016304016,
      "learning_rate": 9.21736835159034e-05,
      "loss": 0.0263,
      "step": 1240
    },
    {
      "epoch": 0.24664561957379638,
      "grad_norm": 0.18740828335285187,
      "learning_rate": 9.210769433812854e-05,
      "loss": 0.0316,
      "step": 1250
    },
    {
      "epoch": 0.24861878453038674,
      "grad_norm": 0.12381169945001602,
      "learning_rate": 9.204170516035372e-05,
      "loss": 0.0198,
      "step": 1260
    },
    {
      "epoch": 0.2505919494869771,
      "grad_norm": 0.134194478392601,
      "learning_rate": 9.197571598257886e-05,
      "loss": 0.0188,
      "step": 1270
    },
    {
      "epoch": 0.2525651144435675,
      "grad_norm": 0.07434512674808502,
      "learning_rate": 9.190972680480402e-05,
      "loss": 0.0174,
      "step": 1280
    },
    {
      "epoch": 0.25453827940015783,
      "grad_norm": 0.18430760502815247,
      "learning_rate": 9.184373762702917e-05,
      "loss": 0.0175,
      "step": 1290
    },
    {
      "epoch": 0.2565114443567482,
      "grad_norm": 0.2655588686466217,
      "learning_rate": 9.177774844925433e-05,
      "loss": 0.027,
      "step": 1300
    },
    {
      "epoch": 0.2584846093133386,
      "grad_norm": 0.19885040819644928,
      "learning_rate": 9.171175927147949e-05,
      "loss": 0.0176,
      "step": 1310
    },
    {
      "epoch": 0.26045777426992894,
      "grad_norm": 0.3365997076034546,
      "learning_rate": 9.164577009370465e-05,
      "loss": 0.0286,
      "step": 1320
    },
    {
      "epoch": 0.26243093922651933,
      "grad_norm": 0.271342396736145,
      "learning_rate": 9.157978091592979e-05,
      "loss": 0.0309,
      "step": 1330
    },
    {
      "epoch": 0.2644041041831097,
      "grad_norm": 0.28023529052734375,
      "learning_rate": 9.151379173815494e-05,
      "loss": 0.0192,
      "step": 1340
    },
    {
      "epoch": 0.26637726913970006,
      "grad_norm": 0.13775014877319336,
      "learning_rate": 9.14478025603801e-05,
      "loss": 0.0239,
      "step": 1350
    },
    {
      "epoch": 0.26835043409629045,
      "grad_norm": 0.14666390419006348,
      "learning_rate": 9.138181338260526e-05,
      "loss": 0.0223,
      "step": 1360
    },
    {
      "epoch": 0.27032359905288084,
      "grad_norm": 0.36649981141090393,
      "learning_rate": 9.131582420483042e-05,
      "loss": 0.0328,
      "step": 1370
    },
    {
      "epoch": 0.27229676400947117,
      "grad_norm": 0.3963947892189026,
      "learning_rate": 9.124983502705556e-05,
      "loss": 0.025,
      "step": 1380
    },
    {
      "epoch": 0.27426992896606156,
      "grad_norm": 0.20856894552707672,
      "learning_rate": 9.118384584928072e-05,
      "loss": 0.0211,
      "step": 1390
    },
    {
      "epoch": 0.27624309392265195,
      "grad_norm": 0.3312484622001648,
      "learning_rate": 9.111785667150587e-05,
      "loss": 0.022,
      "step": 1400
    },
    {
      "epoch": 0.2782162588792423,
      "grad_norm": 0.25784024596214294,
      "learning_rate": 9.105186749373103e-05,
      "loss": 0.0282,
      "step": 1410
    },
    {
      "epoch": 0.2801894238358327,
      "grad_norm": 0.15600810945034027,
      "learning_rate": 9.098587831595619e-05,
      "loss": 0.0276,
      "step": 1420
    },
    {
      "epoch": 0.28216258879242306,
      "grad_norm": 0.12752984464168549,
      "learning_rate": 9.091988913818135e-05,
      "loss": 0.0182,
      "step": 1430
    },
    {
      "epoch": 0.2841357537490134,
      "grad_norm": 0.2322634607553482,
      "learning_rate": 9.08538999604065e-05,
      "loss": 0.0203,
      "step": 1440
    },
    {
      "epoch": 0.2861089187056038,
      "grad_norm": 0.28299856185913086,
      "learning_rate": 9.078791078263166e-05,
      "loss": 0.0246,
      "step": 1450
    },
    {
      "epoch": 0.2880820836621942,
      "grad_norm": 0.15474987030029297,
      "learning_rate": 9.07219216048568e-05,
      "loss": 0.0248,
      "step": 1460
    },
    {
      "epoch": 0.2900552486187845,
      "grad_norm": 0.1761782467365265,
      "learning_rate": 9.065593242708196e-05,
      "loss": 0.0222,
      "step": 1470
    },
    {
      "epoch": 0.2920284135753749,
      "grad_norm": 0.1634652018547058,
      "learning_rate": 9.058994324930712e-05,
      "loss": 0.0214,
      "step": 1480
    },
    {
      "epoch": 0.2940015785319653,
      "grad_norm": 0.2260710746049881,
      "learning_rate": 9.052395407153227e-05,
      "loss": 0.0245,
      "step": 1490
    },
    {
      "epoch": 0.2959747434885556,
      "grad_norm": 0.1086411252617836,
      "learning_rate": 9.045796489375743e-05,
      "loss": 0.0147,
      "step": 1500
    },
    {
      "epoch": 0.297947908445146,
      "grad_norm": 0.1889488697052002,
      "learning_rate": 9.039197571598257e-05,
      "loss": 0.022,
      "step": 1510
    },
    {
      "epoch": 0.2999210734017364,
      "grad_norm": 0.30477672815322876,
      "learning_rate": 9.032598653820775e-05,
      "loss": 0.028,
      "step": 1520
    },
    {
      "epoch": 0.30189423835832674,
      "grad_norm": 0.4428350031375885,
      "learning_rate": 9.02599973604329e-05,
      "loss": 0.0281,
      "step": 1530
    },
    {
      "epoch": 0.30386740331491713,
      "grad_norm": 0.35944440960884094,
      "learning_rate": 9.019400818265805e-05,
      "loss": 0.0284,
      "step": 1540
    },
    {
      "epoch": 0.3058405682715075,
      "grad_norm": 0.13919587433338165,
      "learning_rate": 9.01280190048832e-05,
      "loss": 0.0225,
      "step": 1550
    },
    {
      "epoch": 0.30781373322809785,
      "grad_norm": 0.2463933378458023,
      "learning_rate": 9.006202982710836e-05,
      "loss": 0.0209,
      "step": 1560
    },
    {
      "epoch": 0.30978689818468824,
      "grad_norm": 0.3741827607154846,
      "learning_rate": 8.999604064933352e-05,
      "loss": 0.023,
      "step": 1570
    },
    {
      "epoch": 0.31176006314127863,
      "grad_norm": 0.16469472646713257,
      "learning_rate": 8.993005147155868e-05,
      "loss": 0.0222,
      "step": 1580
    },
    {
      "epoch": 0.31373322809786897,
      "grad_norm": 0.2762618660926819,
      "learning_rate": 8.986406229378383e-05,
      "loss": 0.0314,
      "step": 1590
    },
    {
      "epoch": 0.31570639305445936,
      "grad_norm": 0.18345780670642853,
      "learning_rate": 8.979807311600897e-05,
      "loss": 0.0223,
      "step": 1600
    },
    {
      "epoch": 0.31767955801104975,
      "grad_norm": 0.15144047141075134,
      "learning_rate": 8.973208393823413e-05,
      "loss": 0.0251,
      "step": 1610
    },
    {
      "epoch": 0.3196527229676401,
      "grad_norm": 0.19288930296897888,
      "learning_rate": 8.966609476045929e-05,
      "loss": 0.0183,
      "step": 1620
    },
    {
      "epoch": 0.32162588792423047,
      "grad_norm": 0.18706466257572174,
      "learning_rate": 8.960010558268445e-05,
      "loss": 0.0252,
      "step": 1630
    },
    {
      "epoch": 0.32359905288082086,
      "grad_norm": 0.244232639670372,
      "learning_rate": 8.95341164049096e-05,
      "loss": 0.0155,
      "step": 1640
    },
    {
      "epoch": 0.3255722178374112,
      "grad_norm": 0.15882663428783417,
      "learning_rate": 8.946812722713476e-05,
      "loss": 0.0161,
      "step": 1650
    },
    {
      "epoch": 0.3275453827940016,
      "grad_norm": 0.15540711581707,
      "learning_rate": 8.94021380493599e-05,
      "loss": 0.0287,
      "step": 1660
    },
    {
      "epoch": 0.329518547750592,
      "grad_norm": 0.3600049912929535,
      "learning_rate": 8.933614887158506e-05,
      "loss": 0.0205,
      "step": 1670
    },
    {
      "epoch": 0.3314917127071823,
      "grad_norm": 0.08375268429517746,
      "learning_rate": 8.927015969381022e-05,
      "loss": 0.0185,
      "step": 1680
    },
    {
      "epoch": 0.3334648776637727,
      "grad_norm": 0.2130114883184433,
      "learning_rate": 8.920417051603538e-05,
      "loss": 0.0288,
      "step": 1690
    },
    {
      "epoch": 0.3354380426203631,
      "grad_norm": 0.16596010327339172,
      "learning_rate": 8.913818133826053e-05,
      "loss": 0.0249,
      "step": 1700
    },
    {
      "epoch": 0.3374112075769534,
      "grad_norm": 0.09498976171016693,
      "learning_rate": 8.907219216048569e-05,
      "loss": 0.0255,
      "step": 1710
    },
    {
      "epoch": 0.3393843725335438,
      "grad_norm": 0.1302279829978943,
      "learning_rate": 8.900620298271083e-05,
      "loss": 0.0201,
      "step": 1720
    },
    {
      "epoch": 0.3413575374901342,
      "grad_norm": 0.4256078004837036,
      "learning_rate": 8.8940213804936e-05,
      "loss": 0.0235,
      "step": 1730
    },
    {
      "epoch": 0.34333070244672453,
      "grad_norm": 0.23502911627292633,
      "learning_rate": 8.887422462716115e-05,
      "loss": 0.0155,
      "step": 1740
    },
    {
      "epoch": 0.3453038674033149,
      "grad_norm": 0.10116340219974518,
      "learning_rate": 8.88082354493863e-05,
      "loss": 0.022,
      "step": 1750
    },
    {
      "epoch": 0.3472770323599053,
      "grad_norm": 0.2188977599143982,
      "learning_rate": 8.874224627161146e-05,
      "loss": 0.0265,
      "step": 1760
    },
    {
      "epoch": 0.34925019731649565,
      "grad_norm": 0.1446029096841812,
      "learning_rate": 8.86762570938366e-05,
      "loss": 0.019,
      "step": 1770
    },
    {
      "epoch": 0.35122336227308604,
      "grad_norm": 0.11250781267881393,
      "learning_rate": 8.861026791606178e-05,
      "loss": 0.0218,
      "step": 1780
    },
    {
      "epoch": 0.3531965272296764,
      "grad_norm": 0.17726556956768036,
      "learning_rate": 8.854427873828693e-05,
      "loss": 0.0217,
      "step": 1790
    },
    {
      "epoch": 0.35516969218626676,
      "grad_norm": 0.15663570165634155,
      "learning_rate": 8.847828956051209e-05,
      "loss": 0.0258,
      "step": 1800
    },
    {
      "epoch": 0.35714285714285715,
      "grad_norm": 0.13024507462978363,
      "learning_rate": 8.841230038273723e-05,
      "loss": 0.0196,
      "step": 1810
    },
    {
      "epoch": 0.35911602209944754,
      "grad_norm": 0.39252379536628723,
      "learning_rate": 8.834631120496239e-05,
      "loss": 0.0206,
      "step": 1820
    },
    {
      "epoch": 0.3610891870560379,
      "grad_norm": 0.08633299171924591,
      "learning_rate": 8.828032202718755e-05,
      "loss": 0.0179,
      "step": 1830
    },
    {
      "epoch": 0.36306235201262826,
      "grad_norm": 0.35403943061828613,
      "learning_rate": 8.82143328494127e-05,
      "loss": 0.0192,
      "step": 1840
    },
    {
      "epoch": 0.36503551696921865,
      "grad_norm": 0.23811423778533936,
      "learning_rate": 8.814834367163786e-05,
      "loss": 0.0145,
      "step": 1850
    },
    {
      "epoch": 0.367008681925809,
      "grad_norm": 0.13806965947151184,
      "learning_rate": 8.8082354493863e-05,
      "loss": 0.0211,
      "step": 1860
    },
    {
      "epoch": 0.3689818468823994,
      "grad_norm": 0.2047615647315979,
      "learning_rate": 8.801636531608816e-05,
      "loss": 0.0165,
      "step": 1870
    },
    {
      "epoch": 0.3709550118389897,
      "grad_norm": 0.20124992728233337,
      "learning_rate": 8.795037613831332e-05,
      "loss": 0.0197,
      "step": 1880
    },
    {
      "epoch": 0.3729281767955801,
      "grad_norm": 0.10278867185115814,
      "learning_rate": 8.788438696053848e-05,
      "loss": 0.0192,
      "step": 1890
    },
    {
      "epoch": 0.3749013417521705,
      "grad_norm": 0.12448365986347198,
      "learning_rate": 8.781839778276363e-05,
      "loss": 0.0158,
      "step": 1900
    },
    {
      "epoch": 0.3768745067087608,
      "grad_norm": 0.3444187045097351,
      "learning_rate": 8.775240860498879e-05,
      "loss": 0.027,
      "step": 1910
    },
    {
      "epoch": 0.3788476716653512,
      "grad_norm": 0.22094103693962097,
      "learning_rate": 8.768641942721393e-05,
      "loss": 0.0224,
      "step": 1920
    },
    {
      "epoch": 0.3808208366219416,
      "grad_norm": 0.14947296679019928,
      "learning_rate": 8.76204302494391e-05,
      "loss": 0.0195,
      "step": 1930
    },
    {
      "epoch": 0.38279400157853194,
      "grad_norm": 0.24588803946971893,
      "learning_rate": 8.755444107166425e-05,
      "loss": 0.0199,
      "step": 1940
    },
    {
      "epoch": 0.38476716653512233,
      "grad_norm": 0.2703007757663727,
      "learning_rate": 8.748845189388941e-05,
      "loss": 0.0241,
      "step": 1950
    },
    {
      "epoch": 0.3867403314917127,
      "grad_norm": 0.1750229001045227,
      "learning_rate": 8.742246271611456e-05,
      "loss": 0.0173,
      "step": 1960
    },
    {
      "epoch": 0.38871349644830305,
      "grad_norm": 0.2533414661884308,
      "learning_rate": 8.73564735383397e-05,
      "loss": 0.0205,
      "step": 1970
    },
    {
      "epoch": 0.39068666140489344,
      "grad_norm": 0.20161814987659454,
      "learning_rate": 8.729048436056487e-05,
      "loss": 0.0205,
      "step": 1980
    },
    {
      "epoch": 0.39265982636148383,
      "grad_norm": 0.1791401207447052,
      "learning_rate": 8.722449518279003e-05,
      "loss": 0.0185,
      "step": 1990
    },
    {
      "epoch": 0.39463299131807417,
      "grad_norm": 0.13687647879123688,
      "learning_rate": 8.715850600501519e-05,
      "loss": 0.0151,
      "step": 2000
    },
    {
      "epoch": 0.39660615627466456,
      "grad_norm": 0.10799020528793335,
      "learning_rate": 8.709251682724033e-05,
      "loss": 0.0167,
      "step": 2010
    },
    {
      "epoch": 0.39857932123125495,
      "grad_norm": 0.14609432220458984,
      "learning_rate": 8.702652764946549e-05,
      "loss": 0.0199,
      "step": 2020
    },
    {
      "epoch": 0.4005524861878453,
      "grad_norm": 0.15053443610668182,
      "learning_rate": 8.696053847169064e-05,
      "loss": 0.0182,
      "step": 2030
    },
    {
      "epoch": 0.40252565114443567,
      "grad_norm": 0.017062779515981674,
      "learning_rate": 8.689454929391581e-05,
      "loss": 0.0178,
      "step": 2040
    },
    {
      "epoch": 0.40449881610102606,
      "grad_norm": 0.22404009103775024,
      "learning_rate": 8.682856011614096e-05,
      "loss": 0.0232,
      "step": 2050
    },
    {
      "epoch": 0.4064719810576164,
      "grad_norm": 0.14048415422439575,
      "learning_rate": 8.676257093836612e-05,
      "loss": 0.0272,
      "step": 2060
    },
    {
      "epoch": 0.4084451460142068,
      "grad_norm": 0.27323487401008606,
      "learning_rate": 8.669658176059126e-05,
      "loss": 0.0335,
      "step": 2070
    },
    {
      "epoch": 0.4104183109707972,
      "grad_norm": 0.20373664796352386,
      "learning_rate": 8.663059258281642e-05,
      "loss": 0.0272,
      "step": 2080
    },
    {
      "epoch": 0.4123914759273875,
      "grad_norm": 0.10446906089782715,
      "learning_rate": 8.656460340504158e-05,
      "loss": 0.0219,
      "step": 2090
    },
    {
      "epoch": 0.4143646408839779,
      "grad_norm": 0.2653334438800812,
      "learning_rate": 8.649861422726673e-05,
      "loss": 0.0219,
      "step": 2100
    },
    {
      "epoch": 0.4163378058405683,
      "grad_norm": 0.2498134821653366,
      "learning_rate": 8.643262504949189e-05,
      "loss": 0.0201,
      "step": 2110
    },
    {
      "epoch": 0.4183109707971586,
      "grad_norm": 0.14502902328968048,
      "learning_rate": 8.636663587171704e-05,
      "loss": 0.0209,
      "step": 2120
    },
    {
      "epoch": 0.420284135753749,
      "grad_norm": 0.33590662479400635,
      "learning_rate": 8.63006466939422e-05,
      "loss": 0.0202,
      "step": 2130
    },
    {
      "epoch": 0.4222573007103394,
      "grad_norm": 0.30244386196136475,
      "learning_rate": 8.623465751616736e-05,
      "loss": 0.0188,
      "step": 2140
    },
    {
      "epoch": 0.42423046566692973,
      "grad_norm": 0.13803397119045258,
      "learning_rate": 8.616866833839251e-05,
      "loss": 0.0134,
      "step": 2150
    },
    {
      "epoch": 0.4262036306235201,
      "grad_norm": 0.09343018382787704,
      "learning_rate": 8.610267916061766e-05,
      "loss": 0.0258,
      "step": 2160
    },
    {
      "epoch": 0.4281767955801105,
      "grad_norm": 0.20463450253009796,
      "learning_rate": 8.603668998284282e-05,
      "loss": 0.0228,
      "step": 2170
    },
    {
      "epoch": 0.43014996053670085,
      "grad_norm": 0.11289612948894501,
      "learning_rate": 8.597070080506797e-05,
      "loss": 0.0164,
      "step": 2180
    },
    {
      "epoch": 0.43212312549329124,
      "grad_norm": 0.16941608488559723,
      "learning_rate": 8.590471162729313e-05,
      "loss": 0.0222,
      "step": 2190
    },
    {
      "epoch": 0.4340962904498816,
      "grad_norm": 0.12562136352062225,
      "learning_rate": 8.583872244951829e-05,
      "loss": 0.0244,
      "step": 2200
    },
    {
      "epoch": 0.43606945540647196,
      "grad_norm": 0.11164776235818863,
      "learning_rate": 8.577273327174343e-05,
      "loss": 0.0184,
      "step": 2210
    },
    {
      "epoch": 0.43804262036306235,
      "grad_norm": 0.308793306350708,
      "learning_rate": 8.570674409396859e-05,
      "loss": 0.0218,
      "step": 2220
    },
    {
      "epoch": 0.44001578531965274,
      "grad_norm": 0.29739466309547424,
      "learning_rate": 8.564075491619374e-05,
      "loss": 0.0285,
      "step": 2230
    },
    {
      "epoch": 0.4419889502762431,
      "grad_norm": 0.10603107511997223,
      "learning_rate": 8.55747657384189e-05,
      "loss": 0.0213,
      "step": 2240
    },
    {
      "epoch": 0.44396211523283347,
      "grad_norm": 0.21721473336219788,
      "learning_rate": 8.550877656064406e-05,
      "loss": 0.0223,
      "step": 2250
    },
    {
      "epoch": 0.44593528018942385,
      "grad_norm": 0.1848006546497345,
      "learning_rate": 8.544278738286922e-05,
      "loss": 0.0202,
      "step": 2260
    },
    {
      "epoch": 0.4479084451460142,
      "grad_norm": 0.36138930916786194,
      "learning_rate": 8.537679820509436e-05,
      "loss": 0.03,
      "step": 2270
    },
    {
      "epoch": 0.4498816101026046,
      "grad_norm": 0.09681910276412964,
      "learning_rate": 8.531080902731952e-05,
      "loss": 0.0148,
      "step": 2280
    },
    {
      "epoch": 0.45185477505919497,
      "grad_norm": 0.3722514808177948,
      "learning_rate": 8.524481984954467e-05,
      "loss": 0.0228,
      "step": 2290
    },
    {
      "epoch": 0.4538279400157853,
      "grad_norm": 0.11490562558174133,
      "learning_rate": 8.517883067176984e-05,
      "loss": 0.0215,
      "step": 2300
    },
    {
      "epoch": 0.4558011049723757,
      "grad_norm": 0.1953182816505432,
      "learning_rate": 8.511284149399499e-05,
      "loss": 0.0181,
      "step": 2310
    },
    {
      "epoch": 0.4577742699289661,
      "grad_norm": 0.42946740984916687,
      "learning_rate": 8.504685231622015e-05,
      "loss": 0.0219,
      "step": 2320
    },
    {
      "epoch": 0.4597474348855564,
      "grad_norm": 0.35451874136924744,
      "learning_rate": 8.49808631384453e-05,
      "loss": 0.0307,
      "step": 2330
    },
    {
      "epoch": 0.4617205998421468,
      "grad_norm": 0.34077826142311096,
      "learning_rate": 8.491487396067046e-05,
      "loss": 0.0272,
      "step": 2340
    },
    {
      "epoch": 0.4636937647987372,
      "grad_norm": 0.33718401193618774,
      "learning_rate": 8.484888478289562e-05,
      "loss": 0.0235,
      "step": 2350
    },
    {
      "epoch": 0.46566692975532753,
      "grad_norm": 0.12781965732574463,
      "learning_rate": 8.478289560512076e-05,
      "loss": 0.0169,
      "step": 2360
    },
    {
      "epoch": 0.4676400947119179,
      "grad_norm": 0.11967973411083221,
      "learning_rate": 8.471690642734592e-05,
      "loss": 0.0162,
      "step": 2370
    },
    {
      "epoch": 0.4696132596685083,
      "grad_norm": 0.10332942008972168,
      "learning_rate": 8.465091724957107e-05,
      "loss": 0.0265,
      "step": 2380
    },
    {
      "epoch": 0.47158642462509864,
      "grad_norm": 0.11563345789909363,
      "learning_rate": 8.458492807179623e-05,
      "loss": 0.0199,
      "step": 2390
    },
    {
      "epoch": 0.47355958958168903,
      "grad_norm": 0.26588401198387146,
      "learning_rate": 8.451893889402139e-05,
      "loss": 0.0242,
      "step": 2400
    },
    {
      "epoch": 0.4755327545382794,
      "grad_norm": 0.35494720935821533,
      "learning_rate": 8.445294971624655e-05,
      "loss": 0.0263,
      "step": 2410
    },
    {
      "epoch": 0.47750591949486976,
      "grad_norm": 0.22371599078178406,
      "learning_rate": 8.43869605384717e-05,
      "loss": 0.0218,
      "step": 2420
    },
    {
      "epoch": 0.47947908445146015,
      "grad_norm": 0.2853167653083801,
      "learning_rate": 8.432097136069685e-05,
      "loss": 0.021,
      "step": 2430
    },
    {
      "epoch": 0.48145224940805054,
      "grad_norm": 0.4989437758922577,
      "learning_rate": 8.4254982182922e-05,
      "loss": 0.0201,
      "step": 2440
    },
    {
      "epoch": 0.48342541436464087,
      "grad_norm": 0.19106024503707886,
      "learning_rate": 8.418899300514716e-05,
      "loss": 0.0204,
      "step": 2450
    },
    {
      "epoch": 0.48539857932123126,
      "grad_norm": 0.16034157574176788,
      "learning_rate": 8.412300382737232e-05,
      "loss": 0.0207,
      "step": 2460
    },
    {
      "epoch": 0.48737174427782165,
      "grad_norm": 0.08801690489053726,
      "learning_rate": 8.405701464959747e-05,
      "loss": 0.0206,
      "step": 2470
    },
    {
      "epoch": 0.489344909234412,
      "grad_norm": 0.26352575421333313,
      "learning_rate": 8.399102547182262e-05,
      "loss": 0.017,
      "step": 2480
    },
    {
      "epoch": 0.4913180741910024,
      "grad_norm": 0.13986879587173462,
      "learning_rate": 8.392503629404777e-05,
      "loss": 0.0194,
      "step": 2490
    },
    {
      "epoch": 0.49329123914759276,
      "grad_norm": 0.036334194242954254,
      "learning_rate": 8.385904711627293e-05,
      "loss": 0.0158,
      "step": 2500
    },
    {
      "epoch": 0.49329123914759276,
      "eval_loss": 0.02126859873533249,
      "eval_runtime": 81.3306,
      "eval_samples_per_second": 13.857,
      "eval_steps_per_second": 6.935,
      "step": 2500
    },
    {
      "epoch": 0.4952644041041831,
      "grad_norm": 0.18194781243801117,
      "learning_rate": 8.379305793849809e-05,
      "loss": 0.0197,
      "step": 2510
    },
    {
      "epoch": 0.4972375690607735,
      "grad_norm": 0.2162056863307953,
      "learning_rate": 8.372706876072325e-05,
      "loss": 0.0222,
      "step": 2520
    },
    {
      "epoch": 0.4992107340173639,
      "grad_norm": 0.17764875292778015,
      "learning_rate": 8.36610795829484e-05,
      "loss": 0.0203,
      "step": 2530
    },
    {
      "epoch": 0.5011838989739542,
      "grad_norm": 0.19819465279579163,
      "learning_rate": 8.359509040517356e-05,
      "loss": 0.0163,
      "step": 2540
    },
    {
      "epoch": 0.5031570639305446,
      "grad_norm": 0.28711986541748047,
      "learning_rate": 8.352910122739872e-05,
      "loss": 0.023,
      "step": 2550
    },
    {
      "epoch": 0.505130228887135,
      "grad_norm": 0.36486539244651794,
      "learning_rate": 8.346311204962388e-05,
      "loss": 0.0229,
      "step": 2560
    },
    {
      "epoch": 0.5071033938437254,
      "grad_norm": 0.08131704479455948,
      "learning_rate": 8.339712287184902e-05,
      "loss": 0.0229,
      "step": 2570
    },
    {
      "epoch": 0.5090765588003157,
      "grad_norm": 0.18201947212219238,
      "learning_rate": 8.333113369407417e-05,
      "loss": 0.0235,
      "step": 2580
    },
    {
      "epoch": 0.511049723756906,
      "grad_norm": 0.23202383518218994,
      "learning_rate": 8.326514451629933e-05,
      "loss": 0.0165,
      "step": 2590
    },
    {
      "epoch": 0.5130228887134964,
      "grad_norm": 0.1064910739660263,
      "learning_rate": 8.319915533852449e-05,
      "loss": 0.0191,
      "step": 2600
    },
    {
      "epoch": 0.5149960536700868,
      "grad_norm": 0.27065250277519226,
      "learning_rate": 8.313316616074965e-05,
      "loss": 0.0166,
      "step": 2610
    },
    {
      "epoch": 0.5169692186266772,
      "grad_norm": 0.33568572998046875,
      "learning_rate": 8.30671769829748e-05,
      "loss": 0.0263,
      "step": 2620
    },
    {
      "epoch": 0.5189423835832676,
      "grad_norm": 0.10982749611139297,
      "learning_rate": 8.300118780519995e-05,
      "loss": 0.0146,
      "step": 2630
    },
    {
      "epoch": 0.5209155485398579,
      "grad_norm": 0.44578227400779724,
      "learning_rate": 8.29351986274251e-05,
      "loss": 0.0217,
      "step": 2640
    },
    {
      "epoch": 0.5228887134964483,
      "grad_norm": 0.11857827007770538,
      "learning_rate": 8.286920944965026e-05,
      "loss": 0.0171,
      "step": 2650
    },
    {
      "epoch": 0.5248618784530387,
      "grad_norm": 0.21179254353046417,
      "learning_rate": 8.280322027187542e-05,
      "loss": 0.0194,
      "step": 2660
    },
    {
      "epoch": 0.5268350434096291,
      "grad_norm": 0.32536983489990234,
      "learning_rate": 8.273723109410058e-05,
      "loss": 0.023,
      "step": 2670
    },
    {
      "epoch": 0.5288082083662194,
      "grad_norm": 0.2590257227420807,
      "learning_rate": 8.267124191632573e-05,
      "loss": 0.0244,
      "step": 2680
    },
    {
      "epoch": 0.5307813733228098,
      "grad_norm": 0.1393773853778839,
      "learning_rate": 8.260525273855089e-05,
      "loss": 0.0197,
      "step": 2690
    },
    {
      "epoch": 0.5327545382794001,
      "grad_norm": 0.14820709824562073,
      "learning_rate": 8.253926356077603e-05,
      "loss": 0.0215,
      "step": 2700
    },
    {
      "epoch": 0.5347277032359905,
      "grad_norm": 0.1737356036901474,
      "learning_rate": 8.247327438300119e-05,
      "loss": 0.0189,
      "step": 2710
    },
    {
      "epoch": 0.5367008681925809,
      "grad_norm": 0.15577954053878784,
      "learning_rate": 8.240728520522635e-05,
      "loss": 0.0231,
      "step": 2720
    },
    {
      "epoch": 0.5386740331491713,
      "grad_norm": 0.23820406198501587,
      "learning_rate": 8.23412960274515e-05,
      "loss": 0.0229,
      "step": 2730
    },
    {
      "epoch": 0.5406471981057617,
      "grad_norm": 0.20613008737564087,
      "learning_rate": 8.227530684967666e-05,
      "loss": 0.0245,
      "step": 2740
    },
    {
      "epoch": 0.5426203630623521,
      "grad_norm": 0.18132783472537994,
      "learning_rate": 8.22093176719018e-05,
      "loss": 0.0209,
      "step": 2750
    },
    {
      "epoch": 0.5445935280189423,
      "grad_norm": 0.1505298912525177,
      "learning_rate": 8.214332849412698e-05,
      "loss": 0.0217,
      "step": 2760
    },
    {
      "epoch": 0.5465666929755327,
      "grad_norm": 0.18341469764709473,
      "learning_rate": 8.207733931635212e-05,
      "loss": 0.0192,
      "step": 2770
    },
    {
      "epoch": 0.5485398579321231,
      "grad_norm": 0.2555026710033417,
      "learning_rate": 8.201135013857728e-05,
      "loss": 0.0219,
      "step": 2780
    },
    {
      "epoch": 0.5505130228887135,
      "grad_norm": 0.19678473472595215,
      "learning_rate": 8.194536096080243e-05,
      "loss": 0.0232,
      "step": 2790
    },
    {
      "epoch": 0.5524861878453039,
      "grad_norm": 0.21009249985218048,
      "learning_rate": 8.187937178302759e-05,
      "loss": 0.018,
      "step": 2800
    },
    {
      "epoch": 0.5544593528018943,
      "grad_norm": 0.11346568167209625,
      "learning_rate": 8.181338260525275e-05,
      "loss": 0.0215,
      "step": 2810
    },
    {
      "epoch": 0.5564325177584846,
      "grad_norm": 0.26720568537712097,
      "learning_rate": 8.174739342747791e-05,
      "loss": 0.0245,
      "step": 2820
    },
    {
      "epoch": 0.558405682715075,
      "grad_norm": 0.1183113306760788,
      "learning_rate": 8.168140424970305e-05,
      "loss": 0.0225,
      "step": 2830
    },
    {
      "epoch": 0.5603788476716653,
      "grad_norm": 0.16137270629405975,
      "learning_rate": 8.16154150719282e-05,
      "loss": 0.0186,
      "step": 2840
    },
    {
      "epoch": 0.5623520126282557,
      "grad_norm": 0.2446693331003189,
      "learning_rate": 8.154942589415336e-05,
      "loss": 0.0288,
      "step": 2850
    },
    {
      "epoch": 0.5643251775848461,
      "grad_norm": 0.14043164253234863,
      "learning_rate": 8.148343671637852e-05,
      "loss": 0.0209,
      "step": 2860
    },
    {
      "epoch": 0.5662983425414365,
      "grad_norm": 0.29300013184547424,
      "learning_rate": 8.141744753860368e-05,
      "loss": 0.0162,
      "step": 2870
    },
    {
      "epoch": 0.5682715074980268,
      "grad_norm": 0.2950044870376587,
      "learning_rate": 8.135145836082883e-05,
      "loss": 0.0212,
      "step": 2880
    },
    {
      "epoch": 0.5702446724546172,
      "grad_norm": 0.18078124523162842,
      "learning_rate": 8.128546918305399e-05,
      "loss": 0.024,
      "step": 2890
    },
    {
      "epoch": 0.5722178374112076,
      "grad_norm": 0.20878827571868896,
      "learning_rate": 8.121948000527913e-05,
      "loss": 0.0198,
      "step": 2900
    },
    {
      "epoch": 0.574191002367798,
      "grad_norm": 0.17144469916820526,
      "learning_rate": 8.115349082750429e-05,
      "loss": 0.0156,
      "step": 2910
    },
    {
      "epoch": 0.5761641673243884,
      "grad_norm": 0.13421541452407837,
      "learning_rate": 8.108750164972945e-05,
      "loss": 0.0191,
      "step": 2920
    },
    {
      "epoch": 0.5781373322809787,
      "grad_norm": 0.19750893115997314,
      "learning_rate": 8.102151247195461e-05,
      "loss": 0.0224,
      "step": 2930
    },
    {
      "epoch": 0.580110497237569,
      "grad_norm": 0.25600525736808777,
      "learning_rate": 8.095552329417976e-05,
      "loss": 0.0264,
      "step": 2940
    },
    {
      "epoch": 0.5820836621941594,
      "grad_norm": 0.2063857913017273,
      "learning_rate": 8.08895341164049e-05,
      "loss": 0.0215,
      "step": 2950
    },
    {
      "epoch": 0.5840568271507498,
      "grad_norm": 0.31065431237220764,
      "learning_rate": 8.082354493863006e-05,
      "loss": 0.0147,
      "step": 2960
    },
    {
      "epoch": 0.5860299921073402,
      "grad_norm": 0.23181788623332977,
      "learning_rate": 8.075755576085522e-05,
      "loss": 0.0243,
      "step": 2970
    },
    {
      "epoch": 0.5880031570639306,
      "grad_norm": 0.12522205710411072,
      "learning_rate": 8.069156658308038e-05,
      "loss": 0.0228,
      "step": 2980
    },
    {
      "epoch": 0.5899763220205209,
      "grad_norm": 0.2056683748960495,
      "learning_rate": 8.062557740530553e-05,
      "loss": 0.018,
      "step": 2990
    },
    {
      "epoch": 0.5919494869771112,
      "grad_norm": 0.20610255002975464,
      "learning_rate": 8.055958822753069e-05,
      "loss": 0.0265,
      "step": 3000
    },
    {
      "epoch": 0.5939226519337016,
      "grad_norm": 0.162211611866951,
      "learning_rate": 8.049359904975584e-05,
      "loss": 0.019,
      "step": 3010
    },
    {
      "epoch": 0.595895816890292,
      "grad_norm": 0.15942507982254028,
      "learning_rate": 8.042760987198101e-05,
      "loss": 0.0281,
      "step": 3020
    },
    {
      "epoch": 0.5978689818468824,
      "grad_norm": 0.16682259738445282,
      "learning_rate": 8.036162069420615e-05,
      "loss": 0.0193,
      "step": 3030
    },
    {
      "epoch": 0.5998421468034728,
      "grad_norm": 0.285078227519989,
      "learning_rate": 8.029563151643131e-05,
      "loss": 0.0201,
      "step": 3040
    },
    {
      "epoch": 0.6018153117600631,
      "grad_norm": 0.1230558305978775,
      "learning_rate": 8.022964233865646e-05,
      "loss": 0.0201,
      "step": 3050
    },
    {
      "epoch": 0.6037884767166535,
      "grad_norm": 0.134041890501976,
      "learning_rate": 8.016365316088162e-05,
      "loss": 0.0204,
      "step": 3060
    },
    {
      "epoch": 0.6057616416732439,
      "grad_norm": 0.2688177824020386,
      "learning_rate": 8.009766398310678e-05,
      "loss": 0.0165,
      "step": 3070
    },
    {
      "epoch": 0.6077348066298343,
      "grad_norm": 0.16863679885864258,
      "learning_rate": 8.003167480533193e-05,
      "loss": 0.0214,
      "step": 3080
    },
    {
      "epoch": 0.6097079715864246,
      "grad_norm": 0.21035240590572357,
      "learning_rate": 7.996568562755709e-05,
      "loss": 0.0192,
      "step": 3090
    },
    {
      "epoch": 0.611681136543015,
      "grad_norm": 0.10518282651901245,
      "learning_rate": 7.989969644978223e-05,
      "loss": 0.0135,
      "step": 3100
    },
    {
      "epoch": 0.6136543014996053,
      "grad_norm": 0.14419126510620117,
      "learning_rate": 7.983370727200739e-05,
      "loss": 0.0178,
      "step": 3110
    },
    {
      "epoch": 0.6156274664561957,
      "grad_norm": 0.16987204551696777,
      "learning_rate": 7.976771809423255e-05,
      "loss": 0.0233,
      "step": 3120
    },
    {
      "epoch": 0.6176006314127861,
      "grad_norm": 0.1857835203409195,
      "learning_rate": 7.970172891645771e-05,
      "loss": 0.0143,
      "step": 3130
    },
    {
      "epoch": 0.6195737963693765,
      "grad_norm": 0.15014050900936127,
      "learning_rate": 7.963573973868286e-05,
      "loss": 0.0189,
      "step": 3140
    },
    {
      "epoch": 0.6215469613259669,
      "grad_norm": 0.1816616803407669,
      "learning_rate": 7.956975056090802e-05,
      "loss": 0.0166,
      "step": 3150
    },
    {
      "epoch": 0.6235201262825573,
      "grad_norm": 0.19095280766487122,
      "learning_rate": 7.950376138313316e-05,
      "loss": 0.0152,
      "step": 3160
    },
    {
      "epoch": 0.6254932912391475,
      "grad_norm": 0.09470447897911072,
      "learning_rate": 7.943777220535832e-05,
      "loss": 0.0179,
      "step": 3170
    },
    {
      "epoch": 0.6274664561957379,
      "grad_norm": 0.14011748135089874,
      "learning_rate": 7.937178302758348e-05,
      "loss": 0.0242,
      "step": 3180
    },
    {
      "epoch": 0.6294396211523283,
      "grad_norm": 0.2059147208929062,
      "learning_rate": 7.930579384980864e-05,
      "loss": 0.0242,
      "step": 3190
    },
    {
      "epoch": 0.6314127861089187,
      "grad_norm": 0.1266554445028305,
      "learning_rate": 7.923980467203379e-05,
      "loss": 0.0154,
      "step": 3200
    },
    {
      "epoch": 0.6333859510655091,
      "grad_norm": 0.20140725374221802,
      "learning_rate": 7.917381549425894e-05,
      "loss": 0.0226,
      "step": 3210
    },
    {
      "epoch": 0.6353591160220995,
      "grad_norm": 0.09192371368408203,
      "learning_rate": 7.91078263164841e-05,
      "loss": 0.0161,
      "step": 3220
    },
    {
      "epoch": 0.6373322809786898,
      "grad_norm": 0.2342003881931305,
      "learning_rate": 7.904183713870926e-05,
      "loss": 0.0192,
      "step": 3230
    },
    {
      "epoch": 0.6393054459352802,
      "grad_norm": 0.2003563940525055,
      "learning_rate": 7.897584796093442e-05,
      "loss": 0.0215,
      "step": 3240
    },
    {
      "epoch": 0.6412786108918705,
      "grad_norm": 0.14200495183467865,
      "learning_rate": 7.890985878315956e-05,
      "loss": 0.0209,
      "step": 3250
    },
    {
      "epoch": 0.6432517758484609,
      "grad_norm": 0.1065407246351242,
      "learning_rate": 7.884386960538472e-05,
      "loss": 0.0163,
      "step": 3260
    },
    {
      "epoch": 0.6452249408050513,
      "grad_norm": 0.2842579483985901,
      "learning_rate": 7.877788042760987e-05,
      "loss": 0.0271,
      "step": 3270
    },
    {
      "epoch": 0.6471981057616417,
      "grad_norm": 0.07414589822292328,
      "learning_rate": 7.871189124983504e-05,
      "loss": 0.0165,
      "step": 3280
    },
    {
      "epoch": 0.649171270718232,
      "grad_norm": 0.17078010737895966,
      "learning_rate": 7.864590207206019e-05,
      "loss": 0.0132,
      "step": 3290
    },
    {
      "epoch": 0.6511444356748224,
      "grad_norm": 0.20122016966342926,
      "learning_rate": 7.857991289428535e-05,
      "loss": 0.0192,
      "step": 3300
    },
    {
      "epoch": 0.6531176006314128,
      "grad_norm": 0.11226814985275269,
      "learning_rate": 7.851392371651049e-05,
      "loss": 0.0165,
      "step": 3310
    },
    {
      "epoch": 0.6550907655880032,
      "grad_norm": 0.22637249529361725,
      "learning_rate": 7.844793453873564e-05,
      "loss": 0.0285,
      "step": 3320
    },
    {
      "epoch": 0.6570639305445936,
      "grad_norm": 0.3036360442638397,
      "learning_rate": 7.838194536096081e-05,
      "loss": 0.0276,
      "step": 3330
    },
    {
      "epoch": 0.659037095501184,
      "grad_norm": 0.3316478133201599,
      "learning_rate": 7.831595618318596e-05,
      "loss": 0.0192,
      "step": 3340
    },
    {
      "epoch": 0.6610102604577742,
      "grad_norm": 0.228751540184021,
      "learning_rate": 7.824996700541112e-05,
      "loss": 0.0175,
      "step": 3350
    },
    {
      "epoch": 0.6629834254143646,
      "grad_norm": 0.17728736996650696,
      "learning_rate": 7.818397782763626e-05,
      "loss": 0.0145,
      "step": 3360
    },
    {
      "epoch": 0.664956590370955,
      "grad_norm": 0.09107223898172379,
      "learning_rate": 7.811798864986142e-05,
      "loss": 0.0152,
      "step": 3370
    },
    {
      "epoch": 0.6669297553275454,
      "grad_norm": 0.2133299857378006,
      "learning_rate": 7.805199947208658e-05,
      "loss": 0.0217,
      "step": 3380
    },
    {
      "epoch": 0.6689029202841358,
      "grad_norm": 0.19832439720630646,
      "learning_rate": 7.798601029431174e-05,
      "loss": 0.0263,
      "step": 3390
    },
    {
      "epoch": 0.6708760852407262,
      "grad_norm": 0.1633250117301941,
      "learning_rate": 7.792002111653689e-05,
      "loss": 0.0203,
      "step": 3400
    },
    {
      "epoch": 0.6728492501973165,
      "grad_norm": 0.23351585865020752,
      "learning_rate": 7.785403193876205e-05,
      "loss": 0.0201,
      "step": 3410
    },
    {
      "epoch": 0.6748224151539068,
      "grad_norm": 0.14884375035762787,
      "learning_rate": 7.77880427609872e-05,
      "loss": 0.0155,
      "step": 3420
    },
    {
      "epoch": 0.6767955801104972,
      "grad_norm": 0.12219247221946716,
      "learning_rate": 7.772205358321236e-05,
      "loss": 0.0232,
      "step": 3430
    },
    {
      "epoch": 0.6787687450670876,
      "grad_norm": 0.1977025866508484,
      "learning_rate": 7.765606440543752e-05,
      "loss": 0.0198,
      "step": 3440
    },
    {
      "epoch": 0.680741910023678,
      "grad_norm": 0.15595515072345734,
      "learning_rate": 7.759007522766266e-05,
      "loss": 0.021,
      "step": 3450
    },
    {
      "epoch": 0.6827150749802684,
      "grad_norm": 0.10508520901203156,
      "learning_rate": 7.752408604988782e-05,
      "loss": 0.0202,
      "step": 3460
    },
    {
      "epoch": 0.6846882399368587,
      "grad_norm": 0.014118521474301815,
      "learning_rate": 7.745809687211297e-05,
      "loss": 0.021,
      "step": 3470
    },
    {
      "epoch": 0.6866614048934491,
      "grad_norm": 0.21432825922966003,
      "learning_rate": 7.739210769433813e-05,
      "loss": 0.0142,
      "step": 3480
    },
    {
      "epoch": 0.6886345698500395,
      "grad_norm": 0.17746473848819733,
      "learning_rate": 7.732611851656329e-05,
      "loss": 0.0184,
      "step": 3490
    },
    {
      "epoch": 0.6906077348066298,
      "grad_norm": 0.20159997045993805,
      "learning_rate": 7.726012933878845e-05,
      "loss": 0.0154,
      "step": 3500
    },
    {
      "epoch": 0.6925808997632202,
      "grad_norm": 0.13225208222866058,
      "learning_rate": 7.71941401610136e-05,
      "loss": 0.0273,
      "step": 3510
    },
    {
      "epoch": 0.6945540647198106,
      "grad_norm": 0.18868038058280945,
      "learning_rate": 7.712815098323875e-05,
      "loss": 0.0227,
      "step": 3520
    },
    {
      "epoch": 0.6965272296764009,
      "grad_norm": 0.2039877325296402,
      "learning_rate": 7.70621618054639e-05,
      "loss": 0.0236,
      "step": 3530
    },
    {
      "epoch": 0.6985003946329913,
      "grad_norm": 0.24704156816005707,
      "learning_rate": 7.699617262768907e-05,
      "loss": 0.0176,
      "step": 3540
    },
    {
      "epoch": 0.7004735595895817,
      "grad_norm": 0.1873452514410019,
      "learning_rate": 7.693018344991422e-05,
      "loss": 0.0181,
      "step": 3550
    },
    {
      "epoch": 0.7024467245461721,
      "grad_norm": 0.13214188814163208,
      "learning_rate": 7.686419427213938e-05,
      "loss": 0.018,
      "step": 3560
    },
    {
      "epoch": 0.7044198895027625,
      "grad_norm": 0.15276233851909637,
      "learning_rate": 7.679820509436453e-05,
      "loss": 0.024,
      "step": 3570
    },
    {
      "epoch": 0.7063930544593529,
      "grad_norm": 0.21931789815425873,
      "learning_rate": 7.673221591658968e-05,
      "loss": 0.0192,
      "step": 3580
    },
    {
      "epoch": 0.7083662194159431,
      "grad_norm": 0.16482849419116974,
      "learning_rate": 7.666622673881484e-05,
      "loss": 0.0202,
      "step": 3590
    },
    {
      "epoch": 0.7103393843725335,
      "grad_norm": 0.21209532022476196,
      "learning_rate": 7.660023756103999e-05,
      "loss": 0.0315,
      "step": 3600
    },
    {
      "epoch": 0.7123125493291239,
      "grad_norm": 0.26788192987442017,
      "learning_rate": 7.653424838326515e-05,
      "loss": 0.019,
      "step": 3610
    },
    {
      "epoch": 0.7142857142857143,
      "grad_norm": 0.3321104049682617,
      "learning_rate": 7.64682592054903e-05,
      "loss": 0.0248,
      "step": 3620
    },
    {
      "epoch": 0.7162588792423047,
      "grad_norm": 0.24503877758979797,
      "learning_rate": 7.640227002771546e-05,
      "loss": 0.0205,
      "step": 3630
    },
    {
      "epoch": 0.7182320441988951,
      "grad_norm": 0.23315125703811646,
      "learning_rate": 7.633628084994062e-05,
      "loss": 0.0233,
      "step": 3640
    },
    {
      "epoch": 0.7202052091554854,
      "grad_norm": 0.09343622624874115,
      "learning_rate": 7.627029167216578e-05,
      "loss": 0.025,
      "step": 3650
    },
    {
      "epoch": 0.7221783741120757,
      "grad_norm": 0.1751154214143753,
      "learning_rate": 7.620430249439092e-05,
      "loss": 0.026,
      "step": 3660
    },
    {
      "epoch": 0.7241515390686661,
      "grad_norm": 0.21410617232322693,
      "learning_rate": 7.613831331661608e-05,
      "loss": 0.0152,
      "step": 3670
    },
    {
      "epoch": 0.7261247040252565,
      "grad_norm": 0.8266969919204712,
      "learning_rate": 7.607232413884123e-05,
      "loss": 0.0272,
      "step": 3680
    },
    {
      "epoch": 0.7280978689818469,
      "grad_norm": 0.16487720608711243,
      "learning_rate": 7.600633496106639e-05,
      "loss": 0.0238,
      "step": 3690
    },
    {
      "epoch": 0.7300710339384373,
      "grad_norm": 0.138772115111351,
      "learning_rate": 7.594034578329155e-05,
      "loss": 0.0219,
      "step": 3700
    },
    {
      "epoch": 0.7320441988950276,
      "grad_norm": 0.08966461569070816,
      "learning_rate": 7.58743566055167e-05,
      "loss": 0.0188,
      "step": 3710
    },
    {
      "epoch": 0.734017363851618,
      "grad_norm": 0.19262608885765076,
      "learning_rate": 7.580836742774185e-05,
      "loss": 0.0159,
      "step": 3720
    },
    {
      "epoch": 0.7359905288082084,
      "grad_norm": 0.22183167934417725,
      "learning_rate": 7.5742378249967e-05,
      "loss": 0.0258,
      "step": 3730
    },
    {
      "epoch": 0.7379636937647988,
      "grad_norm": 0.11993487179279327,
      "learning_rate": 7.567638907219216e-05,
      "loss": 0.0226,
      "step": 3740
    },
    {
      "epoch": 0.7399368587213891,
      "grad_norm": 0.12507565319538116,
      "learning_rate": 7.561039989441732e-05,
      "loss": 0.0161,
      "step": 3750
    },
    {
      "epoch": 0.7419100236779794,
      "grad_norm": 0.10745587199926376,
      "learning_rate": 7.554441071664248e-05,
      "loss": 0.0199,
      "step": 3760
    },
    {
      "epoch": 0.7438831886345698,
      "grad_norm": 0.09904761612415314,
      "learning_rate": 7.547842153886763e-05,
      "loss": 0.0184,
      "step": 3770
    },
    {
      "epoch": 0.7458563535911602,
      "grad_norm": 0.3150240182876587,
      "learning_rate": 7.541243236109279e-05,
      "loss": 0.0203,
      "step": 3780
    },
    {
      "epoch": 0.7478295185477506,
      "grad_norm": 0.2497320920228958,
      "learning_rate": 7.534644318331795e-05,
      "loss": 0.02,
      "step": 3790
    },
    {
      "epoch": 0.749802683504341,
      "grad_norm": 0.2479589432477951,
      "learning_rate": 7.52804540055431e-05,
      "loss": 0.0256,
      "step": 3800
    },
    {
      "epoch": 0.7517758484609314,
      "grad_norm": 0.12614582479000092,
      "learning_rate": 7.521446482776825e-05,
      "loss": 0.0169,
      "step": 3810
    },
    {
      "epoch": 0.7537490134175217,
      "grad_norm": 0.2953318953514099,
      "learning_rate": 7.51484756499934e-05,
      "loss": 0.0212,
      "step": 3820
    },
    {
      "epoch": 0.755722178374112,
      "grad_norm": 0.22516632080078125,
      "learning_rate": 7.508248647221856e-05,
      "loss": 0.0218,
      "step": 3830
    },
    {
      "epoch": 0.7576953433307024,
      "grad_norm": 0.11684217303991318,
      "learning_rate": 7.501649729444372e-05,
      "loss": 0.0192,
      "step": 3840
    },
    {
      "epoch": 0.7596685082872928,
      "grad_norm": 0.16509594023227692,
      "learning_rate": 7.495050811666888e-05,
      "loss": 0.0174,
      "step": 3850
    },
    {
      "epoch": 0.7616416732438832,
      "grad_norm": 0.1074863150715828,
      "learning_rate": 7.488451893889402e-05,
      "loss": 0.0213,
      "step": 3860
    },
    {
      "epoch": 0.7636148382004736,
      "grad_norm": 0.14428700506687164,
      "learning_rate": 7.481852976111918e-05,
      "loss": 0.0242,
      "step": 3870
    },
    {
      "epoch": 0.7655880031570639,
      "grad_norm": 0.09986727684736252,
      "learning_rate": 7.475254058334433e-05,
      "loss": 0.0185,
      "step": 3880
    },
    {
      "epoch": 0.7675611681136543,
      "grad_norm": 0.20986859500408173,
      "learning_rate": 7.468655140556949e-05,
      "loss": 0.0182,
      "step": 3890
    },
    {
      "epoch": 0.7695343330702447,
      "grad_norm": 0.12734319269657135,
      "learning_rate": 7.462056222779465e-05,
      "loss": 0.0212,
      "step": 3900
    },
    {
      "epoch": 0.771507498026835,
      "grad_norm": 0.1346447765827179,
      "learning_rate": 7.455457305001981e-05,
      "loss": 0.0225,
      "step": 3910
    },
    {
      "epoch": 0.7734806629834254,
      "grad_norm": 0.1891154646873474,
      "learning_rate": 7.448858387224495e-05,
      "loss": 0.0217,
      "step": 3920
    },
    {
      "epoch": 0.7754538279400158,
      "grad_norm": 0.2145964801311493,
      "learning_rate": 7.442259469447011e-05,
      "loss": 0.0183,
      "step": 3930
    },
    {
      "epoch": 0.7774269928966061,
      "grad_norm": 0.16411130130290985,
      "learning_rate": 7.435660551669526e-05,
      "loss": 0.022,
      "step": 3940
    },
    {
      "epoch": 0.7794001578531965,
      "grad_norm": 0.09918058663606644,
      "learning_rate": 7.429061633892042e-05,
      "loss": 0.0186,
      "step": 3950
    },
    {
      "epoch": 0.7813733228097869,
      "grad_norm": 0.2021176666021347,
      "learning_rate": 7.422462716114558e-05,
      "loss": 0.0193,
      "step": 3960
    },
    {
      "epoch": 0.7833464877663773,
      "grad_norm": 0.3175845444202423,
      "learning_rate": 7.415863798337073e-05,
      "loss": 0.0231,
      "step": 3970
    },
    {
      "epoch": 0.7853196527229677,
      "grad_norm": 0.11434558033943176,
      "learning_rate": 7.409264880559589e-05,
      "loss": 0.029,
      "step": 3980
    },
    {
      "epoch": 0.787292817679558,
      "grad_norm": 0.26025646924972534,
      "learning_rate": 7.402665962782103e-05,
      "loss": 0.0234,
      "step": 3990
    },
    {
      "epoch": 0.7892659826361483,
      "grad_norm": 0.1366506665945053,
      "learning_rate": 7.396067045004619e-05,
      "loss": 0.0243,
      "step": 4000
    },
    {
      "epoch": 0.7912391475927387,
      "grad_norm": 0.11612890660762787,
      "learning_rate": 7.389468127227135e-05,
      "loss": 0.0247,
      "step": 4010
    },
    {
      "epoch": 0.7932123125493291,
      "grad_norm": 0.19650103151798248,
      "learning_rate": 7.382869209449651e-05,
      "loss": 0.0198,
      "step": 4020
    },
    {
      "epoch": 0.7951854775059195,
      "grad_norm": 0.2765519320964813,
      "learning_rate": 7.376270291672166e-05,
      "loss": 0.0239,
      "step": 4030
    },
    {
      "epoch": 0.7971586424625099,
      "grad_norm": 0.20627491176128387,
      "learning_rate": 7.369671373894682e-05,
      "loss": 0.0172,
      "step": 4040
    },
    {
      "epoch": 0.7991318074191003,
      "grad_norm": 0.21275171637535095,
      "learning_rate": 7.363072456117198e-05,
      "loss": 0.0154,
      "step": 4050
    },
    {
      "epoch": 0.8011049723756906,
      "grad_norm": 0.0809277817606926,
      "learning_rate": 7.356473538339712e-05,
      "loss": 0.0196,
      "step": 4060
    },
    {
      "epoch": 0.803078137332281,
      "grad_norm": 0.13796769082546234,
      "learning_rate": 7.349874620562228e-05,
      "loss": 0.018,
      "step": 4070
    },
    {
      "epoch": 0.8050513022888713,
      "grad_norm": 0.2002200186252594,
      "learning_rate": 7.343275702784743e-05,
      "loss": 0.0206,
      "step": 4080
    },
    {
      "epoch": 0.8070244672454617,
      "grad_norm": 0.24457143247127533,
      "learning_rate": 7.336676785007259e-05,
      "loss": 0.0186,
      "step": 4090
    },
    {
      "epoch": 0.8089976322020521,
      "grad_norm": 0.10161738097667694,
      "learning_rate": 7.330077867229775e-05,
      "loss": 0.0179,
      "step": 4100
    },
    {
      "epoch": 0.8109707971586425,
      "grad_norm": 0.36681628227233887,
      "learning_rate": 7.323478949452291e-05,
      "loss": 0.0226,
      "step": 4110
    },
    {
      "epoch": 0.8129439621152328,
      "grad_norm": 0.17184436321258545,
      "learning_rate": 7.316880031674806e-05,
      "loss": 0.015,
      "step": 4120
    },
    {
      "epoch": 0.8149171270718232,
      "grad_norm": 0.08487793058156967,
      "learning_rate": 7.310281113897321e-05,
      "loss": 0.0179,
      "step": 4130
    },
    {
      "epoch": 0.8168902920284136,
      "grad_norm": 0.03338096663355827,
      "learning_rate": 7.303682196119836e-05,
      "loss": 0.0224,
      "step": 4140
    },
    {
      "epoch": 0.818863456985004,
      "grad_norm": 0.23319175839424133,
      "learning_rate": 7.297083278342352e-05,
      "loss": 0.0219,
      "step": 4150
    },
    {
      "epoch": 0.8208366219415943,
      "grad_norm": 0.1827239990234375,
      "learning_rate": 7.290484360564868e-05,
      "loss": 0.0183,
      "step": 4160
    },
    {
      "epoch": 0.8228097868981847,
      "grad_norm": 0.2217681109905243,
      "learning_rate": 7.283885442787384e-05,
      "loss": 0.0228,
      "step": 4170
    },
    {
      "epoch": 0.824782951854775,
      "grad_norm": 0.33084625005722046,
      "learning_rate": 7.277286525009899e-05,
      "loss": 0.0218,
      "step": 4180
    },
    {
      "epoch": 0.8267561168113654,
      "grad_norm": 0.18638092279434204,
      "learning_rate": 7.270687607232413e-05,
      "loss": 0.0206,
      "step": 4190
    },
    {
      "epoch": 0.8287292817679558,
      "grad_norm": 0.08139859139919281,
      "learning_rate": 7.264088689454929e-05,
      "loss": 0.0128,
      "step": 4200
    },
    {
      "epoch": 0.8307024467245462,
      "grad_norm": 0.3534875214099884,
      "learning_rate": 7.257489771677445e-05,
      "loss": 0.0177,
      "step": 4210
    },
    {
      "epoch": 0.8326756116811366,
      "grad_norm": 0.23723945021629333,
      "learning_rate": 7.250890853899961e-05,
      "loss": 0.0196,
      "step": 4220
    },
    {
      "epoch": 0.834648776637727,
      "grad_norm": 0.27476754784584045,
      "learning_rate": 7.244291936122476e-05,
      "loss": 0.0219,
      "step": 4230
    },
    {
      "epoch": 0.8366219415943172,
      "grad_norm": 0.10219772160053253,
      "learning_rate": 7.237693018344992e-05,
      "loss": 0.0189,
      "step": 4240
    },
    {
      "epoch": 0.8385951065509076,
      "grad_norm": 0.19338750839233398,
      "learning_rate": 7.231094100567506e-05,
      "loss": 0.0186,
      "step": 4250
    },
    {
      "epoch": 0.840568271507498,
      "grad_norm": 0.12269362062215805,
      "learning_rate": 7.224495182790024e-05,
      "loss": 0.0146,
      "step": 4260
    },
    {
      "epoch": 0.8425414364640884,
      "grad_norm": 0.11631211638450623,
      "learning_rate": 7.217896265012538e-05,
      "loss": 0.0152,
      "step": 4270
    },
    {
      "epoch": 0.8445146014206788,
      "grad_norm": 0.2436104118824005,
      "learning_rate": 7.211297347235054e-05,
      "loss": 0.0203,
      "step": 4280
    },
    {
      "epoch": 0.8464877663772692,
      "grad_norm": 0.1461351066827774,
      "learning_rate": 7.204698429457569e-05,
      "loss": 0.0192,
      "step": 4290
    },
    {
      "epoch": 0.8484609313338595,
      "grad_norm": 0.0688849613070488,
      "learning_rate": 7.198099511680085e-05,
      "loss": 0.0199,
      "step": 4300
    },
    {
      "epoch": 0.8504340962904499,
      "grad_norm": 0.14269313216209412,
      "learning_rate": 7.191500593902601e-05,
      "loss": 0.0262,
      "step": 4310
    },
    {
      "epoch": 0.8524072612470402,
      "grad_norm": 0.16537883877754211,
      "learning_rate": 7.184901676125116e-05,
      "loss": 0.0208,
      "step": 4320
    },
    {
      "epoch": 0.8543804262036306,
      "grad_norm": 0.17928306758403778,
      "learning_rate": 7.178302758347632e-05,
      "loss": 0.0175,
      "step": 4330
    },
    {
      "epoch": 0.856353591160221,
      "grad_norm": 0.1185939684510231,
      "learning_rate": 7.171703840570146e-05,
      "loss": 0.0211,
      "step": 4340
    },
    {
      "epoch": 0.8583267561168114,
      "grad_norm": 0.10264576226472855,
      "learning_rate": 7.165104922792662e-05,
      "loss": 0.019,
      "step": 4350
    },
    {
      "epoch": 0.8602999210734017,
      "grad_norm": 0.18520423769950867,
      "learning_rate": 7.158506005015178e-05,
      "loss": 0.0147,
      "step": 4360
    },
    {
      "epoch": 0.8622730860299921,
      "grad_norm": 0.2572309672832489,
      "learning_rate": 7.151907087237694e-05,
      "loss": 0.0223,
      "step": 4370
    },
    {
      "epoch": 0.8642462509865825,
      "grad_norm": 0.13082215189933777,
      "learning_rate": 7.145308169460209e-05,
      "loss": 0.0207,
      "step": 4380
    },
    {
      "epoch": 0.8662194159431729,
      "grad_norm": 0.24392804503440857,
      "learning_rate": 7.138709251682725e-05,
      "loss": 0.0197,
      "step": 4390
    },
    {
      "epoch": 0.8681925808997633,
      "grad_norm": 0.23784270882606506,
      "learning_rate": 7.13211033390524e-05,
      "loss": 0.0252,
      "step": 4400
    },
    {
      "epoch": 0.8701657458563536,
      "grad_norm": 0.1311045140028,
      "learning_rate": 7.125511416127755e-05,
      "loss": 0.0208,
      "step": 4410
    },
    {
      "epoch": 0.8721389108129439,
      "grad_norm": 0.3357791602611542,
      "learning_rate": 7.118912498350271e-05,
      "loss": 0.0184,
      "step": 4420
    },
    {
      "epoch": 0.8741120757695343,
      "grad_norm": 0.11920330673456192,
      "learning_rate": 7.112313580572786e-05,
      "loss": 0.0148,
      "step": 4430
    },
    {
      "epoch": 0.8760852407261247,
      "grad_norm": 0.12970799207687378,
      "learning_rate": 7.105714662795302e-05,
      "loss": 0.0243,
      "step": 4440
    },
    {
      "epoch": 0.8780584056827151,
      "grad_norm": 0.0995183140039444,
      "learning_rate": 7.099115745017817e-05,
      "loss": 0.018,
      "step": 4450
    },
    {
      "epoch": 0.8800315706393055,
      "grad_norm": 0.146336629986763,
      "learning_rate": 7.092516827240332e-05,
      "loss": 0.0172,
      "step": 4460
    },
    {
      "epoch": 0.8820047355958959,
      "grad_norm": 0.1128312274813652,
      "learning_rate": 7.085917909462848e-05,
      "loss": 0.0236,
      "step": 4470
    },
    {
      "epoch": 0.8839779005524862,
      "grad_norm": 0.17010140419006348,
      "learning_rate": 7.079318991685364e-05,
      "loss": 0.0194,
      "step": 4480
    },
    {
      "epoch": 0.8859510655090765,
      "grad_norm": 0.08366888016462326,
      "learning_rate": 7.072720073907879e-05,
      "loss": 0.0221,
      "step": 4490
    },
    {
      "epoch": 0.8879242304656669,
      "grad_norm": 0.431151807308197,
      "learning_rate": 7.066121156130395e-05,
      "loss": 0.0203,
      "step": 4500
    },
    {
      "epoch": 0.8898973954222573,
      "grad_norm": 0.1749744862318039,
      "learning_rate": 7.05952223835291e-05,
      "loss": 0.024,
      "step": 4510
    },
    {
      "epoch": 0.8918705603788477,
      "grad_norm": 0.13015027344226837,
      "learning_rate": 7.052923320575427e-05,
      "loss": 0.0218,
      "step": 4520
    },
    {
      "epoch": 0.893843725335438,
      "grad_norm": 0.11009856313467026,
      "learning_rate": 7.046324402797942e-05,
      "loss": 0.0173,
      "step": 4530
    },
    {
      "epoch": 0.8958168902920284,
      "grad_norm": 0.17459483444690704,
      "learning_rate": 7.039725485020458e-05,
      "loss": 0.0194,
      "step": 4540
    },
    {
      "epoch": 0.8977900552486188,
      "grad_norm": 0.18931736052036285,
      "learning_rate": 7.033126567242972e-05,
      "loss": 0.0254,
      "step": 4550
    },
    {
      "epoch": 0.8997632202052092,
      "grad_norm": 0.14459636807441711,
      "learning_rate": 7.026527649465487e-05,
      "loss": 0.0162,
      "step": 4560
    },
    {
      "epoch": 0.9017363851617995,
      "grad_norm": 0.14794792234897614,
      "learning_rate": 7.019928731688004e-05,
      "loss": 0.0211,
      "step": 4570
    },
    {
      "epoch": 0.9037095501183899,
      "grad_norm": 0.16460078954696655,
      "learning_rate": 7.013329813910519e-05,
      "loss": 0.0202,
      "step": 4580
    },
    {
      "epoch": 0.9056827150749802,
      "grad_norm": 0.17632076144218445,
      "learning_rate": 7.006730896133035e-05,
      "loss": 0.0145,
      "step": 4590
    },
    {
      "epoch": 0.9076558800315706,
      "grad_norm": 0.11828061193227768,
      "learning_rate": 7.00013197835555e-05,
      "loss": 0.0183,
      "step": 4600
    },
    {
      "epoch": 0.909629044988161,
      "grad_norm": 0.13718464970588684,
      "learning_rate": 6.993533060578065e-05,
      "loss": 0.0142,
      "step": 4610
    },
    {
      "epoch": 0.9116022099447514,
      "grad_norm": 0.2087099254131317,
      "learning_rate": 6.986934142800581e-05,
      "loss": 0.021,
      "step": 4620
    },
    {
      "epoch": 0.9135753749013418,
      "grad_norm": 0.03343246132135391,
      "learning_rate": 6.980335225023097e-05,
      "loss": 0.0153,
      "step": 4630
    },
    {
      "epoch": 0.9155485398579322,
      "grad_norm": 0.1064058467745781,
      "learning_rate": 6.973736307245612e-05,
      "loss": 0.0204,
      "step": 4640
    },
    {
      "epoch": 0.9175217048145224,
      "grad_norm": 0.1061515137553215,
      "learning_rate": 6.967137389468128e-05,
      "loss": 0.0203,
      "step": 4650
    },
    {
      "epoch": 0.9194948697711128,
      "grad_norm": 0.26454809308052063,
      "learning_rate": 6.960538471690643e-05,
      "loss": 0.0243,
      "step": 4660
    },
    {
      "epoch": 0.9214680347277032,
      "grad_norm": 0.0829278752207756,
      "learning_rate": 6.953939553913159e-05,
      "loss": 0.0216,
      "step": 4670
    },
    {
      "epoch": 0.9234411996842936,
      "grad_norm": 0.13596946001052856,
      "learning_rate": 6.947340636135675e-05,
      "loss": 0.016,
      "step": 4680
    },
    {
      "epoch": 0.925414364640884,
      "grad_norm": 0.1879347860813141,
      "learning_rate": 6.940741718358189e-05,
      "loss": 0.0232,
      "step": 4690
    },
    {
      "epoch": 0.9273875295974744,
      "grad_norm": 0.14727672934532166,
      "learning_rate": 6.934142800580705e-05,
      "loss": 0.0238,
      "step": 4700
    },
    {
      "epoch": 0.9293606945540647,
      "grad_norm": 0.17501649260520935,
      "learning_rate": 6.92754388280322e-05,
      "loss": 0.0216,
      "step": 4710
    },
    {
      "epoch": 0.9313338595106551,
      "grad_norm": 0.11131854355335236,
      "learning_rate": 6.920944965025736e-05,
      "loss": 0.013,
      "step": 4720
    },
    {
      "epoch": 0.9333070244672454,
      "grad_norm": 0.15420174598693848,
      "learning_rate": 6.914346047248252e-05,
      "loss": 0.0194,
      "step": 4730
    },
    {
      "epoch": 0.9352801894238358,
      "grad_norm": 0.18381711840629578,
      "learning_rate": 6.907747129470768e-05,
      "loss": 0.033,
      "step": 4740
    },
    {
      "epoch": 0.9372533543804262,
      "grad_norm": 0.232926145195961,
      "learning_rate": 6.901148211693282e-05,
      "loss": 0.0233,
      "step": 4750
    },
    {
      "epoch": 0.9392265193370166,
      "grad_norm": 0.2899739146232605,
      "learning_rate": 6.894549293915798e-05,
      "loss": 0.0222,
      "step": 4760
    },
    {
      "epoch": 0.9411996842936069,
      "grad_norm": 0.15998108685016632,
      "learning_rate": 6.887950376138313e-05,
      "loss": 0.0204,
      "step": 4770
    },
    {
      "epoch": 0.9431728492501973,
      "grad_norm": 0.1830623894929886,
      "learning_rate": 6.88135145836083e-05,
      "loss": 0.0212,
      "step": 4780
    },
    {
      "epoch": 0.9451460142067877,
      "grad_norm": 0.21538393199443817,
      "learning_rate": 6.874752540583345e-05,
      "loss": 0.0171,
      "step": 4790
    },
    {
      "epoch": 0.9471191791633781,
      "grad_norm": 0.3137681186199188,
      "learning_rate": 6.868153622805861e-05,
      "loss": 0.0172,
      "step": 4800
    },
    {
      "epoch": 0.9490923441199685,
      "grad_norm": 0.19769886136054993,
      "learning_rate": 6.861554705028375e-05,
      "loss": 0.0142,
      "step": 4810
    },
    {
      "epoch": 0.9510655090765588,
      "grad_norm": 0.13370254635810852,
      "learning_rate": 6.85495578725089e-05,
      "loss": 0.0191,
      "step": 4820
    },
    {
      "epoch": 0.9530386740331491,
      "grad_norm": 0.17305204272270203,
      "learning_rate": 6.848356869473407e-05,
      "loss": 0.0117,
      "step": 4830
    },
    {
      "epoch": 0.9550118389897395,
      "grad_norm": 0.22370868921279907,
      "learning_rate": 6.841757951695922e-05,
      "loss": 0.017,
      "step": 4840
    },
    {
      "epoch": 0.9569850039463299,
      "grad_norm": 0.1310393214225769,
      "learning_rate": 6.835159033918438e-05,
      "loss": 0.0171,
      "step": 4850
    },
    {
      "epoch": 0.9589581689029203,
      "grad_norm": 0.23780162632465363,
      "learning_rate": 6.828560116140953e-05,
      "loss": 0.0204,
      "step": 4860
    },
    {
      "epoch": 0.9609313338595107,
      "grad_norm": 0.07679881900548935,
      "learning_rate": 6.821961198363469e-05,
      "loss": 0.0223,
      "step": 4870
    },
    {
      "epoch": 0.9629044988161011,
      "grad_norm": 0.17016959190368652,
      "learning_rate": 6.815362280585985e-05,
      "loss": 0.0181,
      "step": 4880
    },
    {
      "epoch": 0.9648776637726914,
      "grad_norm": 0.10384056717157364,
      "learning_rate": 6.8087633628085e-05,
      "loss": 0.0212,
      "step": 4890
    },
    {
      "epoch": 0.9668508287292817,
      "grad_norm": 0.07297742366790771,
      "learning_rate": 6.802164445031015e-05,
      "loss": 0.0172,
      "step": 4900
    },
    {
      "epoch": 0.9688239936858721,
      "grad_norm": 0.1508493721485138,
      "learning_rate": 6.795565527253531e-05,
      "loss": 0.0128,
      "step": 4910
    },
    {
      "epoch": 0.9707971586424625,
      "grad_norm": 0.2583673298358917,
      "learning_rate": 6.788966609476046e-05,
      "loss": 0.0169,
      "step": 4920
    },
    {
      "epoch": 0.9727703235990529,
      "grad_norm": 0.16614826023578644,
      "learning_rate": 6.782367691698562e-05,
      "loss": 0.0169,
      "step": 4930
    },
    {
      "epoch": 0.9747434885556433,
      "grad_norm": 0.11186005175113678,
      "learning_rate": 6.775768773921078e-05,
      "loss": 0.0172,
      "step": 4940
    },
    {
      "epoch": 0.9767166535122336,
      "grad_norm": 0.17114174365997314,
      "learning_rate": 6.769169856143592e-05,
      "loss": 0.0255,
      "step": 4950
    },
    {
      "epoch": 0.978689818468824,
      "grad_norm": 0.14804548025131226,
      "learning_rate": 6.762570938366108e-05,
      "loss": 0.0203,
      "step": 4960
    },
    {
      "epoch": 0.9806629834254144,
      "grad_norm": 0.06252957135438919,
      "learning_rate": 6.755972020588623e-05,
      "loss": 0.0198,
      "step": 4970
    },
    {
      "epoch": 0.9826361483820047,
      "grad_norm": 0.24678277969360352,
      "learning_rate": 6.749373102811139e-05,
      "loss": 0.022,
      "step": 4980
    },
    {
      "epoch": 0.9846093133385951,
      "grad_norm": 0.09253264963626862,
      "learning_rate": 6.742774185033655e-05,
      "loss": 0.0215,
      "step": 4990
    },
    {
      "epoch": 0.9865824782951855,
      "grad_norm": 0.14735917747020721,
      "learning_rate": 6.736175267256171e-05,
      "loss": 0.0258,
      "step": 5000
    },
    {
      "epoch": 0.9865824782951855,
      "eval_loss": 0.018556997179985046,
      "eval_runtime": 77.5997,
      "eval_samples_per_second": 14.523,
      "eval_steps_per_second": 7.268,
      "step": 5000
    },
    {
      "epoch": 0.9885556432517758,
      "grad_norm": 0.19784000515937805,
      "learning_rate": 6.729576349478685e-05,
      "loss": 0.0224,
      "step": 5010
    },
    {
      "epoch": 0.9905288082083662,
      "grad_norm": 0.13323652744293213,
      "learning_rate": 6.722977431701201e-05,
      "loss": 0.0187,
      "step": 5020
    },
    {
      "epoch": 0.9925019731649566,
      "grad_norm": 0.14905619621276855,
      "learning_rate": 6.716378513923716e-05,
      "loss": 0.0177,
      "step": 5030
    },
    {
      "epoch": 0.994475138121547,
      "grad_norm": 0.1904193013906479,
      "learning_rate": 6.709779596146233e-05,
      "loss": 0.0135,
      "step": 5040
    },
    {
      "epoch": 0.9964483030781374,
      "grad_norm": 0.32508423924446106,
      "learning_rate": 6.703180678368748e-05,
      "loss": 0.0207,
      "step": 5050
    },
    {
      "epoch": 0.9984214680347278,
      "grad_norm": 0.14917577803134918,
      "learning_rate": 6.696581760591263e-05,
      "loss": 0.0188,
      "step": 5060
    },
    {
      "epoch": 1.000394632991318,
      "grad_norm": 0.10956957191228867,
      "learning_rate": 6.689982842813779e-05,
      "loss": 0.0196,
      "step": 5070
    },
    {
      "epoch": 1.0023677979479084,
      "grad_norm": 0.19788821041584015,
      "learning_rate": 6.683383925036295e-05,
      "loss": 0.0161,
      "step": 5080
    },
    {
      "epoch": 1.0043409629044988,
      "grad_norm": 0.11511150002479553,
      "learning_rate": 6.67678500725881e-05,
      "loss": 0.0226,
      "step": 5090
    },
    {
      "epoch": 1.0063141278610892,
      "grad_norm": 0.11834748834371567,
      "learning_rate": 6.670186089481325e-05,
      "loss": 0.0216,
      "step": 5100
    },
    {
      "epoch": 1.0082872928176796,
      "grad_norm": 0.1622592657804489,
      "learning_rate": 6.663587171703841e-05,
      "loss": 0.0194,
      "step": 5110
    },
    {
      "epoch": 1.01026045777427,
      "grad_norm": 0.10215382277965546,
      "learning_rate": 6.656988253926356e-05,
      "loss": 0.0183,
      "step": 5120
    },
    {
      "epoch": 1.0122336227308604,
      "grad_norm": 0.1689581423997879,
      "learning_rate": 6.650389336148872e-05,
      "loss": 0.0131,
      "step": 5130
    },
    {
      "epoch": 1.0142067876874508,
      "grad_norm": 0.21463344991207123,
      "learning_rate": 6.643790418371388e-05,
      "loss": 0.0166,
      "step": 5140
    },
    {
      "epoch": 1.0161799526440412,
      "grad_norm": 0.1419295221567154,
      "learning_rate": 6.637191500593904e-05,
      "loss": 0.0141,
      "step": 5150
    },
    {
      "epoch": 1.0181531176006313,
      "grad_norm": 0.17558859288692474,
      "learning_rate": 6.630592582816418e-05,
      "loss": 0.0214,
      "step": 5160
    },
    {
      "epoch": 1.0201262825572217,
      "grad_norm": 0.3635105490684509,
      "learning_rate": 6.623993665038934e-05,
      "loss": 0.0177,
      "step": 5170
    },
    {
      "epoch": 1.022099447513812,
      "grad_norm": 0.17826014757156372,
      "learning_rate": 6.617394747261449e-05,
      "loss": 0.0173,
      "step": 5180
    },
    {
      "epoch": 1.0240726124704025,
      "grad_norm": 0.18227951228618622,
      "learning_rate": 6.610795829483965e-05,
      "loss": 0.0211,
      "step": 5190
    },
    {
      "epoch": 1.0260457774269929,
      "grad_norm": 0.24587109684944153,
      "learning_rate": 6.604196911706481e-05,
      "loss": 0.022,
      "step": 5200
    },
    {
      "epoch": 1.0280189423835833,
      "grad_norm": 0.130339115858078,
      "learning_rate": 6.597597993928996e-05,
      "loss": 0.0151,
      "step": 5210
    },
    {
      "epoch": 1.0299921073401737,
      "grad_norm": 0.35951051115989685,
      "learning_rate": 6.590999076151512e-05,
      "loss": 0.0185,
      "step": 5220
    },
    {
      "epoch": 1.031965272296764,
      "grad_norm": 0.20183970034122467,
      "learning_rate": 6.584400158374026e-05,
      "loss": 0.0205,
      "step": 5230
    },
    {
      "epoch": 1.0339384372533544,
      "grad_norm": 0.18232132494449615,
      "learning_rate": 6.577801240596542e-05,
      "loss": 0.0134,
      "step": 5240
    },
    {
      "epoch": 1.0359116022099448,
      "grad_norm": 0.10484621673822403,
      "learning_rate": 6.571202322819058e-05,
      "loss": 0.019,
      "step": 5250
    },
    {
      "epoch": 1.0378847671665352,
      "grad_norm": 0.06465668231248856,
      "learning_rate": 6.564603405041574e-05,
      "loss": 0.0188,
      "step": 5260
    },
    {
      "epoch": 1.0398579321231254,
      "grad_norm": 0.26625025272369385,
      "learning_rate": 6.558004487264089e-05,
      "loss": 0.0189,
      "step": 5270
    },
    {
      "epoch": 1.0418310970797158,
      "grad_norm": 0.12261949479579926,
      "learning_rate": 6.551405569486605e-05,
      "loss": 0.0167,
      "step": 5280
    },
    {
      "epoch": 1.0438042620363062,
      "grad_norm": 0.19312196969985962,
      "learning_rate": 6.54480665170912e-05,
      "loss": 0.0223,
      "step": 5290
    },
    {
      "epoch": 1.0457774269928966,
      "grad_norm": 0.1666136085987091,
      "learning_rate": 6.538207733931635e-05,
      "loss": 0.0139,
      "step": 5300
    },
    {
      "epoch": 1.047750591949487,
      "grad_norm": 0.22244520485401154,
      "learning_rate": 6.531608816154151e-05,
      "loss": 0.0205,
      "step": 5310
    },
    {
      "epoch": 1.0497237569060773,
      "grad_norm": 0.2974224090576172,
      "learning_rate": 6.525009898376666e-05,
      "loss": 0.0192,
      "step": 5320
    },
    {
      "epoch": 1.0516969218626677,
      "grad_norm": 0.16541653871536255,
      "learning_rate": 6.518410980599182e-05,
      "loss": 0.0209,
      "step": 5330
    },
    {
      "epoch": 1.0536700868192581,
      "grad_norm": 0.15074005722999573,
      "learning_rate": 6.511812062821698e-05,
      "loss": 0.0211,
      "step": 5340
    },
    {
      "epoch": 1.0556432517758485,
      "grad_norm": 0.22183796763420105,
      "learning_rate": 6.505213145044214e-05,
      "loss": 0.0133,
      "step": 5350
    },
    {
      "epoch": 1.057616416732439,
      "grad_norm": 0.09842728078365326,
      "learning_rate": 6.498614227266728e-05,
      "loss": 0.0132,
      "step": 5360
    },
    {
      "epoch": 1.0595895816890293,
      "grad_norm": 0.23754650354385376,
      "learning_rate": 6.492015309489244e-05,
      "loss": 0.0194,
      "step": 5370
    },
    {
      "epoch": 1.0615627466456197,
      "grad_norm": 0.2659507691860199,
      "learning_rate": 6.485416391711759e-05,
      "loss": 0.0248,
      "step": 5380
    },
    {
      "epoch": 1.06353591160221,
      "grad_norm": 0.2901514172554016,
      "learning_rate": 6.478817473934275e-05,
      "loss": 0.0179,
      "step": 5390
    },
    {
      "epoch": 1.0655090765588002,
      "grad_norm": 0.25919365882873535,
      "learning_rate": 6.472218556156791e-05,
      "loss": 0.0138,
      "step": 5400
    },
    {
      "epoch": 1.0674822415153906,
      "grad_norm": 0.2054389864206314,
      "learning_rate": 6.465619638379307e-05,
      "loss": 0.0188,
      "step": 5410
    },
    {
      "epoch": 1.069455406471981,
      "grad_norm": 0.21316786110401154,
      "learning_rate": 6.459020720601822e-05,
      "loss": 0.0207,
      "step": 5420
    },
    {
      "epoch": 1.0714285714285714,
      "grad_norm": 0.1915712058544159,
      "learning_rate": 6.452421802824336e-05,
      "loss": 0.0183,
      "step": 5430
    },
    {
      "epoch": 1.0734017363851618,
      "grad_norm": 0.19058986008167267,
      "learning_rate": 6.445822885046852e-05,
      "loss": 0.0177,
      "step": 5440
    },
    {
      "epoch": 1.0753749013417522,
      "grad_norm": 0.2132035195827484,
      "learning_rate": 6.439223967269368e-05,
      "loss": 0.0196,
      "step": 5450
    },
    {
      "epoch": 1.0773480662983426,
      "grad_norm": 0.14368660748004913,
      "learning_rate": 6.432625049491884e-05,
      "loss": 0.0205,
      "step": 5460
    },
    {
      "epoch": 1.079321231254933,
      "grad_norm": 0.34871265292167664,
      "learning_rate": 6.426026131714399e-05,
      "loss": 0.0184,
      "step": 5470
    },
    {
      "epoch": 1.0812943962115233,
      "grad_norm": 0.16211822628974915,
      "learning_rate": 6.419427213936915e-05,
      "loss": 0.0158,
      "step": 5480
    },
    {
      "epoch": 1.0832675611681137,
      "grad_norm": 0.18465715646743774,
      "learning_rate": 6.41282829615943e-05,
      "loss": 0.0289,
      "step": 5490
    },
    {
      "epoch": 1.0852407261247041,
      "grad_norm": 0.1071409285068512,
      "learning_rate": 6.406229378381947e-05,
      "loss": 0.0268,
      "step": 5500
    },
    {
      "epoch": 1.0872138910812943,
      "grad_norm": 0.18833881616592407,
      "learning_rate": 6.399630460604461e-05,
      "loss": 0.0191,
      "step": 5510
    },
    {
      "epoch": 1.0891870560378847,
      "grad_norm": 0.19941575825214386,
      "learning_rate": 6.393031542826977e-05,
      "loss": 0.0205,
      "step": 5520
    },
    {
      "epoch": 1.091160220994475,
      "grad_norm": 0.390546977519989,
      "learning_rate": 6.386432625049492e-05,
      "loss": 0.0207,
      "step": 5530
    },
    {
      "epoch": 1.0931333859510655,
      "grad_norm": 0.10050071775913239,
      "learning_rate": 6.379833707272008e-05,
      "loss": 0.0212,
      "step": 5540
    },
    {
      "epoch": 1.0951065509076559,
      "grad_norm": 0.22585546970367432,
      "learning_rate": 6.373234789494524e-05,
      "loss": 0.0183,
      "step": 5550
    },
    {
      "epoch": 1.0970797158642462,
      "grad_norm": 0.1390571892261505,
      "learning_rate": 6.366635871717038e-05,
      "loss": 0.0128,
      "step": 5560
    },
    {
      "epoch": 1.0990528808208366,
      "grad_norm": 0.20388129353523254,
      "learning_rate": 6.360036953939554e-05,
      "loss": 0.0168,
      "step": 5570
    },
    {
      "epoch": 1.101026045777427,
      "grad_norm": 0.13569501042366028,
      "learning_rate": 6.353438036162069e-05,
      "loss": 0.0182,
      "step": 5580
    },
    {
      "epoch": 1.1029992107340174,
      "grad_norm": 0.19403482973575592,
      "learning_rate": 6.346839118384585e-05,
      "loss": 0.0162,
      "step": 5590
    },
    {
      "epoch": 1.1049723756906078,
      "grad_norm": 0.14955677092075348,
      "learning_rate": 6.340240200607101e-05,
      "loss": 0.019,
      "step": 5600
    },
    {
      "epoch": 1.1069455406471982,
      "grad_norm": 0.26341521739959717,
      "learning_rate": 6.333641282829617e-05,
      "loss": 0.0219,
      "step": 5610
    },
    {
      "epoch": 1.1089187056037886,
      "grad_norm": 0.26335060596466064,
      "learning_rate": 6.327042365052132e-05,
      "loss": 0.0179,
      "step": 5620
    },
    {
      "epoch": 1.1108918705603787,
      "grad_norm": 0.13879306614398956,
      "learning_rate": 6.320443447274648e-05,
      "loss": 0.0155,
      "step": 5630
    },
    {
      "epoch": 1.1128650355169691,
      "grad_norm": 0.18555103242397308,
      "learning_rate": 6.313844529497162e-05,
      "loss": 0.0175,
      "step": 5640
    },
    {
      "epoch": 1.1148382004735595,
      "grad_norm": 0.2170545607805252,
      "learning_rate": 6.307245611719678e-05,
      "loss": 0.0185,
      "step": 5650
    },
    {
      "epoch": 1.11681136543015,
      "grad_norm": 0.3824804127216339,
      "learning_rate": 6.300646693942194e-05,
      "loss": 0.021,
      "step": 5660
    },
    {
      "epoch": 1.1187845303867403,
      "grad_norm": 0.22550560534000397,
      "learning_rate": 6.294047776164709e-05,
      "loss": 0.0205,
      "step": 5670
    },
    {
      "epoch": 1.1207576953433307,
      "grad_norm": 0.2092662900686264,
      "learning_rate": 6.287448858387225e-05,
      "loss": 0.0203,
      "step": 5680
    },
    {
      "epoch": 1.122730860299921,
      "grad_norm": 0.14043013751506805,
      "learning_rate": 6.28084994060974e-05,
      "loss": 0.0154,
      "step": 5690
    },
    {
      "epoch": 1.1247040252565115,
      "grad_norm": 0.16021183133125305,
      "learning_rate": 6.274251022832255e-05,
      "loss": 0.0199,
      "step": 5700
    },
    {
      "epoch": 1.1266771902131019,
      "grad_norm": 0.23704616725444794,
      "learning_rate": 6.267652105054771e-05,
      "loss": 0.0168,
      "step": 5710
    },
    {
      "epoch": 1.1286503551696923,
      "grad_norm": 0.13233092427253723,
      "learning_rate": 6.261053187277287e-05,
      "loss": 0.0158,
      "step": 5720
    },
    {
      "epoch": 1.1306235201262826,
      "grad_norm": 0.10072280466556549,
      "learning_rate": 6.254454269499802e-05,
      "loss": 0.0119,
      "step": 5730
    },
    {
      "epoch": 1.132596685082873,
      "grad_norm": 0.18131770193576813,
      "learning_rate": 6.247855351722318e-05,
      "loss": 0.0148,
      "step": 5740
    },
    {
      "epoch": 1.1345698500394632,
      "grad_norm": 0.14981487393379211,
      "learning_rate": 6.241256433944833e-05,
      "loss": 0.0176,
      "step": 5750
    },
    {
      "epoch": 1.1365430149960536,
      "grad_norm": 0.17794004082679749,
      "learning_rate": 6.23465751616735e-05,
      "loss": 0.012,
      "step": 5760
    },
    {
      "epoch": 1.138516179952644,
      "grad_norm": 0.1482638269662857,
      "learning_rate": 6.228058598389865e-05,
      "loss": 0.0157,
      "step": 5770
    },
    {
      "epoch": 1.1404893449092344,
      "grad_norm": 0.08269254118204117,
      "learning_rate": 6.22145968061238e-05,
      "loss": 0.0154,
      "step": 5780
    },
    {
      "epoch": 1.1424625098658248,
      "grad_norm": 0.11689556390047073,
      "learning_rate": 6.214860762834895e-05,
      "loss": 0.0169,
      "step": 5790
    },
    {
      "epoch": 1.1444356748224151,
      "grad_norm": 0.40513521432876587,
      "learning_rate": 6.20826184505741e-05,
      "loss": 0.0213,
      "step": 5800
    },
    {
      "epoch": 1.1464088397790055,
      "grad_norm": 0.20900702476501465,
      "learning_rate": 6.201662927279927e-05,
      "loss": 0.0129,
      "step": 5810
    },
    {
      "epoch": 1.148382004735596,
      "grad_norm": 0.13154074549674988,
      "learning_rate": 6.195064009502442e-05,
      "loss": 0.0137,
      "step": 5820
    },
    {
      "epoch": 1.1503551696921863,
      "grad_norm": 0.19985276460647583,
      "learning_rate": 6.188465091724958e-05,
      "loss": 0.0237,
      "step": 5830
    },
    {
      "epoch": 1.1523283346487767,
      "grad_norm": 0.23273788392543793,
      "learning_rate": 6.181866173947472e-05,
      "loss": 0.0229,
      "step": 5840
    },
    {
      "epoch": 1.154301499605367,
      "grad_norm": 0.2574884593486786,
      "learning_rate": 6.175267256169988e-05,
      "loss": 0.0141,
      "step": 5850
    },
    {
      "epoch": 1.1562746645619573,
      "grad_norm": 0.20278725028038025,
      "learning_rate": 6.168668338392504e-05,
      "loss": 0.0192,
      "step": 5860
    },
    {
      "epoch": 1.1582478295185477,
      "grad_norm": 0.1508471518754959,
      "learning_rate": 6.16206942061502e-05,
      "loss": 0.017,
      "step": 5870
    },
    {
      "epoch": 1.160220994475138,
      "grad_norm": 0.16030019521713257,
      "learning_rate": 6.155470502837535e-05,
      "loss": 0.017,
      "step": 5880
    },
    {
      "epoch": 1.1621941594317284,
      "grad_norm": 0.16718925535678864,
      "learning_rate": 6.148871585060051e-05,
      "loss": 0.0153,
      "step": 5890
    },
    {
      "epoch": 1.1641673243883188,
      "grad_norm": 0.22913576662540436,
      "learning_rate": 6.142272667282565e-05,
      "loss": 0.0142,
      "step": 5900
    },
    {
      "epoch": 1.1661404893449092,
      "grad_norm": 0.10758921504020691,
      "learning_rate": 6.135673749505081e-05,
      "loss": 0.0143,
      "step": 5910
    },
    {
      "epoch": 1.1681136543014996,
      "grad_norm": 0.13375742733478546,
      "learning_rate": 6.129074831727597e-05,
      "loss": 0.0172,
      "step": 5920
    },
    {
      "epoch": 1.17008681925809,
      "grad_norm": 0.1401737928390503,
      "learning_rate": 6.122475913950112e-05,
      "loss": 0.0153,
      "step": 5930
    },
    {
      "epoch": 1.1720599842146804,
      "grad_norm": 0.12630856037139893,
      "learning_rate": 6.115876996172628e-05,
      "loss": 0.0134,
      "step": 5940
    },
    {
      "epoch": 1.1740331491712708,
      "grad_norm": 0.13587602972984314,
      "learning_rate": 6.109278078395143e-05,
      "loss": 0.0229,
      "step": 5950
    },
    {
      "epoch": 1.1760063141278612,
      "grad_norm": 0.04039584472775459,
      "learning_rate": 6.102679160617659e-05,
      "loss": 0.0189,
      "step": 5960
    },
    {
      "epoch": 1.1779794790844516,
      "grad_norm": 0.1621006727218628,
      "learning_rate": 6.096080242840174e-05,
      "loss": 0.0169,
      "step": 5970
    },
    {
      "epoch": 1.179952644041042,
      "grad_norm": 0.09463413804769516,
      "learning_rate": 6.0894813250626906e-05,
      "loss": 0.0118,
      "step": 5980
    },
    {
      "epoch": 1.181925808997632,
      "grad_norm": 0.16688932478427887,
      "learning_rate": 6.082882407285205e-05,
      "loss": 0.0152,
      "step": 5990
    },
    {
      "epoch": 1.1838989739542225,
      "grad_norm": 0.22635886073112488,
      "learning_rate": 6.076283489507721e-05,
      "loss": 0.0198,
      "step": 6000
    },
    {
      "epoch": 1.185872138910813,
      "grad_norm": 0.08582822978496552,
      "learning_rate": 6.0696845717302365e-05,
      "loss": 0.0141,
      "step": 6010
    },
    {
      "epoch": 1.1878453038674033,
      "grad_norm": 0.1959083378314972,
      "learning_rate": 6.0630856539527524e-05,
      "loss": 0.0125,
      "step": 6020
    },
    {
      "epoch": 1.1898184688239937,
      "grad_norm": 0.3385908305644989,
      "learning_rate": 6.056486736175268e-05,
      "loss": 0.0177,
      "step": 6030
    },
    {
      "epoch": 1.191791633780584,
      "grad_norm": 0.2249719649553299,
      "learning_rate": 6.0498878183977824e-05,
      "loss": 0.027,
      "step": 6040
    },
    {
      "epoch": 1.1937647987371744,
      "grad_norm": 0.19749002158641815,
      "learning_rate": 6.0432889006202983e-05,
      "loss": 0.0175,
      "step": 6050
    },
    {
      "epoch": 1.1957379636937648,
      "grad_norm": 0.205586239695549,
      "learning_rate": 6.0366899828428136e-05,
      "loss": 0.0224,
      "step": 6060
    },
    {
      "epoch": 1.1977111286503552,
      "grad_norm": 0.21393892168998718,
      "learning_rate": 6.0300910650653296e-05,
      "loss": 0.0173,
      "step": 6070
    },
    {
      "epoch": 1.1996842936069456,
      "grad_norm": 0.20148319005966187,
      "learning_rate": 6.023492147287845e-05,
      "loss": 0.0239,
      "step": 6080
    },
    {
      "epoch": 1.201657458563536,
      "grad_norm": 0.11657760292291641,
      "learning_rate": 6.016893229510361e-05,
      "loss": 0.0144,
      "step": 6090
    },
    {
      "epoch": 1.2036306235201262,
      "grad_norm": 0.14978040754795074,
      "learning_rate": 6.0102943117328755e-05,
      "loss": 0.0162,
      "step": 6100
    },
    {
      "epoch": 1.2056037884767166,
      "grad_norm": 0.10728719830513,
      "learning_rate": 6.003695393955392e-05,
      "loss": 0.015,
      "step": 6110
    },
    {
      "epoch": 1.207576953433307,
      "grad_norm": 0.18652817606925964,
      "learning_rate": 5.997096476177907e-05,
      "loss": 0.0154,
      "step": 6120
    },
    {
      "epoch": 1.2095501183898973,
      "grad_norm": 0.24863751232624054,
      "learning_rate": 5.990497558400423e-05,
      "loss": 0.0145,
      "step": 6130
    },
    {
      "epoch": 1.2115232833464877,
      "grad_norm": 0.12007620185613632,
      "learning_rate": 5.983898640622938e-05,
      "loss": 0.0176,
      "step": 6140
    },
    {
      "epoch": 1.2134964483030781,
      "grad_norm": 0.26116225123405457,
      "learning_rate": 5.977299722845454e-05,
      "loss": 0.0186,
      "step": 6150
    },
    {
      "epoch": 1.2154696132596685,
      "grad_norm": 0.10587169229984283,
      "learning_rate": 5.9707008050679694e-05,
      "loss": 0.0176,
      "step": 6160
    },
    {
      "epoch": 1.217442778216259,
      "grad_norm": 0.19882091879844666,
      "learning_rate": 5.964101887290484e-05,
      "loss": 0.0144,
      "step": 6170
    },
    {
      "epoch": 1.2194159431728493,
      "grad_norm": 0.2603120803833008,
      "learning_rate": 5.957502969513e-05,
      "loss": 0.014,
      "step": 6180
    },
    {
      "epoch": 1.2213891081294397,
      "grad_norm": 0.24474787712097168,
      "learning_rate": 5.950904051735515e-05,
      "loss": 0.0227,
      "step": 6190
    },
    {
      "epoch": 1.22336227308603,
      "grad_norm": 0.20104074478149414,
      "learning_rate": 5.944305133958031e-05,
      "loss": 0.0164,
      "step": 6200
    },
    {
      "epoch": 1.2253354380426202,
      "grad_norm": 0.07866887748241425,
      "learning_rate": 5.9377062161805465e-05,
      "loss": 0.0151,
      "step": 6210
    },
    {
      "epoch": 1.2273086029992109,
      "grad_norm": 0.15011762082576752,
      "learning_rate": 5.9311072984030625e-05,
      "loss": 0.0185,
      "step": 6220
    },
    {
      "epoch": 1.229281767955801,
      "grad_norm": 0.2249891608953476,
      "learning_rate": 5.924508380625577e-05,
      "loss": 0.0189,
      "step": 6230
    },
    {
      "epoch": 1.2312549329123914,
      "grad_norm": 0.16440075635910034,
      "learning_rate": 5.917909462848094e-05,
      "loss": 0.0136,
      "step": 6240
    },
    {
      "epoch": 1.2332280978689818,
      "grad_norm": 0.21917730569839478,
      "learning_rate": 5.9113105450706084e-05,
      "loss": 0.0217,
      "step": 6250
    },
    {
      "epoch": 1.2352012628255722,
      "grad_norm": 0.46802887320518494,
      "learning_rate": 5.9047116272931244e-05,
      "loss": 0.0191,
      "step": 6260
    },
    {
      "epoch": 1.2371744277821626,
      "grad_norm": 0.1411123126745224,
      "learning_rate": 5.89811270951564e-05,
      "loss": 0.0138,
      "step": 6270
    },
    {
      "epoch": 1.239147592738753,
      "grad_norm": 0.10672064870595932,
      "learning_rate": 5.891513791738156e-05,
      "loss": 0.0177,
      "step": 6280
    },
    {
      "epoch": 1.2411207576953434,
      "grad_norm": 0.1313740611076355,
      "learning_rate": 5.884914873960671e-05,
      "loss": 0.0139,
      "step": 6290
    },
    {
      "epoch": 1.2430939226519337,
      "grad_norm": 0.2512008547782898,
      "learning_rate": 5.8783159561831856e-05,
      "loss": 0.02,
      "step": 6300
    },
    {
      "epoch": 1.2450670876085241,
      "grad_norm": 0.13951677083969116,
      "learning_rate": 5.8717170384057016e-05,
      "loss": 0.0209,
      "step": 6310
    },
    {
      "epoch": 1.2470402525651145,
      "grad_norm": 0.14228445291519165,
      "learning_rate": 5.865118120628217e-05,
      "loss": 0.0259,
      "step": 6320
    },
    {
      "epoch": 1.249013417521705,
      "grad_norm": 0.12075529992580414,
      "learning_rate": 5.858519202850733e-05,
      "loss": 0.0181,
      "step": 6330
    },
    {
      "epoch": 1.250986582478295,
      "grad_norm": 0.04301771894097328,
      "learning_rate": 5.851920285073248e-05,
      "loss": 0.0177,
      "step": 6340
    },
    {
      "epoch": 1.2529597474348855,
      "grad_norm": 0.1129218190908432,
      "learning_rate": 5.845321367295764e-05,
      "loss": 0.018,
      "step": 6350
    },
    {
      "epoch": 1.2549329123914759,
      "grad_norm": 0.13449546694755554,
      "learning_rate": 5.838722449518279e-05,
      "loss": 0.0171,
      "step": 6360
    },
    {
      "epoch": 1.2569060773480663,
      "grad_norm": 0.1410660594701767,
      "learning_rate": 5.8321235317407954e-05,
      "loss": 0.0139,
      "step": 6370
    },
    {
      "epoch": 1.2588792423046566,
      "grad_norm": 0.14772270619869232,
      "learning_rate": 5.82552461396331e-05,
      "loss": 0.02,
      "step": 6380
    },
    {
      "epoch": 1.260852407261247,
      "grad_norm": 0.178181454539299,
      "learning_rate": 5.818925696185826e-05,
      "loss": 0.0173,
      "step": 6390
    },
    {
      "epoch": 1.2628255722178374,
      "grad_norm": 0.1748999059200287,
      "learning_rate": 5.812326778408341e-05,
      "loss": 0.0187,
      "step": 6400
    },
    {
      "epoch": 1.2647987371744278,
      "grad_norm": 0.31400394439697266,
      "learning_rate": 5.8057278606308566e-05,
      "loss": 0.0202,
      "step": 6410
    },
    {
      "epoch": 1.2667719021310182,
      "grad_norm": 0.21728463470935822,
      "learning_rate": 5.7991289428533726e-05,
      "loss": 0.0179,
      "step": 6420
    },
    {
      "epoch": 1.2687450670876086,
      "grad_norm": 0.14364705979824066,
      "learning_rate": 5.792530025075887e-05,
      "loss": 0.012,
      "step": 6430
    },
    {
      "epoch": 1.270718232044199,
      "grad_norm": 0.13411112129688263,
      "learning_rate": 5.785931107298403e-05,
      "loss": 0.0189,
      "step": 6440
    },
    {
      "epoch": 1.2726913970007891,
      "grad_norm": 0.04249290004372597,
      "learning_rate": 5.7793321895209185e-05,
      "loss": 0.0141,
      "step": 6450
    },
    {
      "epoch": 1.2746645619573798,
      "grad_norm": 0.15078289806842804,
      "learning_rate": 5.7727332717434344e-05,
      "loss": 0.0187,
      "step": 6460
    },
    {
      "epoch": 1.27663772691397,
      "grad_norm": 0.14622975885868073,
      "learning_rate": 5.76613435396595e-05,
      "loss": 0.0162,
      "step": 6470
    },
    {
      "epoch": 1.2786108918705603,
      "grad_norm": 0.10764865577220917,
      "learning_rate": 5.759535436188466e-05,
      "loss": 0.0173,
      "step": 6480
    },
    {
      "epoch": 1.2805840568271507,
      "grad_norm": 0.11856143176555634,
      "learning_rate": 5.752936518410981e-05,
      "loss": 0.0202,
      "step": 6490
    },
    {
      "epoch": 1.282557221783741,
      "grad_norm": 0.1449231058359146,
      "learning_rate": 5.746337600633497e-05,
      "loss": 0.021,
      "step": 6500
    },
    {
      "epoch": 1.2845303867403315,
      "grad_norm": 0.23316264152526855,
      "learning_rate": 5.7397386828560116e-05,
      "loss": 0.0162,
      "step": 6510
    },
    {
      "epoch": 1.2865035516969219,
      "grad_norm": 0.24162007868289948,
      "learning_rate": 5.7331397650785276e-05,
      "loss": 0.0214,
      "step": 6520
    },
    {
      "epoch": 1.2884767166535123,
      "grad_norm": 0.030360965058207512,
      "learning_rate": 5.726540847301043e-05,
      "loss": 0.0175,
      "step": 6530
    },
    {
      "epoch": 1.2904498816101027,
      "grad_norm": 0.10580506175756454,
      "learning_rate": 5.719941929523558e-05,
      "loss": 0.0136,
      "step": 6540
    },
    {
      "epoch": 1.292423046566693,
      "grad_norm": 0.3729129731655121,
      "learning_rate": 5.713343011746074e-05,
      "loss": 0.0118,
      "step": 6550
    },
    {
      "epoch": 1.2943962115232832,
      "grad_norm": 0.26421117782592773,
      "learning_rate": 5.706744093968589e-05,
      "loss": 0.0161,
      "step": 6560
    },
    {
      "epoch": 1.2963693764798738,
      "grad_norm": 0.07574775069952011,
      "learning_rate": 5.700145176191105e-05,
      "loss": 0.0185,
      "step": 6570
    },
    {
      "epoch": 1.298342541436464,
      "grad_norm": 0.13204535841941833,
      "learning_rate": 5.69354625841362e-05,
      "loss": 0.0152,
      "step": 6580
    },
    {
      "epoch": 1.3003157063930544,
      "grad_norm": 0.20496729016304016,
      "learning_rate": 5.686947340636136e-05,
      "loss": 0.0214,
      "step": 6590
    },
    {
      "epoch": 1.3022888713496448,
      "grad_norm": 0.10965285450220108,
      "learning_rate": 5.6803484228586514e-05,
      "loss": 0.0196,
      "step": 6600
    },
    {
      "epoch": 1.3042620363062352,
      "grad_norm": 0.15029245615005493,
      "learning_rate": 5.673749505081167e-05,
      "loss": 0.0234,
      "step": 6610
    },
    {
      "epoch": 1.3062352012628256,
      "grad_norm": 0.22010798752307892,
      "learning_rate": 5.6671505873036826e-05,
      "loss": 0.0186,
      "step": 6620
    },
    {
      "epoch": 1.308208366219416,
      "grad_norm": 0.16313225030899048,
      "learning_rate": 5.6605516695261986e-05,
      "loss": 0.0181,
      "step": 6630
    },
    {
      "epoch": 1.3101815311760063,
      "grad_norm": 0.0840672180056572,
      "learning_rate": 5.653952751748713e-05,
      "loss": 0.0125,
      "step": 6640
    },
    {
      "epoch": 1.3121546961325967,
      "grad_norm": 0.2807483971118927,
      "learning_rate": 5.647353833971229e-05,
      "loss": 0.0172,
      "step": 6650
    },
    {
      "epoch": 1.314127861089187,
      "grad_norm": 0.20689593255519867,
      "learning_rate": 5.6407549161937445e-05,
      "loss": 0.0227,
      "step": 6660
    },
    {
      "epoch": 1.3161010260457775,
      "grad_norm": 0.04829149693250656,
      "learning_rate": 5.63415599841626e-05,
      "loss": 0.0177,
      "step": 6670
    },
    {
      "epoch": 1.318074191002368,
      "grad_norm": 0.1047438532114029,
      "learning_rate": 5.627557080638776e-05,
      "loss": 0.0201,
      "step": 6680
    },
    {
      "epoch": 1.320047355958958,
      "grad_norm": 0.15969444811344147,
      "learning_rate": 5.6209581628612904e-05,
      "loss": 0.0184,
      "step": 6690
    },
    {
      "epoch": 1.3220205209155487,
      "grad_norm": 0.18457184731960297,
      "learning_rate": 5.614359245083807e-05,
      "loss": 0.0169,
      "step": 6700
    },
    {
      "epoch": 1.3239936858721388,
      "grad_norm": 0.13132181763648987,
      "learning_rate": 5.607760327306322e-05,
      "loss": 0.0125,
      "step": 6710
    },
    {
      "epoch": 1.3259668508287292,
      "grad_norm": 0.10606645047664642,
      "learning_rate": 5.601161409528838e-05,
      "loss": 0.0133,
      "step": 6720
    },
    {
      "epoch": 1.3279400157853196,
      "grad_norm": 0.12792083621025085,
      "learning_rate": 5.594562491751353e-05,
      "loss": 0.021,
      "step": 6730
    },
    {
      "epoch": 1.32991318074191,
      "grad_norm": 0.17040716111660004,
      "learning_rate": 5.587963573973869e-05,
      "loss": 0.0211,
      "step": 6740
    },
    {
      "epoch": 1.3318863456985004,
      "grad_norm": 0.08612199872732162,
      "learning_rate": 5.581364656196384e-05,
      "loss": 0.0205,
      "step": 6750
    },
    {
      "epoch": 1.3338595106550908,
      "grad_norm": 0.22402843832969666,
      "learning_rate": 5.5747657384189e-05,
      "loss": 0.0202,
      "step": 6760
    },
    {
      "epoch": 1.3358326756116812,
      "grad_norm": 0.43701738119125366,
      "learning_rate": 5.568166820641415e-05,
      "loss": 0.022,
      "step": 6770
    },
    {
      "epoch": 1.3378058405682716,
      "grad_norm": 0.11496024578809738,
      "learning_rate": 5.56156790286393e-05,
      "loss": 0.0104,
      "step": 6780
    },
    {
      "epoch": 1.339779005524862,
      "grad_norm": 0.20403391122817993,
      "learning_rate": 5.554968985086446e-05,
      "loss": 0.017,
      "step": 6790
    },
    {
      "epoch": 1.3417521704814521,
      "grad_norm": 0.21558046340942383,
      "learning_rate": 5.5483700673089614e-05,
      "loss": 0.0174,
      "step": 6800
    },
    {
      "epoch": 1.3437253354380427,
      "grad_norm": 0.27253004908561707,
      "learning_rate": 5.5417711495314774e-05,
      "loss": 0.0173,
      "step": 6810
    },
    {
      "epoch": 1.345698500394633,
      "grad_norm": 0.14506125450134277,
      "learning_rate": 5.535172231753992e-05,
      "loss": 0.016,
      "step": 6820
    },
    {
      "epoch": 1.3476716653512233,
      "grad_norm": 0.17486710846424103,
      "learning_rate": 5.528573313976509e-05,
      "loss": 0.0159,
      "step": 6830
    },
    {
      "epoch": 1.3496448303078137,
      "grad_norm": 0.21953502297401428,
      "learning_rate": 5.521974396199023e-05,
      "loss": 0.0157,
      "step": 6840
    },
    {
      "epoch": 1.351617995264404,
      "grad_norm": 0.06531253457069397,
      "learning_rate": 5.515375478421539e-05,
      "loss": 0.0114,
      "step": 6850
    },
    {
      "epoch": 1.3535911602209945,
      "grad_norm": 0.12511202692985535,
      "learning_rate": 5.5087765606440546e-05,
      "loss": 0.0135,
      "step": 6860
    },
    {
      "epoch": 1.3555643251775849,
      "grad_norm": 0.11062365770339966,
      "learning_rate": 5.5021776428665705e-05,
      "loss": 0.0155,
      "step": 6870
    },
    {
      "epoch": 1.3575374901341752,
      "grad_norm": 0.15132777392864227,
      "learning_rate": 5.495578725089086e-05,
      "loss": 0.0128,
      "step": 6880
    },
    {
      "epoch": 1.3595106550907656,
      "grad_norm": 0.2452412098646164,
      "learning_rate": 5.488979807311602e-05,
      "loss": 0.0174,
      "step": 6890
    },
    {
      "epoch": 1.361483820047356,
      "grad_norm": 0.1616220921278,
      "learning_rate": 5.4823808895341164e-05,
      "loss": 0.0225,
      "step": 6900
    },
    {
      "epoch": 1.3634569850039464,
      "grad_norm": 0.14593705534934998,
      "learning_rate": 5.475781971756632e-05,
      "loss": 0.0244,
      "step": 6910
    },
    {
      "epoch": 1.3654301499605368,
      "grad_norm": 0.29563552141189575,
      "learning_rate": 5.469183053979148e-05,
      "loss": 0.0209,
      "step": 6920
    },
    {
      "epoch": 1.367403314917127,
      "grad_norm": 0.05972321704030037,
      "learning_rate": 5.462584136201663e-05,
      "loss": 0.0113,
      "step": 6930
    },
    {
      "epoch": 1.3693764798737176,
      "grad_norm": 0.09725983440876007,
      "learning_rate": 5.455985218424179e-05,
      "loss": 0.0197,
      "step": 6940
    },
    {
      "epoch": 1.3713496448303077,
      "grad_norm": 0.17382396757602692,
      "learning_rate": 5.4493863006466936e-05,
      "loss": 0.0154,
      "step": 6950
    },
    {
      "epoch": 1.3733228097868981,
      "grad_norm": 0.14972510933876038,
      "learning_rate": 5.44278738286921e-05,
      "loss": 0.017,
      "step": 6960
    },
    {
      "epoch": 1.3752959747434885,
      "grad_norm": 0.3150089681148529,
      "learning_rate": 5.436188465091725e-05,
      "loss": 0.0224,
      "step": 6970
    },
    {
      "epoch": 1.377269139700079,
      "grad_norm": 0.1560102105140686,
      "learning_rate": 5.429589547314241e-05,
      "loss": 0.0234,
      "step": 6980
    },
    {
      "epoch": 1.3792423046566693,
      "grad_norm": 0.1457483321428299,
      "learning_rate": 5.422990629536756e-05,
      "loss": 0.0124,
      "step": 6990
    },
    {
      "epoch": 1.3812154696132597,
      "grad_norm": 0.37355488538742065,
      "learning_rate": 5.416391711759272e-05,
      "loss": 0.0256,
      "step": 7000
    },
    {
      "epoch": 1.38318863456985,
      "grad_norm": 0.23217369616031647,
      "learning_rate": 5.4097927939817875e-05,
      "loss": 0.0165,
      "step": 7010
    },
    {
      "epoch": 1.3851617995264405,
      "grad_norm": 0.17656724154949188,
      "learning_rate": 5.4031938762043034e-05,
      "loss": 0.0165,
      "step": 7020
    },
    {
      "epoch": 1.3871349644830309,
      "grad_norm": 0.08372676372528076,
      "learning_rate": 5.396594958426818e-05,
      "loss": 0.0134,
      "step": 7030
    },
    {
      "epoch": 1.389108129439621,
      "grad_norm": 0.21015438437461853,
      "learning_rate": 5.3899960406493334e-05,
      "loss": 0.0183,
      "step": 7040
    },
    {
      "epoch": 1.3910812943962116,
      "grad_norm": 0.2871088981628418,
      "learning_rate": 5.383397122871849e-05,
      "loss": 0.0181,
      "step": 7050
    },
    {
      "epoch": 1.3930544593528018,
      "grad_norm": 0.15019305050373077,
      "learning_rate": 5.3767982050943646e-05,
      "loss": 0.0145,
      "step": 7060
    },
    {
      "epoch": 1.3950276243093922,
      "grad_norm": 0.24211038649082184,
      "learning_rate": 5.3701992873168806e-05,
      "loss": 0.0165,
      "step": 7070
    },
    {
      "epoch": 1.3970007892659826,
      "grad_norm": 0.14897066354751587,
      "learning_rate": 5.363600369539395e-05,
      "loss": 0.0176,
      "step": 7080
    },
    {
      "epoch": 1.398973954222573,
      "grad_norm": 0.21671448647975922,
      "learning_rate": 5.357001451761912e-05,
      "loss": 0.017,
      "step": 7090
    },
    {
      "epoch": 1.4009471191791634,
      "grad_norm": 0.15568742156028748,
      "learning_rate": 5.3504025339844265e-05,
      "loss": 0.0141,
      "step": 7100
    },
    {
      "epoch": 1.4029202841357538,
      "grad_norm": 0.13650235533714294,
      "learning_rate": 5.3438036162069425e-05,
      "loss": 0.0138,
      "step": 7110
    },
    {
      "epoch": 1.4048934490923441,
      "grad_norm": 0.3400604724884033,
      "learning_rate": 5.337204698429458e-05,
      "loss": 0.0209,
      "step": 7120
    },
    {
      "epoch": 1.4068666140489345,
      "grad_norm": 0.14811739325523376,
      "learning_rate": 5.330605780651974e-05,
      "loss": 0.0273,
      "step": 7130
    },
    {
      "epoch": 1.408839779005525,
      "grad_norm": 0.09886712580919266,
      "learning_rate": 5.324006862874489e-05,
      "loss": 0.0146,
      "step": 7140
    },
    {
      "epoch": 1.410812943962115,
      "grad_norm": 0.16548535227775574,
      "learning_rate": 5.317407945097004e-05,
      "loss": 0.0198,
      "step": 7150
    },
    {
      "epoch": 1.4127861089187057,
      "grad_norm": 0.1534450799226761,
      "learning_rate": 5.3108090273195197e-05,
      "loss": 0.0268,
      "step": 7160
    },
    {
      "epoch": 1.4147592738752959,
      "grad_norm": 0.18120945990085602,
      "learning_rate": 5.304210109542035e-05,
      "loss": 0.0211,
      "step": 7170
    },
    {
      "epoch": 1.4167324388318863,
      "grad_norm": 0.3450765609741211,
      "learning_rate": 5.297611191764551e-05,
      "loss": 0.0128,
      "step": 7180
    },
    {
      "epoch": 1.4187056037884767,
      "grad_norm": 0.2696066200733185,
      "learning_rate": 5.291012273987066e-05,
      "loss": 0.0152,
      "step": 7190
    },
    {
      "epoch": 1.420678768745067,
      "grad_norm": 0.10118424147367477,
      "learning_rate": 5.284413356209582e-05,
      "loss": 0.0173,
      "step": 7200
    },
    {
      "epoch": 1.4226519337016574,
      "grad_norm": 0.11578891426324844,
      "learning_rate": 5.277814438432097e-05,
      "loss": 0.0172,
      "step": 7210
    },
    {
      "epoch": 1.4246250986582478,
      "grad_norm": 0.14117714762687683,
      "learning_rate": 5.2712155206546135e-05,
      "loss": 0.014,
      "step": 7220
    },
    {
      "epoch": 1.4265982636148382,
      "grad_norm": 0.2016008496284485,
      "learning_rate": 5.264616602877128e-05,
      "loss": 0.0244,
      "step": 7230
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.2692916691303253,
      "learning_rate": 5.258017685099644e-05,
      "loss": 0.0157,
      "step": 7240
    },
    {
      "epoch": 1.430544593528019,
      "grad_norm": 0.13730555772781372,
      "learning_rate": 5.2514187673221594e-05,
      "loss": 0.0128,
      "step": 7250
    },
    {
      "epoch": 1.4325177584846094,
      "grad_norm": 0.5110456943511963,
      "learning_rate": 5.2448198495446754e-05,
      "loss": 0.0162,
      "step": 7260
    },
    {
      "epoch": 1.4344909234411998,
      "grad_norm": 0.22653986513614655,
      "learning_rate": 5.238220931767191e-05,
      "loss": 0.017,
      "step": 7270
    },
    {
      "epoch": 1.43646408839779,
      "grad_norm": 0.09153801202774048,
      "learning_rate": 5.231622013989705e-05,
      "loss": 0.0191,
      "step": 7280
    },
    {
      "epoch": 1.4384372533543806,
      "grad_norm": 0.15610472857952118,
      "learning_rate": 5.225023096212221e-05,
      "loss": 0.0192,
      "step": 7290
    },
    {
      "epoch": 1.4404104183109707,
      "grad_norm": 0.3756570518016815,
      "learning_rate": 5.2184241784347366e-05,
      "loss": 0.0204,
      "step": 7300
    },
    {
      "epoch": 1.442383583267561,
      "grad_norm": 0.21239367127418518,
      "learning_rate": 5.2118252606572525e-05,
      "loss": 0.0159,
      "step": 7310
    },
    {
      "epoch": 1.4443567482241515,
      "grad_norm": 0.07697591185569763,
      "learning_rate": 5.205226342879768e-05,
      "loss": 0.0171,
      "step": 7320
    },
    {
      "epoch": 1.4463299131807419,
      "grad_norm": 0.1302700638771057,
      "learning_rate": 5.198627425102284e-05,
      "loss": 0.0252,
      "step": 7330
    },
    {
      "epoch": 1.4483030781373323,
      "grad_norm": 0.09849581122398376,
      "learning_rate": 5.1920285073247984e-05,
      "loss": 0.0143,
      "step": 7340
    },
    {
      "epoch": 1.4502762430939227,
      "grad_norm": 0.20499752461910248,
      "learning_rate": 5.185429589547315e-05,
      "loss": 0.0152,
      "step": 7350
    },
    {
      "epoch": 1.452249408050513,
      "grad_norm": 0.2842726409435272,
      "learning_rate": 5.17883067176983e-05,
      "loss": 0.0151,
      "step": 7360
    },
    {
      "epoch": 1.4542225730071034,
      "grad_norm": 0.18161584436893463,
      "learning_rate": 5.172231753992346e-05,
      "loss": 0.0154,
      "step": 7370
    },
    {
      "epoch": 1.4561957379636938,
      "grad_norm": 0.14744745194911957,
      "learning_rate": 5.165632836214861e-05,
      "loss": 0.0178,
      "step": 7380
    },
    {
      "epoch": 1.458168902920284,
      "grad_norm": 0.07334057986736298,
      "learning_rate": 5.159033918437377e-05,
      "loss": 0.0179,
      "step": 7390
    },
    {
      "epoch": 1.4601420678768746,
      "grad_norm": 0.20346905291080475,
      "learning_rate": 5.152435000659892e-05,
      "loss": 0.0121,
      "step": 7400
    },
    {
      "epoch": 1.4621152328334648,
      "grad_norm": 0.2886085510253906,
      "learning_rate": 5.145836082882407e-05,
      "loss": 0.0212,
      "step": 7410
    },
    {
      "epoch": 1.4640883977900552,
      "grad_norm": 0.16880379617214203,
      "learning_rate": 5.139237165104923e-05,
      "loss": 0.0146,
      "step": 7420
    },
    {
      "epoch": 1.4660615627466456,
      "grad_norm": 0.13712434470653534,
      "learning_rate": 5.132638247327438e-05,
      "loss": 0.0142,
      "step": 7430
    },
    {
      "epoch": 1.468034727703236,
      "grad_norm": 0.1727093607187271,
      "learning_rate": 5.126039329549954e-05,
      "loss": 0.0136,
      "step": 7440
    },
    {
      "epoch": 1.4700078926598263,
      "grad_norm": 0.2302297204732895,
      "learning_rate": 5.1194404117724695e-05,
      "loss": 0.0118,
      "step": 7450
    },
    {
      "epoch": 1.4719810576164167,
      "grad_norm": 0.1407134085893631,
      "learning_rate": 5.1128414939949854e-05,
      "loss": 0.0128,
      "step": 7460
    },
    {
      "epoch": 1.4739542225730071,
      "grad_norm": 0.1006166934967041,
      "learning_rate": 5.1062425762175e-05,
      "loss": 0.0179,
      "step": 7470
    },
    {
      "epoch": 1.4759273875295975,
      "grad_norm": 0.1722760945558548,
      "learning_rate": 5.099643658440017e-05,
      "loss": 0.0201,
      "step": 7480
    },
    {
      "epoch": 1.477900552486188,
      "grad_norm": 0.1693049818277359,
      "learning_rate": 5.093044740662531e-05,
      "loss": 0.0177,
      "step": 7490
    },
    {
      "epoch": 1.4798737174427783,
      "grad_norm": 0.31900808215141296,
      "learning_rate": 5.086445822885047e-05,
      "loss": 0.0178,
      "step": 7500
    },
    {
      "epoch": 1.4798737174427783,
      "eval_loss": 0.01733010821044445,
      "eval_runtime": 78.3917,
      "eval_samples_per_second": 14.377,
      "eval_steps_per_second": 7.195,
      "step": 7500
    },
    {
      "epoch": 1.4818468823993687,
      "grad_norm": 0.21145275235176086,
      "learning_rate": 5.0798469051075626e-05,
      "loss": 0.0206,
      "step": 7510
    },
    {
      "epoch": 1.4838200473559588,
      "grad_norm": 0.19326423108577728,
      "learning_rate": 5.073247987330077e-05,
      "loss": 0.0187,
      "step": 7520
    },
    {
      "epoch": 1.4857932123125495,
      "grad_norm": 0.16479268670082092,
      "learning_rate": 5.066649069552594e-05,
      "loss": 0.0129,
      "step": 7530
    },
    {
      "epoch": 1.4877663772691396,
      "grad_norm": 0.23112282156944275,
      "learning_rate": 5.0600501517751085e-05,
      "loss": 0.0181,
      "step": 7540
    },
    {
      "epoch": 1.48973954222573,
      "grad_norm": 0.1787862330675125,
      "learning_rate": 5.0534512339976245e-05,
      "loss": 0.0118,
      "step": 7550
    },
    {
      "epoch": 1.4917127071823204,
      "grad_norm": 0.2419169396162033,
      "learning_rate": 5.04685231622014e-05,
      "loss": 0.0182,
      "step": 7560
    },
    {
      "epoch": 1.4936858721389108,
      "grad_norm": 0.19510209560394287,
      "learning_rate": 5.040253398442656e-05,
      "loss": 0.0173,
      "step": 7570
    },
    {
      "epoch": 1.4956590370955012,
      "grad_norm": 0.269802063703537,
      "learning_rate": 5.033654480665171e-05,
      "loss": 0.0185,
      "step": 7580
    },
    {
      "epoch": 1.4976322020520916,
      "grad_norm": 0.14478234946727753,
      "learning_rate": 5.027055562887687e-05,
      "loss": 0.0135,
      "step": 7590
    },
    {
      "epoch": 1.499605367008682,
      "grad_norm": 0.22629380226135254,
      "learning_rate": 5.0204566451102017e-05,
      "loss": 0.0204,
      "step": 7600
    },
    {
      "epoch": 1.5015785319652721,
      "grad_norm": 0.14164836704730988,
      "learning_rate": 5.013857727332718e-05,
      "loss": 0.0235,
      "step": 7610
    },
    {
      "epoch": 1.5035516969218627,
      "grad_norm": 0.24296122789382935,
      "learning_rate": 5.007258809555233e-05,
      "loss": 0.015,
      "step": 7620
    },
    {
      "epoch": 1.505524861878453,
      "grad_norm": 0.17098674178123474,
      "learning_rate": 5.000659891777749e-05,
      "loss": 0.0135,
      "step": 7630
    },
    {
      "epoch": 1.5074980268350435,
      "grad_norm": 0.07477404922246933,
      "learning_rate": 4.994060974000264e-05,
      "loss": 0.0126,
      "step": 7640
    },
    {
      "epoch": 1.5094711917916337,
      "grad_norm": 0.13015064597129822,
      "learning_rate": 4.9874620562227795e-05,
      "loss": 0.0147,
      "step": 7650
    },
    {
      "epoch": 1.5114443567482243,
      "grad_norm": 0.272216260433197,
      "learning_rate": 4.9808631384452955e-05,
      "loss": 0.0152,
      "step": 7660
    },
    {
      "epoch": 1.5134175217048145,
      "grad_norm": 0.14215518534183502,
      "learning_rate": 4.974264220667811e-05,
      "loss": 0.0156,
      "step": 7670
    },
    {
      "epoch": 1.5153906866614049,
      "grad_norm": 0.2725718915462494,
      "learning_rate": 4.967665302890326e-05,
      "loss": 0.013,
      "step": 7680
    },
    {
      "epoch": 1.5173638516179953,
      "grad_norm": 0.20790664851665497,
      "learning_rate": 4.961066385112842e-05,
      "loss": 0.021,
      "step": 7690
    },
    {
      "epoch": 1.5193370165745856,
      "grad_norm": 0.20989830791950226,
      "learning_rate": 4.9544674673353574e-05,
      "loss": 0.023,
      "step": 7700
    },
    {
      "epoch": 1.521310181531176,
      "grad_norm": 0.21244008839130402,
      "learning_rate": 4.947868549557873e-05,
      "loss": 0.0215,
      "step": 7710
    },
    {
      "epoch": 1.5232833464877664,
      "grad_norm": 0.20573337376117706,
      "learning_rate": 4.941269631780388e-05,
      "loss": 0.0135,
      "step": 7720
    },
    {
      "epoch": 1.5252565114443568,
      "grad_norm": 0.158193439245224,
      "learning_rate": 4.934670714002903e-05,
      "loss": 0.0158,
      "step": 7730
    },
    {
      "epoch": 1.527229676400947,
      "grad_norm": 0.2395699918270111,
      "learning_rate": 4.928071796225419e-05,
      "loss": 0.0211,
      "step": 7740
    },
    {
      "epoch": 1.5292028413575376,
      "grad_norm": 0.14730875194072723,
      "learning_rate": 4.9214728784479345e-05,
      "loss": 0.0117,
      "step": 7750
    },
    {
      "epoch": 1.5311760063141278,
      "grad_norm": 0.15228301286697388,
      "learning_rate": 4.9148739606704505e-05,
      "loss": 0.0198,
      "step": 7760
    },
    {
      "epoch": 1.5331491712707184,
      "grad_norm": 0.16919296979904175,
      "learning_rate": 4.908275042892966e-05,
      "loss": 0.0191,
      "step": 7770
    },
    {
      "epoch": 1.5351223362273085,
      "grad_norm": 0.06676816940307617,
      "learning_rate": 4.901676125115481e-05,
      "loss": 0.016,
      "step": 7780
    },
    {
      "epoch": 1.537095501183899,
      "grad_norm": 0.23934639990329742,
      "learning_rate": 4.895077207337997e-05,
      "loss": 0.0159,
      "step": 7790
    },
    {
      "epoch": 1.5390686661404893,
      "grad_norm": 0.12254834920167923,
      "learning_rate": 4.8884782895605124e-05,
      "loss": 0.0154,
      "step": 7800
    },
    {
      "epoch": 1.5410418310970797,
      "grad_norm": 0.15905730426311493,
      "learning_rate": 4.881879371783028e-05,
      "loss": 0.0165,
      "step": 7810
    },
    {
      "epoch": 1.54301499605367,
      "grad_norm": 0.3348362147808075,
      "learning_rate": 4.875280454005544e-05,
      "loss": 0.0184,
      "step": 7820
    },
    {
      "epoch": 1.5449881610102605,
      "grad_norm": 0.13979405164718628,
      "learning_rate": 4.868681536228058e-05,
      "loss": 0.013,
      "step": 7830
    },
    {
      "epoch": 1.5469613259668509,
      "grad_norm": 0.21831141412258148,
      "learning_rate": 4.862082618450574e-05,
      "loss": 0.0121,
      "step": 7840
    },
    {
      "epoch": 1.548934490923441,
      "grad_norm": 0.16945984959602356,
      "learning_rate": 4.8554837006730896e-05,
      "loss": 0.0122,
      "step": 7850
    },
    {
      "epoch": 1.5509076558800317,
      "grad_norm": 0.16149647533893585,
      "learning_rate": 4.8488847828956056e-05,
      "loss": 0.0146,
      "step": 7860
    },
    {
      "epoch": 1.5528808208366218,
      "grad_norm": 0.0818111002445221,
      "learning_rate": 4.842285865118121e-05,
      "loss": 0.0094,
      "step": 7870
    },
    {
      "epoch": 1.5548539857932124,
      "grad_norm": 0.18410055339336395,
      "learning_rate": 4.835686947340636e-05,
      "loss": 0.0147,
      "step": 7880
    },
    {
      "epoch": 1.5568271507498026,
      "grad_norm": 0.10335968434810638,
      "learning_rate": 4.829088029563152e-05,
      "loss": 0.0235,
      "step": 7890
    },
    {
      "epoch": 1.5588003157063932,
      "grad_norm": 0.20418378710746765,
      "learning_rate": 4.8224891117856674e-05,
      "loss": 0.0146,
      "step": 7900
    },
    {
      "epoch": 1.5607734806629834,
      "grad_norm": 0.10502661019563675,
      "learning_rate": 4.815890194008183e-05,
      "loss": 0.0178,
      "step": 7910
    },
    {
      "epoch": 1.5627466456195738,
      "grad_norm": 0.11296495795249939,
      "learning_rate": 4.809291276230699e-05,
      "loss": 0.0113,
      "step": 7920
    },
    {
      "epoch": 1.5647198105761642,
      "grad_norm": 0.2869780659675598,
      "learning_rate": 4.802692358453214e-05,
      "loss": 0.0144,
      "step": 7930
    },
    {
      "epoch": 1.5666929755327546,
      "grad_norm": 0.3381222188472748,
      "learning_rate": 4.796093440675729e-05,
      "loss": 0.0183,
      "step": 7940
    },
    {
      "epoch": 1.568666140489345,
      "grad_norm": 0.16065393388271332,
      "learning_rate": 4.789494522898245e-05,
      "loss": 0.0151,
      "step": 7950
    },
    {
      "epoch": 1.5706393054459353,
      "grad_norm": 0.18400318920612335,
      "learning_rate": 4.78289560512076e-05,
      "loss": 0.0156,
      "step": 7960
    },
    {
      "epoch": 1.5726124704025257,
      "grad_norm": 0.17509889602661133,
      "learning_rate": 4.776296687343276e-05,
      "loss": 0.012,
      "step": 7970
    },
    {
      "epoch": 1.5745856353591159,
      "grad_norm": 0.19748222827911377,
      "learning_rate": 4.769697769565791e-05,
      "loss": 0.021,
      "step": 7980
    },
    {
      "epoch": 1.5765588003157065,
      "grad_norm": 0.17683550715446472,
      "learning_rate": 4.763098851788307e-05,
      "loss": 0.0151,
      "step": 7990
    },
    {
      "epoch": 1.5785319652722967,
      "grad_norm": 0.19695526361465454,
      "learning_rate": 4.7564999340108225e-05,
      "loss": 0.0156,
      "step": 8000
    },
    {
      "epoch": 1.5805051302288873,
      "grad_norm": 0.18323341012001038,
      "learning_rate": 4.749901016233338e-05,
      "loss": 0.011,
      "step": 8010
    },
    {
      "epoch": 1.5824782951854774,
      "grad_norm": 0.14530353248119354,
      "learning_rate": 4.743302098455854e-05,
      "loss": 0.0149,
      "step": 8020
    },
    {
      "epoch": 1.5844514601420678,
      "grad_norm": 0.13601748645305634,
      "learning_rate": 4.736703180678369e-05,
      "loss": 0.0129,
      "step": 8030
    },
    {
      "epoch": 1.5864246250986582,
      "grad_norm": 0.14940804243087769,
      "learning_rate": 4.730104262900884e-05,
      "loss": 0.0179,
      "step": 8040
    },
    {
      "epoch": 1.5883977900552486,
      "grad_norm": 0.1917588859796524,
      "learning_rate": 4.7235053451234e-05,
      "loss": 0.0172,
      "step": 8050
    },
    {
      "epoch": 1.590370955011839,
      "grad_norm": 0.10866145044565201,
      "learning_rate": 4.7169064273459156e-05,
      "loss": 0.021,
      "step": 8060
    },
    {
      "epoch": 1.5923441199684294,
      "grad_norm": 0.148296520113945,
      "learning_rate": 4.7103075095684316e-05,
      "loss": 0.0139,
      "step": 8070
    },
    {
      "epoch": 1.5943172849250198,
      "grad_norm": 0.01399147417396307,
      "learning_rate": 4.703708591790946e-05,
      "loss": 0.0172,
      "step": 8080
    },
    {
      "epoch": 1.59629044988161,
      "grad_norm": 0.13064682483673096,
      "learning_rate": 4.6971096740134615e-05,
      "loss": 0.0124,
      "step": 8090
    },
    {
      "epoch": 1.5982636148382006,
      "grad_norm": 0.06869596987962723,
      "learning_rate": 4.6905107562359775e-05,
      "loss": 0.0171,
      "step": 8100
    },
    {
      "epoch": 1.6002367797947907,
      "grad_norm": 0.24870234727859497,
      "learning_rate": 4.683911838458493e-05,
      "loss": 0.0268,
      "step": 8110
    },
    {
      "epoch": 1.6022099447513813,
      "grad_norm": 0.1938718557357788,
      "learning_rate": 4.677312920681009e-05,
      "loss": 0.0186,
      "step": 8120
    },
    {
      "epoch": 1.6041831097079715,
      "grad_norm": 0.3024370074272156,
      "learning_rate": 4.670714002903524e-05,
      "loss": 0.0171,
      "step": 8130
    },
    {
      "epoch": 1.6061562746645621,
      "grad_norm": 0.15973669290542603,
      "learning_rate": 4.6641150851260394e-05,
      "loss": 0.0133,
      "step": 8140
    },
    {
      "epoch": 1.6081294396211523,
      "grad_norm": 0.20560505986213684,
      "learning_rate": 4.6575161673485553e-05,
      "loss": 0.0131,
      "step": 8150
    },
    {
      "epoch": 1.6101026045777427,
      "grad_norm": 0.13004226982593536,
      "learning_rate": 4.6509172495710706e-05,
      "loss": 0.0174,
      "step": 8160
    },
    {
      "epoch": 1.612075769534333,
      "grad_norm": 0.21832865476608276,
      "learning_rate": 4.644318331793586e-05,
      "loss": 0.0233,
      "step": 8170
    },
    {
      "epoch": 1.6140489344909235,
      "grad_norm": 0.21326182782649994,
      "learning_rate": 4.637719414016102e-05,
      "loss": 0.0218,
      "step": 8180
    },
    {
      "epoch": 1.6160220994475138,
      "grad_norm": 0.2670675218105316,
      "learning_rate": 4.631120496238617e-05,
      "loss": 0.0179,
      "step": 8190
    },
    {
      "epoch": 1.617995264404104,
      "grad_norm": 0.27259063720703125,
      "learning_rate": 4.6245215784611325e-05,
      "loss": 0.0166,
      "step": 8200
    },
    {
      "epoch": 1.6199684293606946,
      "grad_norm": 0.06055158004164696,
      "learning_rate": 4.617922660683648e-05,
      "loss": 0.0225,
      "step": 8210
    },
    {
      "epoch": 1.6219415943172848,
      "grad_norm": 0.12066635489463806,
      "learning_rate": 4.611323742906163e-05,
      "loss": 0.0143,
      "step": 8220
    },
    {
      "epoch": 1.6239147592738754,
      "grad_norm": 0.22100552916526794,
      "learning_rate": 4.604724825128679e-05,
      "loss": 0.0208,
      "step": 8230
    },
    {
      "epoch": 1.6258879242304656,
      "grad_norm": 0.22464948892593384,
      "learning_rate": 4.5981259073511944e-05,
      "loss": 0.0172,
      "step": 8240
    },
    {
      "epoch": 1.6278610891870562,
      "grad_norm": 0.2765127420425415,
      "learning_rate": 4.5915269895737104e-05,
      "loss": 0.0182,
      "step": 8250
    },
    {
      "epoch": 1.6298342541436464,
      "grad_norm": 0.18829898536205292,
      "learning_rate": 4.584928071796226e-05,
      "loss": 0.0113,
      "step": 8260
    },
    {
      "epoch": 1.6318074191002367,
      "grad_norm": 0.26682114601135254,
      "learning_rate": 4.578329154018741e-05,
      "loss": 0.0151,
      "step": 8270
    },
    {
      "epoch": 1.6337805840568271,
      "grad_norm": 0.12315364181995392,
      "learning_rate": 4.571730236241257e-05,
      "loss": 0.0203,
      "step": 8280
    },
    {
      "epoch": 1.6357537490134175,
      "grad_norm": 0.19532594084739685,
      "learning_rate": 4.565131318463772e-05,
      "loss": 0.0141,
      "step": 8290
    },
    {
      "epoch": 1.637726913970008,
      "grad_norm": 0.1981206089258194,
      "learning_rate": 4.5585324006862875e-05,
      "loss": 0.0195,
      "step": 8300
    },
    {
      "epoch": 1.6397000789265983,
      "grad_norm": 0.19446110725402832,
      "learning_rate": 4.5519334829088035e-05,
      "loss": 0.0135,
      "step": 8310
    },
    {
      "epoch": 1.6416732438831887,
      "grad_norm": 0.02200166881084442,
      "learning_rate": 4.545334565131319e-05,
      "loss": 0.0154,
      "step": 8320
    },
    {
      "epoch": 1.6436464088397789,
      "grad_norm": 0.17979906499385834,
      "learning_rate": 4.538735647353834e-05,
      "loss": 0.0179,
      "step": 8330
    },
    {
      "epoch": 1.6456195737963695,
      "grad_norm": 0.06530388444662094,
      "learning_rate": 4.5321367295763494e-05,
      "loss": 0.0163,
      "step": 8340
    },
    {
      "epoch": 1.6475927387529596,
      "grad_norm": 0.1310221552848816,
      "learning_rate": 4.525537811798865e-05,
      "loss": 0.0107,
      "step": 8350
    },
    {
      "epoch": 1.6495659037095503,
      "grad_norm": 0.2616969645023346,
      "learning_rate": 4.518938894021381e-05,
      "loss": 0.0193,
      "step": 8360
    },
    {
      "epoch": 1.6515390686661404,
      "grad_norm": 0.13162167370319366,
      "learning_rate": 4.512339976243896e-05,
      "loss": 0.0169,
      "step": 8370
    },
    {
      "epoch": 1.6535122336227308,
      "grad_norm": 0.18138009309768677,
      "learning_rate": 4.505741058466412e-05,
      "loss": 0.0137,
      "step": 8380
    },
    {
      "epoch": 1.6554853985793212,
      "grad_norm": 0.16358032822608948,
      "learning_rate": 4.499142140688927e-05,
      "loss": 0.0149,
      "step": 8390
    },
    {
      "epoch": 1.6574585635359116,
      "grad_norm": 0.1308816522359848,
      "learning_rate": 4.4925432229114426e-05,
      "loss": 0.0112,
      "step": 8400
    },
    {
      "epoch": 1.659431728492502,
      "grad_norm": 0.2424004077911377,
      "learning_rate": 4.4859443051339586e-05,
      "loss": 0.0216,
      "step": 8410
    },
    {
      "epoch": 1.6614048934490924,
      "grad_norm": 0.18125960230827332,
      "learning_rate": 4.479345387356474e-05,
      "loss": 0.022,
      "step": 8420
    },
    {
      "epoch": 1.6633780584056828,
      "grad_norm": 0.2130773365497589,
      "learning_rate": 4.472746469578989e-05,
      "loss": 0.0161,
      "step": 8430
    },
    {
      "epoch": 1.665351223362273,
      "grad_norm": 0.031919658184051514,
      "learning_rate": 4.466147551801505e-05,
      "loss": 0.0126,
      "step": 8440
    },
    {
      "epoch": 1.6673243883188635,
      "grad_norm": 0.18245656788349152,
      "learning_rate": 4.45954863402402e-05,
      "loss": 0.0203,
      "step": 8450
    },
    {
      "epoch": 1.6692975532754537,
      "grad_norm": 0.1441306620836258,
      "learning_rate": 4.452949716246536e-05,
      "loss": 0.0191,
      "step": 8460
    },
    {
      "epoch": 1.6712707182320443,
      "grad_norm": 0.23831602931022644,
      "learning_rate": 4.446350798469051e-05,
      "loss": 0.0159,
      "step": 8470
    },
    {
      "epoch": 1.6732438831886345,
      "grad_norm": 0.1994558870792389,
      "learning_rate": 4.439751880691566e-05,
      "loss": 0.0138,
      "step": 8480
    },
    {
      "epoch": 1.675217048145225,
      "grad_norm": 0.08485490083694458,
      "learning_rate": 4.433152962914082e-05,
      "loss": 0.0148,
      "step": 8490
    },
    {
      "epoch": 1.6771902131018153,
      "grad_norm": 0.13453969359397888,
      "learning_rate": 4.4265540451365976e-05,
      "loss": 0.0173,
      "step": 8500
    },
    {
      "epoch": 1.6791633780584057,
      "grad_norm": 0.0967436283826828,
      "learning_rate": 4.4199551273591136e-05,
      "loss": 0.0151,
      "step": 8510
    },
    {
      "epoch": 1.681136543014996,
      "grad_norm": 0.20415997505187988,
      "learning_rate": 4.413356209581629e-05,
      "loss": 0.0154,
      "step": 8520
    },
    {
      "epoch": 1.6831097079715864,
      "grad_norm": 0.2168043702840805,
      "learning_rate": 4.406757291804144e-05,
      "loss": 0.0117,
      "step": 8530
    },
    {
      "epoch": 1.6850828729281768,
      "grad_norm": 0.05028548091650009,
      "learning_rate": 4.40015837402666e-05,
      "loss": 0.0184,
      "step": 8540
    },
    {
      "epoch": 1.6870560378847672,
      "grad_norm": 0.19889657199382782,
      "learning_rate": 4.3935594562491755e-05,
      "loss": 0.02,
      "step": 8550
    },
    {
      "epoch": 1.6890292028413576,
      "grad_norm": 0.18236957490444183,
      "learning_rate": 4.386960538471691e-05,
      "loss": 0.0163,
      "step": 8560
    },
    {
      "epoch": 1.6910023677979478,
      "grad_norm": 0.14612771570682526,
      "learning_rate": 4.380361620694207e-05,
      "loss": 0.0197,
      "step": 8570
    },
    {
      "epoch": 1.6929755327545384,
      "grad_norm": 0.23503096401691437,
      "learning_rate": 4.3737627029167214e-05,
      "loss": 0.0183,
      "step": 8580
    },
    {
      "epoch": 1.6949486977111285,
      "grad_norm": 0.11711814999580383,
      "learning_rate": 4.3671637851392373e-05,
      "loss": 0.0304,
      "step": 8590
    },
    {
      "epoch": 1.6969218626677192,
      "grad_norm": 0.1684240847826004,
      "learning_rate": 4.3605648673617526e-05,
      "loss": 0.0213,
      "step": 8600
    },
    {
      "epoch": 1.6988950276243093,
      "grad_norm": 0.1707235425710678,
      "learning_rate": 4.3539659495842686e-05,
      "loss": 0.0153,
      "step": 8610
    },
    {
      "epoch": 1.7008681925808997,
      "grad_norm": 0.1436576098203659,
      "learning_rate": 4.347367031806784e-05,
      "loss": 0.0187,
      "step": 8620
    },
    {
      "epoch": 1.70284135753749,
      "grad_norm": 0.15753358602523804,
      "learning_rate": 4.340768114029299e-05,
      "loss": 0.0198,
      "step": 8630
    },
    {
      "epoch": 1.7048145224940805,
      "grad_norm": 0.20065733790397644,
      "learning_rate": 4.334169196251815e-05,
      "loss": 0.0189,
      "step": 8640
    },
    {
      "epoch": 1.7067876874506709,
      "grad_norm": 0.24950480461120605,
      "learning_rate": 4.3275702784743305e-05,
      "loss": 0.0164,
      "step": 8650
    },
    {
      "epoch": 1.7087608524072613,
      "grad_norm": 0.18032315373420715,
      "learning_rate": 4.320971360696846e-05,
      "loss": 0.015,
      "step": 8660
    },
    {
      "epoch": 1.7107340173638517,
      "grad_norm": 0.14516212046146393,
      "learning_rate": 4.314372442919362e-05,
      "loss": 0.0223,
      "step": 8670
    },
    {
      "epoch": 1.7127071823204418,
      "grad_norm": 0.1726878583431244,
      "learning_rate": 4.307773525141877e-05,
      "loss": 0.0288,
      "step": 8680
    },
    {
      "epoch": 1.7146803472770324,
      "grad_norm": 0.05778830870985985,
      "learning_rate": 4.3011746073643924e-05,
      "loss": 0.0117,
      "step": 8690
    },
    {
      "epoch": 1.7166535122336226,
      "grad_norm": 0.2132214903831482,
      "learning_rate": 4.294575689586908e-05,
      "loss": 0.0202,
      "step": 8700
    },
    {
      "epoch": 1.7186266771902132,
      "grad_norm": 0.17863616347312927,
      "learning_rate": 4.287976771809423e-05,
      "loss": 0.0184,
      "step": 8710
    },
    {
      "epoch": 1.7205998421468034,
      "grad_norm": 0.15461717545986176,
      "learning_rate": 4.281377854031939e-05,
      "loss": 0.0145,
      "step": 8720
    },
    {
      "epoch": 1.722573007103394,
      "grad_norm": 0.21344813704490662,
      "learning_rate": 4.274778936254454e-05,
      "loss": 0.0164,
      "step": 8730
    },
    {
      "epoch": 1.7245461720599842,
      "grad_norm": 0.15125170350074768,
      "learning_rate": 4.26818001847697e-05,
      "loss": 0.0176,
      "step": 8740
    },
    {
      "epoch": 1.7265193370165746,
      "grad_norm": 0.13151834905147552,
      "learning_rate": 4.2615811006994855e-05,
      "loss": 0.0171,
      "step": 8750
    },
    {
      "epoch": 1.728492501973165,
      "grad_norm": 0.09807366132736206,
      "learning_rate": 4.254982182922001e-05,
      "loss": 0.0169,
      "step": 8760
    },
    {
      "epoch": 1.7304656669297553,
      "grad_norm": 0.12282781302928925,
      "learning_rate": 4.248383265144517e-05,
      "loss": 0.0145,
      "step": 8770
    },
    {
      "epoch": 1.7324388318863457,
      "grad_norm": 0.18530075252056122,
      "learning_rate": 4.241784347367032e-05,
      "loss": 0.0186,
      "step": 8780
    },
    {
      "epoch": 1.7344119968429361,
      "grad_norm": 0.14367444813251495,
      "learning_rate": 4.2351854295895474e-05,
      "loss": 0.0149,
      "step": 8790
    },
    {
      "epoch": 1.7363851617995265,
      "grad_norm": 0.05560024827718735,
      "learning_rate": 4.2285865118120634e-05,
      "loss": 0.0111,
      "step": 8800
    },
    {
      "epoch": 1.7383583267561167,
      "grad_norm": 0.1360643357038498,
      "learning_rate": 4.221987594034579e-05,
      "loss": 0.0144,
      "step": 8810
    },
    {
      "epoch": 1.7403314917127073,
      "grad_norm": 0.13564741611480713,
      "learning_rate": 4.215388676257094e-05,
      "loss": 0.013,
      "step": 8820
    },
    {
      "epoch": 1.7423046566692975,
      "grad_norm": 0.17420728504657745,
      "learning_rate": 4.208789758479609e-05,
      "loss": 0.0151,
      "step": 8830
    },
    {
      "epoch": 1.744277821625888,
      "grad_norm": 0.2386128455400467,
      "learning_rate": 4.2021908407021246e-05,
      "loss": 0.015,
      "step": 8840
    },
    {
      "epoch": 1.7462509865824782,
      "grad_norm": 0.15595364570617676,
      "learning_rate": 4.1955919229246406e-05,
      "loss": 0.0174,
      "step": 8850
    },
    {
      "epoch": 1.7482241515390686,
      "grad_norm": 0.26569291949272156,
      "learning_rate": 4.188993005147156e-05,
      "loss": 0.018,
      "step": 8860
    },
    {
      "epoch": 1.750197316495659,
      "grad_norm": 0.23206958174705505,
      "learning_rate": 4.182394087369672e-05,
      "loss": 0.0173,
      "step": 8870
    },
    {
      "epoch": 1.7521704814522494,
      "grad_norm": 0.1730359047651291,
      "learning_rate": 4.175795169592187e-05,
      "loss": 0.0129,
      "step": 8880
    },
    {
      "epoch": 1.7541436464088398,
      "grad_norm": 0.17079950869083405,
      "learning_rate": 4.1691962518147024e-05,
      "loss": 0.0151,
      "step": 8890
    },
    {
      "epoch": 1.7561168113654302,
      "grad_norm": 0.14332561194896698,
      "learning_rate": 4.1625973340372184e-05,
      "loss": 0.0224,
      "step": 8900
    },
    {
      "epoch": 1.7580899763220206,
      "grad_norm": 0.1416766494512558,
      "learning_rate": 4.155998416259734e-05,
      "loss": 0.0219,
      "step": 8910
    },
    {
      "epoch": 1.7600631412786107,
      "grad_norm": 0.204309344291687,
      "learning_rate": 4.149399498482249e-05,
      "loss": 0.0143,
      "step": 8920
    },
    {
      "epoch": 1.7620363062352014,
      "grad_norm": 0.14072182774543762,
      "learning_rate": 4.142800580704765e-05,
      "loss": 0.0131,
      "step": 8930
    },
    {
      "epoch": 1.7640094711917915,
      "grad_norm": 0.237575963139534,
      "learning_rate": 4.13620166292728e-05,
      "loss": 0.0221,
      "step": 8940
    },
    {
      "epoch": 1.7659826361483821,
      "grad_norm": 0.33365708589553833,
      "learning_rate": 4.1296027451497956e-05,
      "loss": 0.0179,
      "step": 8950
    },
    {
      "epoch": 1.7679558011049723,
      "grad_norm": 0.13059593737125397,
      "learning_rate": 4.123003827372311e-05,
      "loss": 0.0154,
      "step": 8960
    },
    {
      "epoch": 1.7699289660615627,
      "grad_norm": 0.16264432668685913,
      "learning_rate": 4.116404909594826e-05,
      "loss": 0.0183,
      "step": 8970
    },
    {
      "epoch": 1.771902131018153,
      "grad_norm": 0.02238309383392334,
      "learning_rate": 4.109805991817342e-05,
      "loss": 0.0111,
      "step": 8980
    },
    {
      "epoch": 1.7738752959747435,
      "grad_norm": 0.07825929671525955,
      "learning_rate": 4.1032070740398575e-05,
      "loss": 0.0143,
      "step": 8990
    },
    {
      "epoch": 1.7758484609313339,
      "grad_norm": 0.2068912237882614,
      "learning_rate": 4.0966081562623734e-05,
      "loss": 0.0174,
      "step": 9000
    },
    {
      "epoch": 1.7778216258879243,
      "grad_norm": 0.11052574217319489,
      "learning_rate": 4.090009238484889e-05,
      "loss": 0.0213,
      "step": 9010
    },
    {
      "epoch": 1.7797947908445146,
      "grad_norm": 0.13366250693798065,
      "learning_rate": 4.083410320707404e-05,
      "loss": 0.0151,
      "step": 9020
    },
    {
      "epoch": 1.7817679558011048,
      "grad_norm": 0.2996380031108856,
      "learning_rate": 4.07681140292992e-05,
      "loss": 0.03,
      "step": 9030
    },
    {
      "epoch": 1.7837411207576954,
      "grad_norm": 0.13908958435058594,
      "learning_rate": 4.070212485152435e-05,
      "loss": 0.0103,
      "step": 9040
    },
    {
      "epoch": 1.7857142857142856,
      "grad_norm": 0.2807904779911041,
      "learning_rate": 4.0636135673749506e-05,
      "loss": 0.015,
      "step": 9050
    },
    {
      "epoch": 1.7876874506708762,
      "grad_norm": 0.1642109602689743,
      "learning_rate": 4.0570146495974666e-05,
      "loss": 0.0185,
      "step": 9060
    },
    {
      "epoch": 1.7896606156274664,
      "grad_norm": 0.1503138542175293,
      "learning_rate": 4.050415731819981e-05,
      "loss": 0.0125,
      "step": 9070
    },
    {
      "epoch": 1.791633780584057,
      "grad_norm": 0.3978534936904907,
      "learning_rate": 4.043816814042497e-05,
      "loss": 0.0184,
      "step": 9080
    },
    {
      "epoch": 1.7936069455406471,
      "grad_norm": 0.06628439575433731,
      "learning_rate": 4.0372178962650125e-05,
      "loss": 0.0181,
      "step": 9090
    },
    {
      "epoch": 1.7955801104972375,
      "grad_norm": 0.13860459625720978,
      "learning_rate": 4.030618978487528e-05,
      "loss": 0.0145,
      "step": 9100
    },
    {
      "epoch": 1.797553275453828,
      "grad_norm": 0.2339755743741989,
      "learning_rate": 4.024020060710044e-05,
      "loss": 0.0191,
      "step": 9110
    },
    {
      "epoch": 1.7995264404104183,
      "grad_norm": 0.1749359369277954,
      "learning_rate": 4.017421142932559e-05,
      "loss": 0.0212,
      "step": 9120
    },
    {
      "epoch": 1.8014996053670087,
      "grad_norm": 0.2652641236782074,
      "learning_rate": 4.010822225155075e-05,
      "loss": 0.0152,
      "step": 9130
    },
    {
      "epoch": 1.803472770323599,
      "grad_norm": 0.22894753515720367,
      "learning_rate": 4.0042233073775903e-05,
      "loss": 0.0127,
      "step": 9140
    },
    {
      "epoch": 1.8054459352801895,
      "grad_norm": 0.1505090743303299,
      "learning_rate": 3.9976243896001056e-05,
      "loss": 0.0126,
      "step": 9150
    },
    {
      "epoch": 1.8074191002367797,
      "grad_norm": 0.172432541847229,
      "learning_rate": 3.9910254718226216e-05,
      "loss": 0.0174,
      "step": 9160
    },
    {
      "epoch": 1.8093922651933703,
      "grad_norm": 0.2091028392314911,
      "learning_rate": 3.984426554045137e-05,
      "loss": 0.021,
      "step": 9170
    },
    {
      "epoch": 1.8113654301499604,
      "grad_norm": 0.16330204904079437,
      "learning_rate": 3.977827636267652e-05,
      "loss": 0.0218,
      "step": 9180
    },
    {
      "epoch": 1.813338595106551,
      "grad_norm": 0.08784140646457672,
      "learning_rate": 3.9712287184901675e-05,
      "loss": 0.0183,
      "step": 9190
    },
    {
      "epoch": 1.8153117600631412,
      "grad_norm": 0.12183726578950882,
      "learning_rate": 3.964629800712683e-05,
      "loss": 0.0134,
      "step": 9200
    },
    {
      "epoch": 1.8172849250197316,
      "grad_norm": 0.16758711636066437,
      "learning_rate": 3.958030882935199e-05,
      "loss": 0.015,
      "step": 9210
    },
    {
      "epoch": 1.819258089976322,
      "grad_norm": 0.13533830642700195,
      "learning_rate": 3.951431965157714e-05,
      "loss": 0.0197,
      "step": 9220
    },
    {
      "epoch": 1.8212312549329124,
      "grad_norm": 0.22079822421073914,
      "learning_rate": 3.94483304738023e-05,
      "loss": 0.0168,
      "step": 9230
    },
    {
      "epoch": 1.8232044198895028,
      "grad_norm": 0.1308601349592209,
      "learning_rate": 3.9382341296027454e-05,
      "loss": 0.018,
      "step": 9240
    },
    {
      "epoch": 1.8251775848460932,
      "grad_norm": 0.3626627027988434,
      "learning_rate": 3.931635211825261e-05,
      "loss": 0.0189,
      "step": 9250
    },
    {
      "epoch": 1.8271507498026835,
      "grad_norm": 0.18607494235038757,
      "learning_rate": 3.9250362940477767e-05,
      "loss": 0.0105,
      "step": 9260
    },
    {
      "epoch": 1.8291239147592737,
      "grad_norm": 0.09827666729688644,
      "learning_rate": 3.918437376270292e-05,
      "loss": 0.014,
      "step": 9270
    },
    {
      "epoch": 1.8310970797158643,
      "grad_norm": 0.07656683027744293,
      "learning_rate": 3.911838458492807e-05,
      "loss": 0.02,
      "step": 9280
    },
    {
      "epoch": 1.8330702446724545,
      "grad_norm": 0.3092162609100342,
      "learning_rate": 3.905239540715323e-05,
      "loss": 0.0198,
      "step": 9290
    },
    {
      "epoch": 1.835043409629045,
      "grad_norm": 0.17973865568637848,
      "learning_rate": 3.8986406229378385e-05,
      "loss": 0.014,
      "step": 9300
    },
    {
      "epoch": 1.8370165745856353,
      "grad_norm": 0.260667622089386,
      "learning_rate": 3.892041705160354e-05,
      "loss": 0.0183,
      "step": 9310
    },
    {
      "epoch": 1.8389897395422259,
      "grad_norm": 0.25034305453300476,
      "learning_rate": 3.885442787382869e-05,
      "loss": 0.0155,
      "step": 9320
    },
    {
      "epoch": 1.840962904498816,
      "grad_norm": 0.2264328896999359,
      "learning_rate": 3.8788438696053844e-05,
      "loss": 0.0237,
      "step": 9330
    },
    {
      "epoch": 1.8429360694554064,
      "grad_norm": 0.14373500645160675,
      "learning_rate": 3.8722449518279004e-05,
      "loss": 0.0148,
      "step": 9340
    },
    {
      "epoch": 1.8449092344119968,
      "grad_norm": 0.2382756471633911,
      "learning_rate": 3.865646034050416e-05,
      "loss": 0.0155,
      "step": 9350
    },
    {
      "epoch": 1.8468823993685872,
      "grad_norm": 0.12924280762672424,
      "learning_rate": 3.859047116272932e-05,
      "loss": 0.0168,
      "step": 9360
    },
    {
      "epoch": 1.8488555643251776,
      "grad_norm": 0.2322147935628891,
      "learning_rate": 3.852448198495447e-05,
      "loss": 0.012,
      "step": 9370
    },
    {
      "epoch": 1.850828729281768,
      "grad_norm": 0.17673258483409882,
      "learning_rate": 3.845849280717962e-05,
      "loss": 0.0142,
      "step": 9380
    },
    {
      "epoch": 1.8528018942383584,
      "grad_norm": 0.19441033899784088,
      "learning_rate": 3.839250362940478e-05,
      "loss": 0.013,
      "step": 9390
    },
    {
      "epoch": 1.8547750591949486,
      "grad_norm": 0.32532256841659546,
      "learning_rate": 3.8326514451629936e-05,
      "loss": 0.0162,
      "step": 9400
    },
    {
      "epoch": 1.8567482241515392,
      "grad_norm": 0.11489751935005188,
      "learning_rate": 3.826052527385509e-05,
      "loss": 0.0151,
      "step": 9410
    },
    {
      "epoch": 1.8587213891081293,
      "grad_norm": 0.16454939544200897,
      "learning_rate": 3.819453609608025e-05,
      "loss": 0.0217,
      "step": 9420
    },
    {
      "epoch": 1.86069455406472,
      "grad_norm": 0.2834443747997284,
      "learning_rate": 3.81285469183054e-05,
      "loss": 0.0159,
      "step": 9430
    },
    {
      "epoch": 1.8626677190213101,
      "grad_norm": 0.18113839626312256,
      "learning_rate": 3.8062557740530554e-05,
      "loss": 0.0224,
      "step": 9440
    },
    {
      "epoch": 1.8646408839779005,
      "grad_norm": 0.14048871397972107,
      "learning_rate": 3.799656856275571e-05,
      "loss": 0.0135,
      "step": 9450
    },
    {
      "epoch": 1.866614048934491,
      "grad_norm": 0.19194431602954865,
      "learning_rate": 3.793057938498086e-05,
      "loss": 0.0141,
      "step": 9460
    },
    {
      "epoch": 1.8685872138910813,
      "grad_norm": 0.09823436290025711,
      "learning_rate": 3.786459020720602e-05,
      "loss": 0.011,
      "step": 9470
    },
    {
      "epoch": 1.8705603788476717,
      "grad_norm": 0.12034600973129272,
      "learning_rate": 3.779860102943117e-05,
      "loss": 0.0186,
      "step": 9480
    },
    {
      "epoch": 1.872533543804262,
      "grad_norm": 0.2327631264925003,
      "learning_rate": 3.773261185165633e-05,
      "loss": 0.0218,
      "step": 9490
    },
    {
      "epoch": 1.8745067087608525,
      "grad_norm": 0.16053643822669983,
      "learning_rate": 3.7666622673881486e-05,
      "loss": 0.0193,
      "step": 9500
    },
    {
      "epoch": 1.8764798737174426,
      "grad_norm": 0.20873327553272247,
      "learning_rate": 3.760063349610664e-05,
      "loss": 0.0139,
      "step": 9510
    },
    {
      "epoch": 1.8784530386740332,
      "grad_norm": 0.18297429382801056,
      "learning_rate": 3.75346443183318e-05,
      "loss": 0.016,
      "step": 9520
    },
    {
      "epoch": 1.8804262036306234,
      "grad_norm": 0.09048043191432953,
      "learning_rate": 3.746865514055695e-05,
      "loss": 0.0241,
      "step": 9530
    },
    {
      "epoch": 1.882399368587214,
      "grad_norm": 0.0892835259437561,
      "learning_rate": 3.7402665962782105e-05,
      "loss": 0.0126,
      "step": 9540
    },
    {
      "epoch": 1.8843725335438042,
      "grad_norm": 0.08481472730636597,
      "learning_rate": 3.7336676785007264e-05,
      "loss": 0.0158,
      "step": 9550
    },
    {
      "epoch": 1.8863456985003948,
      "grad_norm": 0.153224915266037,
      "learning_rate": 3.727068760723241e-05,
      "loss": 0.0211,
      "step": 9560
    },
    {
      "epoch": 1.888318863456985,
      "grad_norm": 0.18923695385456085,
      "learning_rate": 3.720469842945757e-05,
      "loss": 0.0172,
      "step": 9570
    },
    {
      "epoch": 1.8902920284135754,
      "grad_norm": 0.16550199687480927,
      "learning_rate": 3.7138709251682723e-05,
      "loss": 0.0149,
      "step": 9580
    },
    {
      "epoch": 1.8922651933701657,
      "grad_norm": 0.19272582232952118,
      "learning_rate": 3.7072720073907876e-05,
      "loss": 0.0139,
      "step": 9590
    },
    {
      "epoch": 1.8942383583267561,
      "grad_norm": 0.14703617990016937,
      "learning_rate": 3.7006730896133036e-05,
      "loss": 0.0192,
      "step": 9600
    },
    {
      "epoch": 1.8962115232833465,
      "grad_norm": 0.2816583514213562,
      "learning_rate": 3.694074171835819e-05,
      "loss": 0.0185,
      "step": 9610
    },
    {
      "epoch": 1.898184688239937,
      "grad_norm": 0.12009380012750626,
      "learning_rate": 3.687475254058335e-05,
      "loss": 0.0104,
      "step": 9620
    },
    {
      "epoch": 1.9001578531965273,
      "grad_norm": 0.29234442114830017,
      "learning_rate": 3.68087633628085e-05,
      "loss": 0.016,
      "step": 9630
    },
    {
      "epoch": 1.9021310181531175,
      "grad_norm": 0.10579835623502731,
      "learning_rate": 3.6742774185033655e-05,
      "loss": 0.0183,
      "step": 9640
    },
    {
      "epoch": 1.904104183109708,
      "grad_norm": 0.19365569949150085,
      "learning_rate": 3.6676785007258815e-05,
      "loss": 0.0162,
      "step": 9650
    },
    {
      "epoch": 1.9060773480662982,
      "grad_norm": 0.1434764415025711,
      "learning_rate": 3.661079582948397e-05,
      "loss": 0.0162,
      "step": 9660
    },
    {
      "epoch": 1.9080505130228889,
      "grad_norm": 0.10518507659435272,
      "learning_rate": 3.654480665170912e-05,
      "loss": 0.0186,
      "step": 9670
    },
    {
      "epoch": 1.910023677979479,
      "grad_norm": 0.24240057170391083,
      "learning_rate": 3.647881747393428e-05,
      "loss": 0.0119,
      "step": 9680
    },
    {
      "epoch": 1.9119968429360694,
      "grad_norm": 0.2615204453468323,
      "learning_rate": 3.641282829615943e-05,
      "loss": 0.0166,
      "step": 9690
    },
    {
      "epoch": 1.9139700078926598,
      "grad_norm": 0.12828393280506134,
      "learning_rate": 3.6346839118384587e-05,
      "loss": 0.0158,
      "step": 9700
    },
    {
      "epoch": 1.9159431728492502,
      "grad_norm": 0.1752035915851593,
      "learning_rate": 3.628084994060974e-05,
      "loss": 0.0209,
      "step": 9710
    },
    {
      "epoch": 1.9179163378058406,
      "grad_norm": 0.43272122740745544,
      "learning_rate": 3.621486076283489e-05,
      "loss": 0.0171,
      "step": 9720
    },
    {
      "epoch": 1.919889502762431,
      "grad_norm": 0.11339125037193298,
      "learning_rate": 3.614887158506005e-05,
      "loss": 0.0183,
      "step": 9730
    },
    {
      "epoch": 1.9218626677190214,
      "grad_norm": 0.10973110795021057,
      "learning_rate": 3.6082882407285205e-05,
      "loss": 0.0162,
      "step": 9740
    },
    {
      "epoch": 1.9238358326756115,
      "grad_norm": 0.3169776201248169,
      "learning_rate": 3.6016893229510365e-05,
      "loss": 0.0128,
      "step": 9750
    },
    {
      "epoch": 1.9258089976322021,
      "grad_norm": 0.2704952657222748,
      "learning_rate": 3.595090405173552e-05,
      "loss": 0.0169,
      "step": 9760
    },
    {
      "epoch": 1.9277821625887923,
      "grad_norm": 0.23308967053890228,
      "learning_rate": 3.588491487396067e-05,
      "loss": 0.0163,
      "step": 9770
    },
    {
      "epoch": 1.929755327545383,
      "grad_norm": 0.22312505543231964,
      "learning_rate": 3.581892569618583e-05,
      "loss": 0.0131,
      "step": 9780
    },
    {
      "epoch": 1.931728492501973,
      "grad_norm": 0.22577719390392303,
      "learning_rate": 3.5752936518410984e-05,
      "loss": 0.0106,
      "step": 9790
    },
    {
      "epoch": 1.9337016574585635,
      "grad_norm": 0.23212960362434387,
      "learning_rate": 3.568694734063614e-05,
      "loss": 0.0158,
      "step": 9800
    },
    {
      "epoch": 1.9356748224151539,
      "grad_norm": 0.14823949337005615,
      "learning_rate": 3.562095816286129e-05,
      "loss": 0.0185,
      "step": 9810
    },
    {
      "epoch": 1.9376479873717443,
      "grad_norm": 0.17651259899139404,
      "learning_rate": 3.555496898508644e-05,
      "loss": 0.0125,
      "step": 9820
    },
    {
      "epoch": 1.9396211523283347,
      "grad_norm": 0.03442669287323952,
      "learning_rate": 3.54889798073116e-05,
      "loss": 0.0149,
      "step": 9830
    },
    {
      "epoch": 1.941594317284925,
      "grad_norm": 0.104499951004982,
      "learning_rate": 3.5422990629536756e-05,
      "loss": 0.0165,
      "step": 9840
    },
    {
      "epoch": 1.9435674822415154,
      "grad_norm": 0.2282504290342331,
      "learning_rate": 3.535700145176191e-05,
      "loss": 0.0141,
      "step": 9850
    },
    {
      "epoch": 1.9455406471981056,
      "grad_norm": 0.19133885204792023,
      "learning_rate": 3.529101227398707e-05,
      "loss": 0.0186,
      "step": 9860
    },
    {
      "epoch": 1.9475138121546962,
      "grad_norm": 0.23731613159179688,
      "learning_rate": 3.522502309621222e-05,
      "loss": 0.0088,
      "step": 9870
    },
    {
      "epoch": 1.9494869771112864,
      "grad_norm": 0.29309141635894775,
      "learning_rate": 3.515903391843738e-05,
      "loss": 0.018,
      "step": 9880
    },
    {
      "epoch": 1.951460142067877,
      "grad_norm": 0.7014560103416443,
      "learning_rate": 3.5093044740662534e-05,
      "loss": 0.0159,
      "step": 9890
    },
    {
      "epoch": 1.9534333070244672,
      "grad_norm": 0.14643864333629608,
      "learning_rate": 3.502705556288769e-05,
      "loss": 0.0148,
      "step": 9900
    },
    {
      "epoch": 1.9554064719810578,
      "grad_norm": 0.17765234410762787,
      "learning_rate": 3.496106638511285e-05,
      "loss": 0.0125,
      "step": 9910
    },
    {
      "epoch": 1.957379636937648,
      "grad_norm": 0.1706540584564209,
      "learning_rate": 3.4895077207338e-05,
      "loss": 0.0139,
      "step": 9920
    },
    {
      "epoch": 1.9593528018942383,
      "grad_norm": 0.3766710162162781,
      "learning_rate": 3.482908802956315e-05,
      "loss": 0.0203,
      "step": 9930
    },
    {
      "epoch": 1.9613259668508287,
      "grad_norm": 0.09868508577346802,
      "learning_rate": 3.4763098851788306e-05,
      "loss": 0.017,
      "step": 9940
    },
    {
      "epoch": 1.963299131807419,
      "grad_norm": 0.20416222512722015,
      "learning_rate": 3.469710967401346e-05,
      "loss": 0.0151,
      "step": 9950
    },
    {
      "epoch": 1.9652722967640095,
      "grad_norm": 0.1316249966621399,
      "learning_rate": 3.463112049623862e-05,
      "loss": 0.0188,
      "step": 9960
    },
    {
      "epoch": 1.9672454617205999,
      "grad_norm": 0.038479033857584,
      "learning_rate": 3.456513131846377e-05,
      "loss": 0.011,
      "step": 9970
    },
    {
      "epoch": 1.9692186266771903,
      "grad_norm": 0.26132944226264954,
      "learning_rate": 3.449914214068893e-05,
      "loss": 0.0133,
      "step": 9980
    },
    {
      "epoch": 1.9711917916337804,
      "grad_norm": 0.04569437354803085,
      "learning_rate": 3.4433152962914084e-05,
      "loss": 0.0083,
      "step": 9990
    },
    {
      "epoch": 1.973164956590371,
      "grad_norm": 0.2886505424976349,
      "learning_rate": 3.436716378513924e-05,
      "loss": 0.0143,
      "step": 10000
    },
    {
      "epoch": 1.973164956590371,
      "eval_loss": 0.01670140214264393,
      "eval_runtime": 85.3868,
      "eval_samples_per_second": 13.199,
      "eval_steps_per_second": 6.605,
      "step": 10000
    },
    {
      "epoch": 1.9751381215469612,
      "grad_norm": 0.07260531187057495,
      "learning_rate": 3.43011746073644e-05,
      "loss": 0.0114,
      "step": 10010
    },
    {
      "epoch": 1.9771112865035518,
      "grad_norm": 0.26500648260116577,
      "learning_rate": 3.423518542958955e-05,
      "loss": 0.0152,
      "step": 10020
    },
    {
      "epoch": 1.979084451460142,
      "grad_norm": 0.2867348790168762,
      "learning_rate": 3.41691962518147e-05,
      "loss": 0.0195,
      "step": 10030
    },
    {
      "epoch": 1.9810576164167324,
      "grad_norm": 0.27010759711265564,
      "learning_rate": 3.410320707403986e-05,
      "loss": 0.0177,
      "step": 10040
    },
    {
      "epoch": 1.9830307813733228,
      "grad_norm": 0.21775250136852264,
      "learning_rate": 3.4037217896265016e-05,
      "loss": 0.0146,
      "step": 10050
    },
    {
      "epoch": 1.9850039463299132,
      "grad_norm": 0.26016518473625183,
      "learning_rate": 3.397122871849017e-05,
      "loss": 0.0157,
      "step": 10060
    },
    {
      "epoch": 1.9869771112865036,
      "grad_norm": 0.15686534345149994,
      "learning_rate": 3.390523954071532e-05,
      "loss": 0.0221,
      "step": 10070
    },
    {
      "epoch": 1.988950276243094,
      "grad_norm": 0.18985463678836823,
      "learning_rate": 3.3839250362940475e-05,
      "loss": 0.0148,
      "step": 10080
    },
    {
      "epoch": 1.9909234411996843,
      "grad_norm": 0.4593164920806885,
      "learning_rate": 3.3773261185165635e-05,
      "loss": 0.0185,
      "step": 10090
    },
    {
      "epoch": 1.9928966061562745,
      "grad_norm": 0.18792539834976196,
      "learning_rate": 3.370727200739079e-05,
      "loss": 0.0181,
      "step": 10100
    },
    {
      "epoch": 1.9948697711128651,
      "grad_norm": 0.09716425091028214,
      "learning_rate": 3.364128282961595e-05,
      "loss": 0.0101,
      "step": 10110
    },
    {
      "epoch": 1.9968429360694553,
      "grad_norm": 0.2780551016330719,
      "learning_rate": 3.35752936518411e-05,
      "loss": 0.0162,
      "step": 10120
    },
    {
      "epoch": 1.998816101026046,
      "grad_norm": 0.40303993225097656,
      "learning_rate": 3.3509304474066253e-05,
      "loss": 0.0148,
      "step": 10130
    },
    {
      "epoch": 2.000789265982636,
      "grad_norm": 0.08512942492961884,
      "learning_rate": 3.344331529629141e-05,
      "loss": 0.0143,
      "step": 10140
    },
    {
      "epoch": 2.0027624309392267,
      "grad_norm": 0.1879110038280487,
      "learning_rate": 3.3377326118516566e-05,
      "loss": 0.0139,
      "step": 10150
    },
    {
      "epoch": 2.004735595895817,
      "grad_norm": 0.09692546725273132,
      "learning_rate": 3.331133694074172e-05,
      "loss": 0.0165,
      "step": 10160
    },
    {
      "epoch": 2.0067087608524075,
      "grad_norm": 0.30679017305374146,
      "learning_rate": 3.324534776296688e-05,
      "loss": 0.0177,
      "step": 10170
    },
    {
      "epoch": 2.0086819258089976,
      "grad_norm": 0.106599822640419,
      "learning_rate": 3.3179358585192025e-05,
      "loss": 0.0137,
      "step": 10180
    },
    {
      "epoch": 2.010655090765588,
      "grad_norm": 0.061973243951797485,
      "learning_rate": 3.3113369407417185e-05,
      "loss": 0.0167,
      "step": 10190
    },
    {
      "epoch": 2.0126282557221784,
      "grad_norm": 0.2983168661594391,
      "learning_rate": 3.304738022964234e-05,
      "loss": 0.0118,
      "step": 10200
    },
    {
      "epoch": 2.0146014206787686,
      "grad_norm": 0.27058663964271545,
      "learning_rate": 3.298139105186749e-05,
      "loss": 0.0112,
      "step": 10210
    },
    {
      "epoch": 2.016574585635359,
      "grad_norm": 0.13016769289970398,
      "learning_rate": 3.291540187409265e-05,
      "loss": 0.0107,
      "step": 10220
    },
    {
      "epoch": 2.0185477505919494,
      "grad_norm": 0.1986890435218811,
      "learning_rate": 3.2849412696317804e-05,
      "loss": 0.0154,
      "step": 10230
    },
    {
      "epoch": 2.02052091554854,
      "grad_norm": 0.18851596117019653,
      "learning_rate": 3.2783423518542964e-05,
      "loss": 0.0141,
      "step": 10240
    },
    {
      "epoch": 2.02249408050513,
      "grad_norm": 0.13484936952590942,
      "learning_rate": 3.2717434340768117e-05,
      "loss": 0.0194,
      "step": 10250
    },
    {
      "epoch": 2.0244672454617207,
      "grad_norm": 0.4518287777900696,
      "learning_rate": 3.265144516299327e-05,
      "loss": 0.0184,
      "step": 10260
    },
    {
      "epoch": 2.026440410418311,
      "grad_norm": 0.21070559322834015,
      "learning_rate": 3.258545598521843e-05,
      "loss": 0.0185,
      "step": 10270
    },
    {
      "epoch": 2.0284135753749015,
      "grad_norm": 0.12756472826004028,
      "learning_rate": 3.251946680744358e-05,
      "loss": 0.0162,
      "step": 10280
    },
    {
      "epoch": 2.0303867403314917,
      "grad_norm": 0.12889981269836426,
      "learning_rate": 3.2453477629668735e-05,
      "loss": 0.0151,
      "step": 10290
    },
    {
      "epoch": 2.0323599052880823,
      "grad_norm": 0.13957226276397705,
      "learning_rate": 3.2387488451893895e-05,
      "loss": 0.0143,
      "step": 10300
    },
    {
      "epoch": 2.0343330702446725,
      "grad_norm": 0.2732771933078766,
      "learning_rate": 3.232149927411904e-05,
      "loss": 0.0174,
      "step": 10310
    },
    {
      "epoch": 2.0363062352012626,
      "grad_norm": 0.1466757357120514,
      "learning_rate": 3.22555100963442e-05,
      "loss": 0.0223,
      "step": 10320
    },
    {
      "epoch": 2.0382794001578532,
      "grad_norm": 0.13480712473392487,
      "learning_rate": 3.2189520918569354e-05,
      "loss": 0.0101,
      "step": 10330
    },
    {
      "epoch": 2.0402525651144434,
      "grad_norm": 0.12275277078151703,
      "learning_rate": 3.212353174079451e-05,
      "loss": 0.014,
      "step": 10340
    },
    {
      "epoch": 2.042225730071034,
      "grad_norm": 0.24638935923576355,
      "learning_rate": 3.205754256301967e-05,
      "loss": 0.0131,
      "step": 10350
    },
    {
      "epoch": 2.044198895027624,
      "grad_norm": 0.06539913266897202,
      "learning_rate": 3.199155338524482e-05,
      "loss": 0.0188,
      "step": 10360
    },
    {
      "epoch": 2.046172059984215,
      "grad_norm": 0.2102905809879303,
      "learning_rate": 3.192556420746998e-05,
      "loss": 0.0195,
      "step": 10370
    },
    {
      "epoch": 2.048145224940805,
      "grad_norm": 0.3168344497680664,
      "learning_rate": 3.185957502969513e-05,
      "loss": 0.0149,
      "step": 10380
    },
    {
      "epoch": 2.0501183898973956,
      "grad_norm": 0.1360895335674286,
      "learning_rate": 3.1793585851920286e-05,
      "loss": 0.0187,
      "step": 10390
    },
    {
      "epoch": 2.0520915548539858,
      "grad_norm": 0.15107280015945435,
      "learning_rate": 3.1727596674145445e-05,
      "loss": 0.0135,
      "step": 10400
    },
    {
      "epoch": 2.0540647198105764,
      "grad_norm": 0.2990095913410187,
      "learning_rate": 3.16616074963706e-05,
      "loss": 0.014,
      "step": 10410
    },
    {
      "epoch": 2.0560378847671665,
      "grad_norm": 0.05936918407678604,
      "learning_rate": 3.159561831859575e-05,
      "loss": 0.0076,
      "step": 10420
    },
    {
      "epoch": 2.0580110497237567,
      "grad_norm": 0.22371692955493927,
      "learning_rate": 3.1529629140820904e-05,
      "loss": 0.0174,
      "step": 10430
    },
    {
      "epoch": 2.0599842146803473,
      "grad_norm": 0.03105694055557251,
      "learning_rate": 3.146363996304606e-05,
      "loss": 0.0096,
      "step": 10440
    },
    {
      "epoch": 2.0619573796369375,
      "grad_norm": 0.27958276867866516,
      "learning_rate": 3.139765078527122e-05,
      "loss": 0.0179,
      "step": 10450
    },
    {
      "epoch": 2.063930544593528,
      "grad_norm": 0.16870084404945374,
      "learning_rate": 3.133166160749637e-05,
      "loss": 0.0095,
      "step": 10460
    },
    {
      "epoch": 2.0659037095501183,
      "grad_norm": 0.16311167180538177,
      "learning_rate": 3.126567242972152e-05,
      "loss": 0.0123,
      "step": 10470
    },
    {
      "epoch": 2.067876874506709,
      "grad_norm": 0.09972897171974182,
      "learning_rate": 3.119968325194668e-05,
      "loss": 0.0065,
      "step": 10480
    },
    {
      "epoch": 2.069850039463299,
      "grad_norm": 0.2756372094154358,
      "learning_rate": 3.1133694074171836e-05,
      "loss": 0.0134,
      "step": 10490
    },
    {
      "epoch": 2.0718232044198897,
      "grad_norm": 0.24024657905101776,
      "learning_rate": 3.1067704896396996e-05,
      "loss": 0.0165,
      "step": 10500
    },
    {
      "epoch": 2.07379636937648,
      "grad_norm": 0.0897068902850151,
      "learning_rate": 3.100171571862215e-05,
      "loss": 0.0121,
      "step": 10510
    },
    {
      "epoch": 2.0757695343330704,
      "grad_norm": 0.08413040637969971,
      "learning_rate": 3.09357265408473e-05,
      "loss": 0.0185,
      "step": 10520
    },
    {
      "epoch": 2.0777426992896606,
      "grad_norm": 0.0881834477186203,
      "learning_rate": 3.086973736307246e-05,
      "loss": 0.0156,
      "step": 10530
    },
    {
      "epoch": 2.0797158642462508,
      "grad_norm": 0.2010398507118225,
      "learning_rate": 3.0803748185297614e-05,
      "loss": 0.0148,
      "step": 10540
    },
    {
      "epoch": 2.0816890292028414,
      "grad_norm": 0.06009814888238907,
      "learning_rate": 3.073775900752277e-05,
      "loss": 0.0167,
      "step": 10550
    },
    {
      "epoch": 2.0836621941594315,
      "grad_norm": 0.056796178221702576,
      "learning_rate": 3.067176982974792e-05,
      "loss": 0.0118,
      "step": 10560
    },
    {
      "epoch": 2.085635359116022,
      "grad_norm": 0.20274807512760162,
      "learning_rate": 3.0605780651973073e-05,
      "loss": 0.0136,
      "step": 10570
    },
    {
      "epoch": 2.0876085240726123,
      "grad_norm": 0.2944903075695038,
      "learning_rate": 3.053979147419823e-05,
      "loss": 0.0133,
      "step": 10580
    },
    {
      "epoch": 2.089581689029203,
      "grad_norm": 0.15329059958457947,
      "learning_rate": 3.0473802296423386e-05,
      "loss": 0.0188,
      "step": 10590
    },
    {
      "epoch": 2.091554853985793,
      "grad_norm": 0.193385511636734,
      "learning_rate": 3.0407813118648543e-05,
      "loss": 0.0153,
      "step": 10600
    },
    {
      "epoch": 2.0935280189423837,
      "grad_norm": 0.08826442807912827,
      "learning_rate": 3.03418239408737e-05,
      "loss": 0.0177,
      "step": 10610
    },
    {
      "epoch": 2.095501183898974,
      "grad_norm": 0.18717890977859497,
      "learning_rate": 3.0275834763098852e-05,
      "loss": 0.0145,
      "step": 10620
    },
    {
      "epoch": 2.0974743488555645,
      "grad_norm": 0.2049763798713684,
      "learning_rate": 3.020984558532401e-05,
      "loss": 0.0241,
      "step": 10630
    },
    {
      "epoch": 2.0994475138121547,
      "grad_norm": 0.11067937314510345,
      "learning_rate": 3.0143856407549165e-05,
      "loss": 0.0083,
      "step": 10640
    },
    {
      "epoch": 2.1014206787687453,
      "grad_norm": 0.11729136109352112,
      "learning_rate": 3.007786722977432e-05,
      "loss": 0.0136,
      "step": 10650
    },
    {
      "epoch": 2.1033938437253354,
      "grad_norm": 0.30773088335990906,
      "learning_rate": 3.0011878051999474e-05,
      "loss": 0.014,
      "step": 10660
    },
    {
      "epoch": 2.1053670086819256,
      "grad_norm": 0.11734752357006073,
      "learning_rate": 2.994588887422463e-05,
      "loss": 0.0153,
      "step": 10670
    },
    {
      "epoch": 2.1073401736385162,
      "grad_norm": 1.192306637763977,
      "learning_rate": 2.987989969644978e-05,
      "loss": 0.0165,
      "step": 10680
    },
    {
      "epoch": 2.1093133385951064,
      "grad_norm": 0.27827590703964233,
      "learning_rate": 2.9813910518674937e-05,
      "loss": 0.0118,
      "step": 10690
    },
    {
      "epoch": 2.111286503551697,
      "grad_norm": 0.11722312867641449,
      "learning_rate": 2.9747921340900093e-05,
      "loss": 0.0155,
      "step": 10700
    },
    {
      "epoch": 2.113259668508287,
      "grad_norm": 0.25785550475120544,
      "learning_rate": 2.968193216312525e-05,
      "loss": 0.0149,
      "step": 10710
    },
    {
      "epoch": 2.115232833464878,
      "grad_norm": 0.12311913073062897,
      "learning_rate": 2.9615942985350402e-05,
      "loss": 0.0193,
      "step": 10720
    },
    {
      "epoch": 2.117205998421468,
      "grad_norm": 0.20652766525745392,
      "learning_rate": 2.954995380757556e-05,
      "loss": 0.0132,
      "step": 10730
    },
    {
      "epoch": 2.1191791633780586,
      "grad_norm": 0.22526821494102478,
      "learning_rate": 2.9483964629800715e-05,
      "loss": 0.0108,
      "step": 10740
    },
    {
      "epoch": 2.1211523283346487,
      "grad_norm": 0.09842332452535629,
      "learning_rate": 2.941797545202587e-05,
      "loss": 0.0113,
      "step": 10750
    },
    {
      "epoch": 2.1231254932912393,
      "grad_norm": 0.08168931305408478,
      "learning_rate": 2.9351986274251024e-05,
      "loss": 0.0161,
      "step": 10760
    },
    {
      "epoch": 2.1250986582478295,
      "grad_norm": 0.09921256452798843,
      "learning_rate": 2.928599709647618e-05,
      "loss": 0.0126,
      "step": 10770
    },
    {
      "epoch": 2.12707182320442,
      "grad_norm": 0.30169713497161865,
      "learning_rate": 2.9220007918701337e-05,
      "loss": 0.0157,
      "step": 10780
    },
    {
      "epoch": 2.1290449881610103,
      "grad_norm": 0.33403608202934265,
      "learning_rate": 2.9154018740926494e-05,
      "loss": 0.0193,
      "step": 10790
    },
    {
      "epoch": 2.1310181531176005,
      "grad_norm": 0.3277890086174011,
      "learning_rate": 2.9088029563151643e-05,
      "loss": 0.0174,
      "step": 10800
    },
    {
      "epoch": 2.132991318074191,
      "grad_norm": 0.18164990842342377,
      "learning_rate": 2.9022040385376796e-05,
      "loss": 0.014,
      "step": 10810
    },
    {
      "epoch": 2.1349644830307812,
      "grad_norm": 0.17551016807556152,
      "learning_rate": 2.8956051207601953e-05,
      "loss": 0.0146,
      "step": 10820
    },
    {
      "epoch": 2.136937647987372,
      "grad_norm": 0.2908475399017334,
      "learning_rate": 2.889006202982711e-05,
      "loss": 0.0204,
      "step": 10830
    },
    {
      "epoch": 2.138910812943962,
      "grad_norm": 0.13558995723724365,
      "learning_rate": 2.8824072852052265e-05,
      "loss": 0.0152,
      "step": 10840
    },
    {
      "epoch": 2.1408839779005526,
      "grad_norm": 0.1471712440252304,
      "learning_rate": 2.875808367427742e-05,
      "loss": 0.0167,
      "step": 10850
    },
    {
      "epoch": 2.142857142857143,
      "grad_norm": 0.23382174968719482,
      "learning_rate": 2.8692094496502575e-05,
      "loss": 0.016,
      "step": 10860
    },
    {
      "epoch": 2.1448303078137334,
      "grad_norm": 0.18899621069431305,
      "learning_rate": 2.862610531872773e-05,
      "loss": 0.013,
      "step": 10870
    },
    {
      "epoch": 2.1468034727703236,
      "grad_norm": 0.145762100815773,
      "learning_rate": 2.8560116140952888e-05,
      "loss": 0.0192,
      "step": 10880
    },
    {
      "epoch": 2.1487766377269137,
      "grad_norm": 0.1228640154004097,
      "learning_rate": 2.849412696317804e-05,
      "loss": 0.022,
      "step": 10890
    },
    {
      "epoch": 2.1507498026835044,
      "grad_norm": 0.1959252655506134,
      "learning_rate": 2.8428137785403197e-05,
      "loss": 0.0206,
      "step": 10900
    },
    {
      "epoch": 2.1527229676400945,
      "grad_norm": 0.12804564833641052,
      "learning_rate": 2.8362148607628353e-05,
      "loss": 0.0149,
      "step": 10910
    },
    {
      "epoch": 2.154696132596685,
      "grad_norm": 0.15491516888141632,
      "learning_rate": 2.8296159429853503e-05,
      "loss": 0.0135,
      "step": 10920
    },
    {
      "epoch": 2.1566692975532753,
      "grad_norm": 0.03348984941840172,
      "learning_rate": 2.823017025207866e-05,
      "loss": 0.0166,
      "step": 10930
    },
    {
      "epoch": 2.158642462509866,
      "grad_norm": 0.15968520939350128,
      "learning_rate": 2.8164181074303812e-05,
      "loss": 0.0174,
      "step": 10940
    },
    {
      "epoch": 2.160615627466456,
      "grad_norm": 0.18999959528446198,
      "learning_rate": 2.809819189652897e-05,
      "loss": 0.0162,
      "step": 10950
    },
    {
      "epoch": 2.1625887924230467,
      "grad_norm": 0.20808015763759613,
      "learning_rate": 2.8032202718754125e-05,
      "loss": 0.0155,
      "step": 10960
    },
    {
      "epoch": 2.164561957379637,
      "grad_norm": 0.5383594632148743,
      "learning_rate": 2.796621354097928e-05,
      "loss": 0.0178,
      "step": 10970
    },
    {
      "epoch": 2.1665351223362275,
      "grad_norm": 0.09993825107812881,
      "learning_rate": 2.7900224363204434e-05,
      "loss": 0.0128,
      "step": 10980
    },
    {
      "epoch": 2.1685082872928176,
      "grad_norm": 0.15150822699069977,
      "learning_rate": 2.783423518542959e-05,
      "loss": 0.0201,
      "step": 10990
    },
    {
      "epoch": 2.1704814522494082,
      "grad_norm": 0.29427528381347656,
      "learning_rate": 2.7768246007654747e-05,
      "loss": 0.0171,
      "step": 11000
    },
    {
      "epoch": 2.1724546172059984,
      "grad_norm": 0.13375648856163025,
      "learning_rate": 2.7702256829879904e-05,
      "loss": 0.0139,
      "step": 11010
    },
    {
      "epoch": 2.1744277821625886,
      "grad_norm": 0.0780499279499054,
      "learning_rate": 2.7636267652105057e-05,
      "loss": 0.0108,
      "step": 11020
    },
    {
      "epoch": 2.176400947119179,
      "grad_norm": 0.17353016138076782,
      "learning_rate": 2.7570278474330213e-05,
      "loss": 0.0147,
      "step": 11030
    },
    {
      "epoch": 2.1783741120757694,
      "grad_norm": 0.13619963824748993,
      "learning_rate": 2.750428929655537e-05,
      "loss": 0.0191,
      "step": 11040
    },
    {
      "epoch": 2.18034727703236,
      "grad_norm": 0.21903280913829803,
      "learning_rate": 2.743830011878052e-05,
      "loss": 0.0148,
      "step": 11050
    },
    {
      "epoch": 2.18232044198895,
      "grad_norm": 0.08072070777416229,
      "learning_rate": 2.7372310941005675e-05,
      "loss": 0.0145,
      "step": 11060
    },
    {
      "epoch": 2.1842936069455408,
      "grad_norm": 0.17509250342845917,
      "learning_rate": 2.730632176323083e-05,
      "loss": 0.0127,
      "step": 11070
    },
    {
      "epoch": 2.186266771902131,
      "grad_norm": 0.16134627163410187,
      "learning_rate": 2.7240332585455985e-05,
      "loss": 0.0131,
      "step": 11080
    },
    {
      "epoch": 2.1882399368587215,
      "grad_norm": 0.14429421722888947,
      "learning_rate": 2.717434340768114e-05,
      "loss": 0.015,
      "step": 11090
    },
    {
      "epoch": 2.1902131018153117,
      "grad_norm": 0.17965610325336456,
      "learning_rate": 2.7108354229906298e-05,
      "loss": 0.0138,
      "step": 11100
    },
    {
      "epoch": 2.1921862667719023,
      "grad_norm": 0.15140415728092194,
      "learning_rate": 2.704236505213145e-05,
      "loss": 0.0169,
      "step": 11110
    },
    {
      "epoch": 2.1941594317284925,
      "grad_norm": 0.2199704647064209,
      "learning_rate": 2.6976375874356607e-05,
      "loss": 0.0177,
      "step": 11120
    },
    {
      "epoch": 2.196132596685083,
      "grad_norm": 0.07525159418582916,
      "learning_rate": 2.6910386696581763e-05,
      "loss": 0.0121,
      "step": 11130
    },
    {
      "epoch": 2.1981057616416733,
      "grad_norm": 0.17035099864006042,
      "learning_rate": 2.684439751880692e-05,
      "loss": 0.0121,
      "step": 11140
    },
    {
      "epoch": 2.2000789265982634,
      "grad_norm": 0.11391398310661316,
      "learning_rate": 2.6778408341032073e-05,
      "loss": 0.0133,
      "step": 11150
    },
    {
      "epoch": 2.202052091554854,
      "grad_norm": 0.16046789288520813,
      "learning_rate": 2.671241916325723e-05,
      "loss": 0.0153,
      "step": 11160
    },
    {
      "epoch": 2.204025256511444,
      "grad_norm": 0.08471178263425827,
      "learning_rate": 2.664642998548238e-05,
      "loss": 0.0136,
      "step": 11170
    },
    {
      "epoch": 2.205998421468035,
      "grad_norm": 0.10773582011461258,
      "learning_rate": 2.6580440807707535e-05,
      "loss": 0.0121,
      "step": 11180
    },
    {
      "epoch": 2.207971586424625,
      "grad_norm": 0.10292243212461472,
      "learning_rate": 2.651445162993269e-05,
      "loss": 0.0169,
      "step": 11190
    },
    {
      "epoch": 2.2099447513812156,
      "grad_norm": 0.13758698105812073,
      "learning_rate": 2.6448462452157844e-05,
      "loss": 0.0153,
      "step": 11200
    },
    {
      "epoch": 2.2119179163378058,
      "grad_norm": 0.13651293516159058,
      "learning_rate": 2.6382473274383e-05,
      "loss": 0.0174,
      "step": 11210
    },
    {
      "epoch": 2.2138910812943964,
      "grad_norm": 0.17223452031612396,
      "learning_rate": 2.6316484096608157e-05,
      "loss": 0.016,
      "step": 11220
    },
    {
      "epoch": 2.2158642462509865,
      "grad_norm": 0.1826726794242859,
      "learning_rate": 2.6250494918833314e-05,
      "loss": 0.0181,
      "step": 11230
    },
    {
      "epoch": 2.217837411207577,
      "grad_norm": 0.18980707228183746,
      "learning_rate": 2.6184505741058467e-05,
      "loss": 0.0089,
      "step": 11240
    },
    {
      "epoch": 2.2198105761641673,
      "grad_norm": 0.14488252997398376,
      "learning_rate": 2.6118516563283623e-05,
      "loss": 0.0154,
      "step": 11250
    },
    {
      "epoch": 2.2217837411207575,
      "grad_norm": 0.3006856143474579,
      "learning_rate": 2.605252738550878e-05,
      "loss": 0.0176,
      "step": 11260
    },
    {
      "epoch": 2.223756906077348,
      "grad_norm": 0.13158468902111053,
      "learning_rate": 2.5986538207733936e-05,
      "loss": 0.0134,
      "step": 11270
    },
    {
      "epoch": 2.2257300710339383,
      "grad_norm": 0.08144976198673248,
      "learning_rate": 2.592054902995909e-05,
      "loss": 0.0211,
      "step": 11280
    },
    {
      "epoch": 2.227703235990529,
      "grad_norm": 0.12375402450561523,
      "learning_rate": 2.5854559852184242e-05,
      "loss": 0.0128,
      "step": 11290
    },
    {
      "epoch": 2.229676400947119,
      "grad_norm": 0.12019075453281403,
      "learning_rate": 2.5788570674409395e-05,
      "loss": 0.0184,
      "step": 11300
    },
    {
      "epoch": 2.2316495659037097,
      "grad_norm": 0.08907626569271088,
      "learning_rate": 2.572258149663455e-05,
      "loss": 0.0113,
      "step": 11310
    },
    {
      "epoch": 2.2336227308603,
      "grad_norm": 0.1253035068511963,
      "learning_rate": 2.5656592318859708e-05,
      "loss": 0.0158,
      "step": 11320
    },
    {
      "epoch": 2.2355958958168904,
      "grad_norm": 0.1583939790725708,
      "learning_rate": 2.5590603141084864e-05,
      "loss": 0.0186,
      "step": 11330
    },
    {
      "epoch": 2.2375690607734806,
      "grad_norm": 0.18481393158435822,
      "learning_rate": 2.5524613963310017e-05,
      "loss": 0.0165,
      "step": 11340
    },
    {
      "epoch": 2.2395422257300712,
      "grad_norm": 0.5341671705245972,
      "learning_rate": 2.5458624785535173e-05,
      "loss": 0.0174,
      "step": 11350
    },
    {
      "epoch": 2.2415153906866614,
      "grad_norm": 0.11883227527141571,
      "learning_rate": 2.539263560776033e-05,
      "loss": 0.0112,
      "step": 11360
    },
    {
      "epoch": 2.2434885556432516,
      "grad_norm": 0.16761581599712372,
      "learning_rate": 2.5326646429985486e-05,
      "loss": 0.0169,
      "step": 11370
    },
    {
      "epoch": 2.245461720599842,
      "grad_norm": 0.26282015442848206,
      "learning_rate": 2.526065725221064e-05,
      "loss": 0.0165,
      "step": 11380
    },
    {
      "epoch": 2.2474348855564323,
      "grad_norm": 0.18581873178482056,
      "learning_rate": 2.5194668074435795e-05,
      "loss": 0.0126,
      "step": 11390
    },
    {
      "epoch": 2.249408050513023,
      "grad_norm": 0.21303105354309082,
      "learning_rate": 2.5128678896660952e-05,
      "loss": 0.0173,
      "step": 11400
    },
    {
      "epoch": 2.251381215469613,
      "grad_norm": 0.058555636554956436,
      "learning_rate": 2.5062689718886105e-05,
      "loss": 0.0152,
      "step": 11410
    },
    {
      "epoch": 2.2533543804262037,
      "grad_norm": 0.3446879982948303,
      "learning_rate": 2.4996700541111258e-05,
      "loss": 0.0182,
      "step": 11420
    },
    {
      "epoch": 2.255327545382794,
      "grad_norm": 0.1620585322380066,
      "learning_rate": 2.4930711363336414e-05,
      "loss": 0.0127,
      "step": 11430
    },
    {
      "epoch": 2.2573007103393845,
      "grad_norm": 0.1646968573331833,
      "learning_rate": 2.486472218556157e-05,
      "loss": 0.0123,
      "step": 11440
    },
    {
      "epoch": 2.2592738752959747,
      "grad_norm": 0.2053695023059845,
      "learning_rate": 2.4798733007786724e-05,
      "loss": 0.0156,
      "step": 11450
    },
    {
      "epoch": 2.2612470402525653,
      "grad_norm": 0.5083580017089844,
      "learning_rate": 2.473274383001188e-05,
      "loss": 0.0168,
      "step": 11460
    },
    {
      "epoch": 2.2632202052091555,
      "grad_norm": 0.24920375645160675,
      "learning_rate": 2.4666754652237033e-05,
      "loss": 0.0197,
      "step": 11470
    },
    {
      "epoch": 2.265193370165746,
      "grad_norm": 0.1614125669002533,
      "learning_rate": 2.460076547446219e-05,
      "loss": 0.0149,
      "step": 11480
    },
    {
      "epoch": 2.2671665351223362,
      "grad_norm": 0.11340641975402832,
      "learning_rate": 2.4534776296687346e-05,
      "loss": 0.0144,
      "step": 11490
    },
    {
      "epoch": 2.2691397000789264,
      "grad_norm": 0.19410626590251923,
      "learning_rate": 2.4468787118912502e-05,
      "loss": 0.0125,
      "step": 11500
    },
    {
      "epoch": 2.271112865035517,
      "grad_norm": 0.12450554221868515,
      "learning_rate": 2.4402797941137652e-05,
      "loss": 0.0206,
      "step": 11510
    },
    {
      "epoch": 2.273086029992107,
      "grad_norm": 0.21593208611011505,
      "learning_rate": 2.4336808763362808e-05,
      "loss": 0.0182,
      "step": 11520
    },
    {
      "epoch": 2.275059194948698,
      "grad_norm": 0.06589008122682571,
      "learning_rate": 2.4270819585587965e-05,
      "loss": 0.0154,
      "step": 11530
    },
    {
      "epoch": 2.277032359905288,
      "grad_norm": 0.07741496711969376,
      "learning_rate": 2.420483040781312e-05,
      "loss": 0.0132,
      "step": 11540
    },
    {
      "epoch": 2.2790055248618786,
      "grad_norm": 0.03137325495481491,
      "learning_rate": 2.4138841230038274e-05,
      "loss": 0.0187,
      "step": 11550
    },
    {
      "epoch": 2.2809786898184687,
      "grad_norm": 0.26911744475364685,
      "learning_rate": 2.407285205226343e-05,
      "loss": 0.013,
      "step": 11560
    },
    {
      "epoch": 2.2829518547750594,
      "grad_norm": 0.17720207571983337,
      "learning_rate": 2.4006862874488583e-05,
      "loss": 0.0222,
      "step": 11570
    },
    {
      "epoch": 2.2849250197316495,
      "grad_norm": 0.1535417139530182,
      "learning_rate": 2.394087369671374e-05,
      "loss": 0.0186,
      "step": 11580
    },
    {
      "epoch": 2.2868981846882397,
      "grad_norm": 0.22644929587841034,
      "learning_rate": 2.3874884518938896e-05,
      "loss": 0.0176,
      "step": 11590
    },
    {
      "epoch": 2.2888713496448303,
      "grad_norm": 0.18689106404781342,
      "learning_rate": 2.380889534116405e-05,
      "loss": 0.0186,
      "step": 11600
    },
    {
      "epoch": 2.290844514601421,
      "grad_norm": 0.2085551768541336,
      "learning_rate": 2.3742906163389205e-05,
      "loss": 0.0183,
      "step": 11610
    },
    {
      "epoch": 2.292817679558011,
      "grad_norm": 0.017102530226111412,
      "learning_rate": 2.3676916985614362e-05,
      "loss": 0.0086,
      "step": 11620
    },
    {
      "epoch": 2.2947908445146012,
      "grad_norm": 0.20087788999080658,
      "learning_rate": 2.3610927807839515e-05,
      "loss": 0.0147,
      "step": 11630
    },
    {
      "epoch": 2.296764009471192,
      "grad_norm": 0.14673765003681183,
      "learning_rate": 2.354493863006467e-05,
      "loss": 0.0182,
      "step": 11640
    },
    {
      "epoch": 2.298737174427782,
      "grad_norm": 0.2597208321094513,
      "learning_rate": 2.3478949452289824e-05,
      "loss": 0.0172,
      "step": 11650
    },
    {
      "epoch": 2.3007103393843726,
      "grad_norm": 0.1315520703792572,
      "learning_rate": 2.341296027451498e-05,
      "loss": 0.0177,
      "step": 11660
    },
    {
      "epoch": 2.302683504340963,
      "grad_norm": 0.07392944395542145,
      "learning_rate": 2.3346971096740137e-05,
      "loss": 0.0119,
      "step": 11670
    },
    {
      "epoch": 2.3046566692975534,
      "grad_norm": 0.2941723167896271,
      "learning_rate": 2.3280981918965293e-05,
      "loss": 0.0183,
      "step": 11680
    },
    {
      "epoch": 2.3066298342541436,
      "grad_norm": 0.05311223864555359,
      "learning_rate": 2.3214992741190446e-05,
      "loss": 0.0121,
      "step": 11690
    },
    {
      "epoch": 2.308602999210734,
      "grad_norm": 0.16639643907546997,
      "learning_rate": 2.31490035634156e-05,
      "loss": 0.0144,
      "step": 11700
    },
    {
      "epoch": 2.3105761641673244,
      "grad_norm": 0.16861340403556824,
      "learning_rate": 2.3083014385640756e-05,
      "loss": 0.0125,
      "step": 11710
    },
    {
      "epoch": 2.3125493291239145,
      "grad_norm": 0.1687869280576706,
      "learning_rate": 2.3017025207865912e-05,
      "loss": 0.0089,
      "step": 11720
    },
    {
      "epoch": 2.314522494080505,
      "grad_norm": 0.20219503343105316,
      "learning_rate": 2.2951036030091065e-05,
      "loss": 0.023,
      "step": 11730
    },
    {
      "epoch": 2.3164956590370953,
      "grad_norm": 0.21259808540344238,
      "learning_rate": 2.288504685231622e-05,
      "loss": 0.0179,
      "step": 11740
    },
    {
      "epoch": 2.318468823993686,
      "grad_norm": 0.08551251143217087,
      "learning_rate": 2.2819057674541378e-05,
      "loss": 0.0152,
      "step": 11750
    },
    {
      "epoch": 2.320441988950276,
      "grad_norm": 0.14919652044773102,
      "learning_rate": 2.275306849676653e-05,
      "loss": 0.0156,
      "step": 11760
    },
    {
      "epoch": 2.3224151539068667,
      "grad_norm": 0.2897298038005829,
      "learning_rate": 2.2687079318991687e-05,
      "loss": 0.0148,
      "step": 11770
    },
    {
      "epoch": 2.324388318863457,
      "grad_norm": 0.12660452723503113,
      "learning_rate": 2.262109014121684e-05,
      "loss": 0.0111,
      "step": 11780
    },
    {
      "epoch": 2.3263614838200475,
      "grad_norm": 0.1528996080160141,
      "learning_rate": 2.2555100963441997e-05,
      "loss": 0.0135,
      "step": 11790
    },
    {
      "epoch": 2.3283346487766376,
      "grad_norm": 0.2004353106021881,
      "learning_rate": 2.2489111785667153e-05,
      "loss": 0.0146,
      "step": 11800
    },
    {
      "epoch": 2.3303078137332283,
      "grad_norm": 0.13253676891326904,
      "learning_rate": 2.242312260789231e-05,
      "loss": 0.0182,
      "step": 11810
    },
    {
      "epoch": 2.3322809786898184,
      "grad_norm": 0.17632527649402618,
      "learning_rate": 2.235713343011746e-05,
      "loss": 0.0125,
      "step": 11820
    },
    {
      "epoch": 2.334254143646409,
      "grad_norm": 0.04249212518334389,
      "learning_rate": 2.2291144252342615e-05,
      "loss": 0.0137,
      "step": 11830
    },
    {
      "epoch": 2.336227308602999,
      "grad_norm": 0.3144665062427521,
      "learning_rate": 2.2225155074567772e-05,
      "loss": 0.0143,
      "step": 11840
    },
    {
      "epoch": 2.3382004735595894,
      "grad_norm": 0.03493059426546097,
      "learning_rate": 2.2159165896792928e-05,
      "loss": 0.0089,
      "step": 11850
    },
    {
      "epoch": 2.34017363851618,
      "grad_norm": 0.128574937582016,
      "learning_rate": 2.209317671901808e-05,
      "loss": 0.0189,
      "step": 11860
    },
    {
      "epoch": 2.34214680347277,
      "grad_norm": 0.17086441814899445,
      "learning_rate": 2.2027187541243238e-05,
      "loss": 0.0172,
      "step": 11870
    },
    {
      "epoch": 2.3441199684293608,
      "grad_norm": 0.47226211428642273,
      "learning_rate": 2.196119836346839e-05,
      "loss": 0.0191,
      "step": 11880
    },
    {
      "epoch": 2.346093133385951,
      "grad_norm": 0.11879262328147888,
      "learning_rate": 2.1895209185693547e-05,
      "loss": 0.0218,
      "step": 11890
    },
    {
      "epoch": 2.3480662983425415,
      "grad_norm": 0.3394688367843628,
      "learning_rate": 2.1829220007918703e-05,
      "loss": 0.019,
      "step": 11900
    },
    {
      "epoch": 2.3500394632991317,
      "grad_norm": 0.14427120983600616,
      "learning_rate": 2.1763230830143856e-05,
      "loss": 0.0152,
      "step": 11910
    },
    {
      "epoch": 2.3520126282557223,
      "grad_norm": 0.11346928775310516,
      "learning_rate": 2.1697241652369013e-05,
      "loss": 0.0133,
      "step": 11920
    },
    {
      "epoch": 2.3539857932123125,
      "grad_norm": 0.20379361510276794,
      "learning_rate": 2.163125247459417e-05,
      "loss": 0.0151,
      "step": 11930
    },
    {
      "epoch": 2.355958958168903,
      "grad_norm": 0.12168699502944946,
      "learning_rate": 2.1565263296819322e-05,
      "loss": 0.0201,
      "step": 11940
    },
    {
      "epoch": 2.3579321231254933,
      "grad_norm": 0.053486403077840805,
      "learning_rate": 2.149927411904448e-05,
      "loss": 0.0169,
      "step": 11950
    },
    {
      "epoch": 2.359905288082084,
      "grad_norm": 0.08562849462032318,
      "learning_rate": 2.143328494126963e-05,
      "loss": 0.0158,
      "step": 11960
    },
    {
      "epoch": 2.361878453038674,
      "grad_norm": 0.19360806047916412,
      "learning_rate": 2.1367295763494788e-05,
      "loss": 0.014,
      "step": 11970
    },
    {
      "epoch": 2.363851617995264,
      "grad_norm": 0.13589729368686676,
      "learning_rate": 2.1301306585719944e-05,
      "loss": 0.0136,
      "step": 11980
    },
    {
      "epoch": 2.365824782951855,
      "grad_norm": 0.10065235197544098,
      "learning_rate": 2.1235317407945097e-05,
      "loss": 0.0168,
      "step": 11990
    },
    {
      "epoch": 2.367797947908445,
      "grad_norm": 0.3040347397327423,
      "learning_rate": 2.1169328230170254e-05,
      "loss": 0.0159,
      "step": 12000
    },
    {
      "epoch": 2.3697711128650356,
      "grad_norm": 0.13525700569152832,
      "learning_rate": 2.1103339052395407e-05,
      "loss": 0.0199,
      "step": 12010
    },
    {
      "epoch": 2.371744277821626,
      "grad_norm": 0.2693080008029938,
      "learning_rate": 2.1037349874620563e-05,
      "loss": 0.0217,
      "step": 12020
    },
    {
      "epoch": 2.3737174427782164,
      "grad_norm": 0.2760089039802551,
      "learning_rate": 2.097136069684572e-05,
      "loss": 0.0233,
      "step": 12030
    },
    {
      "epoch": 2.3756906077348066,
      "grad_norm": 0.37676626443862915,
      "learning_rate": 2.0905371519070872e-05,
      "loss": 0.0229,
      "step": 12040
    },
    {
      "epoch": 2.377663772691397,
      "grad_norm": 0.13651688396930695,
      "learning_rate": 2.083938234129603e-05,
      "loss": 0.0088,
      "step": 12050
    },
    {
      "epoch": 2.3796369376479873,
      "grad_norm": 0.0789947435259819,
      "learning_rate": 2.0773393163521185e-05,
      "loss": 0.0112,
      "step": 12060
    },
    {
      "epoch": 2.3816101026045775,
      "grad_norm": 0.30309760570526123,
      "learning_rate": 2.0707403985746338e-05,
      "loss": 0.0104,
      "step": 12070
    },
    {
      "epoch": 2.383583267561168,
      "grad_norm": 0.1975751519203186,
      "learning_rate": 2.0641414807971495e-05,
      "loss": 0.0163,
      "step": 12080
    },
    {
      "epoch": 2.3855564325177587,
      "grad_norm": 0.01815718039870262,
      "learning_rate": 2.0575425630196648e-05,
      "loss": 0.0169,
      "step": 12090
    },
    {
      "epoch": 2.387529597474349,
      "grad_norm": 0.20752708613872528,
      "learning_rate": 2.0509436452421804e-05,
      "loss": 0.0162,
      "step": 12100
    },
    {
      "epoch": 2.389502762430939,
      "grad_norm": 0.2519140839576721,
      "learning_rate": 2.044344727464696e-05,
      "loss": 0.0147,
      "step": 12110
    },
    {
      "epoch": 2.3914759273875297,
      "grad_norm": 0.1741892248392105,
      "learning_rate": 2.0377458096872117e-05,
      "loss": 0.0231,
      "step": 12120
    },
    {
      "epoch": 2.39344909234412,
      "grad_norm": 0.17880646884441376,
      "learning_rate": 2.0311468919097266e-05,
      "loss": 0.021,
      "step": 12130
    },
    {
      "epoch": 2.3954222573007105,
      "grad_norm": 0.16072934865951538,
      "learning_rate": 2.0245479741322423e-05,
      "loss": 0.0119,
      "step": 12140
    },
    {
      "epoch": 2.3973954222573006,
      "grad_norm": 0.19727370142936707,
      "learning_rate": 2.017949056354758e-05,
      "loss": 0.0169,
      "step": 12150
    },
    {
      "epoch": 2.3993685872138912,
      "grad_norm": 0.1871306598186493,
      "learning_rate": 2.0113501385772735e-05,
      "loss": 0.0186,
      "step": 12160
    },
    {
      "epoch": 2.4013417521704814,
      "grad_norm": 0.12824024260044098,
      "learning_rate": 2.004751220799789e-05,
      "loss": 0.0155,
      "step": 12170
    },
    {
      "epoch": 2.403314917127072,
      "grad_norm": 0.10366827249526978,
      "learning_rate": 1.9981523030223045e-05,
      "loss": 0.0153,
      "step": 12180
    },
    {
      "epoch": 2.405288082083662,
      "grad_norm": 0.2743641138076782,
      "learning_rate": 1.9915533852448198e-05,
      "loss": 0.0136,
      "step": 12190
    },
    {
      "epoch": 2.4072612470402523,
      "grad_norm": 0.11443241685628891,
      "learning_rate": 1.9849544674673354e-05,
      "loss": 0.0107,
      "step": 12200
    },
    {
      "epoch": 2.409234411996843,
      "grad_norm": 0.04313557967543602,
      "learning_rate": 1.978355549689851e-05,
      "loss": 0.0131,
      "step": 12210
    },
    {
      "epoch": 2.411207576953433,
      "grad_norm": 0.26019051671028137,
      "learning_rate": 1.9717566319123664e-05,
      "loss": 0.0234,
      "step": 12220
    },
    {
      "epoch": 2.4131807419100237,
      "grad_norm": 0.11918699741363525,
      "learning_rate": 1.965157714134882e-05,
      "loss": 0.0152,
      "step": 12230
    },
    {
      "epoch": 2.415153906866614,
      "grad_norm": 0.153143972158432,
      "learning_rate": 1.9585587963573976e-05,
      "loss": 0.0144,
      "step": 12240
    },
    {
      "epoch": 2.4171270718232045,
      "grad_norm": 0.2030266970396042,
      "learning_rate": 1.951959878579913e-05,
      "loss": 0.0194,
      "step": 12250
    },
    {
      "epoch": 2.4191002367797947,
      "grad_norm": 0.6637263298034668,
      "learning_rate": 1.9453609608024286e-05,
      "loss": 0.029,
      "step": 12260
    },
    {
      "epoch": 2.4210734017363853,
      "grad_norm": 0.20524591207504272,
      "learning_rate": 1.938762043024944e-05,
      "loss": 0.015,
      "step": 12270
    },
    {
      "epoch": 2.4230465666929755,
      "grad_norm": 0.1307462602853775,
      "learning_rate": 1.9321631252474595e-05,
      "loss": 0.0128,
      "step": 12280
    },
    {
      "epoch": 2.425019731649566,
      "grad_norm": 0.2636010944843292,
      "learning_rate": 1.925564207469975e-05,
      "loss": 0.0188,
      "step": 12290
    },
    {
      "epoch": 2.4269928966061562,
      "grad_norm": 0.2473946213722229,
      "learning_rate": 1.9189652896924905e-05,
      "loss": 0.0206,
      "step": 12300
    },
    {
      "epoch": 2.428966061562747,
      "grad_norm": 0.09882427752017975,
      "learning_rate": 1.9123663719150058e-05,
      "loss": 0.0094,
      "step": 12310
    },
    {
      "epoch": 2.430939226519337,
      "grad_norm": 0.15585525333881378,
      "learning_rate": 1.9057674541375214e-05,
      "loss": 0.0124,
      "step": 12320
    },
    {
      "epoch": 2.432912391475927,
      "grad_norm": 0.159467875957489,
      "learning_rate": 1.899168536360037e-05,
      "loss": 0.0159,
      "step": 12330
    },
    {
      "epoch": 2.434885556432518,
      "grad_norm": 0.1401521861553192,
      "learning_rate": 1.8925696185825527e-05,
      "loss": 0.0166,
      "step": 12340
    },
    {
      "epoch": 2.436858721389108,
      "grad_norm": 0.22117164731025696,
      "learning_rate": 1.885970700805068e-05,
      "loss": 0.018,
      "step": 12350
    },
    {
      "epoch": 2.4388318863456986,
      "grad_norm": 0.04899585619568825,
      "learning_rate": 1.8793717830275836e-05,
      "loss": 0.0163,
      "step": 12360
    },
    {
      "epoch": 2.4408050513022888,
      "grad_norm": 0.22529545426368713,
      "learning_rate": 1.8727728652500992e-05,
      "loss": 0.0206,
      "step": 12370
    },
    {
      "epoch": 2.4427782162588794,
      "grad_norm": 0.27881816029548645,
      "learning_rate": 1.8661739474726145e-05,
      "loss": 0.0185,
      "step": 12380
    },
    {
      "epoch": 2.4447513812154695,
      "grad_norm": 0.12976066768169403,
      "learning_rate": 1.8595750296951302e-05,
      "loss": 0.0201,
      "step": 12390
    },
    {
      "epoch": 2.44672454617206,
      "grad_norm": 0.2223885953426361,
      "learning_rate": 1.8529761119176455e-05,
      "loss": 0.015,
      "step": 12400
    },
    {
      "epoch": 2.4486977111286503,
      "grad_norm": 0.23674693703651428,
      "learning_rate": 1.846377194140161e-05,
      "loss": 0.0184,
      "step": 12410
    },
    {
      "epoch": 2.4506708760852405,
      "grad_norm": 0.22314108908176422,
      "learning_rate": 1.8397782763626768e-05,
      "loss": 0.0169,
      "step": 12420
    },
    {
      "epoch": 2.452644041041831,
      "grad_norm": 0.22311511635780334,
      "learning_rate": 1.8331793585851924e-05,
      "loss": 0.0157,
      "step": 12430
    },
    {
      "epoch": 2.4546172059984217,
      "grad_norm": 0.1064213439822197,
      "learning_rate": 1.8265804408077074e-05,
      "loss": 0.0129,
      "step": 12440
    },
    {
      "epoch": 2.456590370955012,
      "grad_norm": 0.18145298957824707,
      "learning_rate": 1.819981523030223e-05,
      "loss": 0.0214,
      "step": 12450
    },
    {
      "epoch": 2.458563535911602,
      "grad_norm": 0.11188662052154541,
      "learning_rate": 1.8133826052527386e-05,
      "loss": 0.0134,
      "step": 12460
    },
    {
      "epoch": 2.4605367008681926,
      "grad_norm": 0.274753212928772,
      "learning_rate": 1.8067836874752543e-05,
      "loss": 0.0248,
      "step": 12470
    },
    {
      "epoch": 2.462509865824783,
      "grad_norm": 0.1440259963274002,
      "learning_rate": 1.8001847696977696e-05,
      "loss": 0.0158,
      "step": 12480
    },
    {
      "epoch": 2.4644830307813734,
      "grad_norm": 0.28630220890045166,
      "learning_rate": 1.7935858519202852e-05,
      "loss": 0.0172,
      "step": 12490
    },
    {
      "epoch": 2.4664561957379636,
      "grad_norm": 0.2432791292667389,
      "learning_rate": 1.7869869341428005e-05,
      "loss": 0.0175,
      "step": 12500
    },
    {
      "epoch": 2.4664561957379636,
      "eval_loss": 0.016363555565476418,
      "eval_runtime": 80.4163,
      "eval_samples_per_second": 14.015,
      "eval_steps_per_second": 7.014,
      "step": 12500
    },
    {
      "epoch": 2.468429360694554,
      "grad_norm": 0.11402080208063126,
      "learning_rate": 1.780388016365316e-05,
      "loss": 0.0135,
      "step": 12510
    },
    {
      "epoch": 2.4704025256511444,
      "grad_norm": 0.10349717736244202,
      "learning_rate": 1.7737890985878318e-05,
      "loss": 0.0117,
      "step": 12520
    },
    {
      "epoch": 2.472375690607735,
      "grad_norm": 0.17022712528705597,
      "learning_rate": 1.767190180810347e-05,
      "loss": 0.0157,
      "step": 12530
    },
    {
      "epoch": 2.474348855564325,
      "grad_norm": 0.20506727695465088,
      "learning_rate": 1.7605912630328627e-05,
      "loss": 0.0175,
      "step": 12540
    },
    {
      "epoch": 2.4763220205209153,
      "grad_norm": 0.17457932233810425,
      "learning_rate": 1.7539923452553784e-05,
      "loss": 0.0143,
      "step": 12550
    },
    {
      "epoch": 2.478295185477506,
      "grad_norm": 0.2301311492919922,
      "learning_rate": 1.7473934274778937e-05,
      "loss": 0.0123,
      "step": 12560
    },
    {
      "epoch": 2.480268350434096,
      "grad_norm": 0.14285331964492798,
      "learning_rate": 1.740794509700409e-05,
      "loss": 0.0113,
      "step": 12570
    },
    {
      "epoch": 2.4822415153906867,
      "grad_norm": 0.2803772985935211,
      "learning_rate": 1.7341955919229246e-05,
      "loss": 0.0191,
      "step": 12580
    },
    {
      "epoch": 2.484214680347277,
      "grad_norm": 0.1817554384469986,
      "learning_rate": 1.7275966741454402e-05,
      "loss": 0.0147,
      "step": 12590
    },
    {
      "epoch": 2.4861878453038675,
      "grad_norm": 0.3449658453464508,
      "learning_rate": 1.720997756367956e-05,
      "loss": 0.0215,
      "step": 12600
    },
    {
      "epoch": 2.4881610102604577,
      "grad_norm": 0.25700294971466064,
      "learning_rate": 1.7143988385904712e-05,
      "loss": 0.0186,
      "step": 12610
    },
    {
      "epoch": 2.4901341752170483,
      "grad_norm": 0.11483268439769745,
      "learning_rate": 1.7077999208129865e-05,
      "loss": 0.0152,
      "step": 12620
    },
    {
      "epoch": 2.4921073401736384,
      "grad_norm": 0.2975009083747864,
      "learning_rate": 1.701201003035502e-05,
      "loss": 0.0161,
      "step": 12630
    },
    {
      "epoch": 2.494080505130229,
      "grad_norm": 0.2210029661655426,
      "learning_rate": 1.6946020852580178e-05,
      "loss": 0.0121,
      "step": 12640
    },
    {
      "epoch": 2.496053670086819,
      "grad_norm": 0.19657747447490692,
      "learning_rate": 1.6880031674805334e-05,
      "loss": 0.0146,
      "step": 12650
    },
    {
      "epoch": 2.49802683504341,
      "grad_norm": 0.03979278355836868,
      "learning_rate": 1.6814042497030487e-05,
      "loss": 0.0177,
      "step": 12660
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.16021546721458435,
      "learning_rate": 1.6748053319255643e-05,
      "loss": 0.0172,
      "step": 12670
    },
    {
      "epoch": 2.50197316495659,
      "grad_norm": 0.13421882688999176,
      "learning_rate": 1.66820641414808e-05,
      "loss": 0.0118,
      "step": 12680
    },
    {
      "epoch": 2.503946329913181,
      "grad_norm": 0.18269431591033936,
      "learning_rate": 1.6616074963705953e-05,
      "loss": 0.0148,
      "step": 12690
    },
    {
      "epoch": 2.505919494869771,
      "grad_norm": 0.1979880928993225,
      "learning_rate": 1.655008578593111e-05,
      "loss": 0.0181,
      "step": 12700
    },
    {
      "epoch": 2.5078926598263616,
      "grad_norm": 0.17458586394786835,
      "learning_rate": 1.6484096608156262e-05,
      "loss": 0.0191,
      "step": 12710
    },
    {
      "epoch": 2.5098658247829517,
      "grad_norm": 0.09997473657131195,
      "learning_rate": 1.641810743038142e-05,
      "loss": 0.0134,
      "step": 12720
    },
    {
      "epoch": 2.5118389897395423,
      "grad_norm": 0.18743698298931122,
      "learning_rate": 1.6352118252606575e-05,
      "loss": 0.0203,
      "step": 12730
    },
    {
      "epoch": 2.5138121546961325,
      "grad_norm": 0.06052471324801445,
      "learning_rate": 1.628612907483173e-05,
      "loss": 0.0178,
      "step": 12740
    },
    {
      "epoch": 2.515785319652723,
      "grad_norm": 0.07486431300640106,
      "learning_rate": 1.622013989705688e-05,
      "loss": 0.0146,
      "step": 12750
    },
    {
      "epoch": 2.5177584846093133,
      "grad_norm": 0.11353680491447449,
      "learning_rate": 1.6154150719282037e-05,
      "loss": 0.01,
      "step": 12760
    },
    {
      "epoch": 2.5197316495659035,
      "grad_norm": 0.2364278882741928,
      "learning_rate": 1.6088161541507194e-05,
      "loss": 0.0179,
      "step": 12770
    },
    {
      "epoch": 2.521704814522494,
      "grad_norm": 0.15155281126499176,
      "learning_rate": 1.602217236373235e-05,
      "loss": 0.0137,
      "step": 12780
    },
    {
      "epoch": 2.5236779794790847,
      "grad_norm": 0.29393836855888367,
      "learning_rate": 1.5956183185957503e-05,
      "loss": 0.0152,
      "step": 12790
    },
    {
      "epoch": 2.525651144435675,
      "grad_norm": 0.10502959042787552,
      "learning_rate": 1.589019400818266e-05,
      "loss": 0.0143,
      "step": 12800
    },
    {
      "epoch": 2.527624309392265,
      "grad_norm": 0.06607748568058014,
      "learning_rate": 1.5824204830407812e-05,
      "loss": 0.0145,
      "step": 12810
    },
    {
      "epoch": 2.5295974743488556,
      "grad_norm": 0.07470493763685226,
      "learning_rate": 1.575821565263297e-05,
      "loss": 0.0151,
      "step": 12820
    },
    {
      "epoch": 2.531570639305446,
      "grad_norm": 0.2480611503124237,
      "learning_rate": 1.5692226474858125e-05,
      "loss": 0.0139,
      "step": 12830
    },
    {
      "epoch": 2.5335438042620364,
      "grad_norm": 0.26625755429267883,
      "learning_rate": 1.5626237297083278e-05,
      "loss": 0.0163,
      "step": 12840
    },
    {
      "epoch": 2.5355169692186266,
      "grad_norm": 0.18107199668884277,
      "learning_rate": 1.5560248119308435e-05,
      "loss": 0.0144,
      "step": 12850
    },
    {
      "epoch": 2.537490134175217,
      "grad_norm": 0.1838533878326416,
      "learning_rate": 1.549425894153359e-05,
      "loss": 0.0117,
      "step": 12860
    },
    {
      "epoch": 2.5394632991318074,
      "grad_norm": 0.2751568555831909,
      "learning_rate": 1.5428269763758744e-05,
      "loss": 0.0207,
      "step": 12870
    },
    {
      "epoch": 2.541436464088398,
      "grad_norm": 0.18992358446121216,
      "learning_rate": 1.5362280585983897e-05,
      "loss": 0.0099,
      "step": 12880
    },
    {
      "epoch": 2.543409629044988,
      "grad_norm": 0.1407807469367981,
      "learning_rate": 1.5296291408209053e-05,
      "loss": 0.0112,
      "step": 12890
    },
    {
      "epoch": 2.5453827940015783,
      "grad_norm": 0.15933576226234436,
      "learning_rate": 1.523030223043421e-05,
      "loss": 0.0169,
      "step": 12900
    },
    {
      "epoch": 2.547355958958169,
      "grad_norm": 0.26732704043388367,
      "learning_rate": 1.5164313052659364e-05,
      "loss": 0.0121,
      "step": 12910
    },
    {
      "epoch": 2.5493291239147595,
      "grad_norm": 0.14235492050647736,
      "learning_rate": 1.5098323874884521e-05,
      "loss": 0.0181,
      "step": 12920
    },
    {
      "epoch": 2.5513022888713497,
      "grad_norm": 0.1642409712076187,
      "learning_rate": 1.5032334697109674e-05,
      "loss": 0.0139,
      "step": 12930
    },
    {
      "epoch": 2.55327545382794,
      "grad_norm": 0.3355788588523865,
      "learning_rate": 1.4966345519334829e-05,
      "loss": 0.0156,
      "step": 12940
    },
    {
      "epoch": 2.5552486187845305,
      "grad_norm": 0.21339504420757294,
      "learning_rate": 1.4900356341559985e-05,
      "loss": 0.0141,
      "step": 12950
    },
    {
      "epoch": 2.5572217837411206,
      "grad_norm": 0.18554823100566864,
      "learning_rate": 1.483436716378514e-05,
      "loss": 0.0148,
      "step": 12960
    },
    {
      "epoch": 2.5591949486977112,
      "grad_norm": 0.2602066397666931,
      "learning_rate": 1.4768377986010296e-05,
      "loss": 0.0184,
      "step": 12970
    },
    {
      "epoch": 2.5611681136543014,
      "grad_norm": 0.17989756166934967,
      "learning_rate": 1.470238880823545e-05,
      "loss": 0.0158,
      "step": 12980
    },
    {
      "epoch": 2.563141278610892,
      "grad_norm": 0.14282208681106567,
      "learning_rate": 1.4636399630460604e-05,
      "loss": 0.0149,
      "step": 12990
    },
    {
      "epoch": 2.565114443567482,
      "grad_norm": 0.05200176686048508,
      "learning_rate": 1.457041045268576e-05,
      "loss": 0.0151,
      "step": 13000
    },
    {
      "epoch": 2.567087608524073,
      "grad_norm": 0.060547616332769394,
      "learning_rate": 1.4504421274910915e-05,
      "loss": 0.0134,
      "step": 13010
    },
    {
      "epoch": 2.569060773480663,
      "grad_norm": 0.23700693249702454,
      "learning_rate": 1.4438432097136071e-05,
      "loss": 0.0162,
      "step": 13020
    },
    {
      "epoch": 2.571033938437253,
      "grad_norm": 0.15643970668315887,
      "learning_rate": 1.4372442919361226e-05,
      "loss": 0.0147,
      "step": 13030
    },
    {
      "epoch": 2.5730071033938438,
      "grad_norm": 0.20745235681533813,
      "learning_rate": 1.4306453741586382e-05,
      "loss": 0.0186,
      "step": 13040
    },
    {
      "epoch": 2.5749802683504344,
      "grad_norm": 0.2026422917842865,
      "learning_rate": 1.4240464563811537e-05,
      "loss": 0.0213,
      "step": 13050
    },
    {
      "epoch": 2.5769534333070245,
      "grad_norm": 0.08719753473997116,
      "learning_rate": 1.417447538603669e-05,
      "loss": 0.0165,
      "step": 13060
    },
    {
      "epoch": 2.5789265982636147,
      "grad_norm": 0.1469651162624359,
      "learning_rate": 1.4108486208261845e-05,
      "loss": 0.0186,
      "step": 13070
    },
    {
      "epoch": 2.5808997632202053,
      "grad_norm": 0.12112220376729965,
      "learning_rate": 1.4042497030487001e-05,
      "loss": 0.0145,
      "step": 13080
    },
    {
      "epoch": 2.5828729281767955,
      "grad_norm": 0.056127551943063736,
      "learning_rate": 1.3976507852712156e-05,
      "loss": 0.0164,
      "step": 13090
    },
    {
      "epoch": 2.584846093133386,
      "grad_norm": 0.11927609145641327,
      "learning_rate": 1.3910518674937312e-05,
      "loss": 0.0169,
      "step": 13100
    },
    {
      "epoch": 2.5868192580899763,
      "grad_norm": 0.3103683292865753,
      "learning_rate": 1.3844529497162467e-05,
      "loss": 0.0207,
      "step": 13110
    },
    {
      "epoch": 2.5887924230465664,
      "grad_norm": 0.11148887127637863,
      "learning_rate": 1.377854031938762e-05,
      "loss": 0.0138,
      "step": 13120
    },
    {
      "epoch": 2.590765588003157,
      "grad_norm": 0.03121913969516754,
      "learning_rate": 1.3712551141612776e-05,
      "loss": 0.0127,
      "step": 13130
    },
    {
      "epoch": 2.5927387529597477,
      "grad_norm": 0.10519883781671524,
      "learning_rate": 1.364656196383793e-05,
      "loss": 0.0144,
      "step": 13140
    },
    {
      "epoch": 2.594711917916338,
      "grad_norm": 0.2140071988105774,
      "learning_rate": 1.3580572786063087e-05,
      "loss": 0.02,
      "step": 13150
    },
    {
      "epoch": 2.596685082872928,
      "grad_norm": 0.11765379458665848,
      "learning_rate": 1.3514583608288242e-05,
      "loss": 0.0129,
      "step": 13160
    },
    {
      "epoch": 2.5986582478295186,
      "grad_norm": 0.43997275829315186,
      "learning_rate": 1.3448594430513398e-05,
      "loss": 0.0156,
      "step": 13170
    },
    {
      "epoch": 2.6006314127861088,
      "grad_norm": 0.13066549599170685,
      "learning_rate": 1.338260525273855e-05,
      "loss": 0.0144,
      "step": 13180
    },
    {
      "epoch": 2.6026045777426994,
      "grad_norm": 0.15930324792861938,
      "learning_rate": 1.3316616074963706e-05,
      "loss": 0.0102,
      "step": 13190
    },
    {
      "epoch": 2.6045777426992895,
      "grad_norm": 0.27287736535072327,
      "learning_rate": 1.325062689718886e-05,
      "loss": 0.0154,
      "step": 13200
    },
    {
      "epoch": 2.60655090765588,
      "grad_norm": 0.16281245648860931,
      "learning_rate": 1.3184637719414017e-05,
      "loss": 0.011,
      "step": 13210
    },
    {
      "epoch": 2.6085240726124703,
      "grad_norm": 0.088039830327034,
      "learning_rate": 1.3118648541639172e-05,
      "loss": 0.0194,
      "step": 13220
    },
    {
      "epoch": 2.610497237569061,
      "grad_norm": 0.17117996513843536,
      "learning_rate": 1.3052659363864328e-05,
      "loss": 0.0127,
      "step": 13230
    },
    {
      "epoch": 2.612470402525651,
      "grad_norm": 0.2112882286310196,
      "learning_rate": 1.2986670186089481e-05,
      "loss": 0.0171,
      "step": 13240
    },
    {
      "epoch": 2.6144435674822413,
      "grad_norm": 0.2074137181043625,
      "learning_rate": 1.2920681008314636e-05,
      "loss": 0.0163,
      "step": 13250
    },
    {
      "epoch": 2.616416732438832,
      "grad_norm": 0.020370282232761383,
      "learning_rate": 1.2854691830539792e-05,
      "loss": 0.0163,
      "step": 13260
    },
    {
      "epoch": 2.6183898973954225,
      "grad_norm": 0.1689435839653015,
      "learning_rate": 1.2788702652764947e-05,
      "loss": 0.0142,
      "step": 13270
    },
    {
      "epoch": 2.6203630623520127,
      "grad_norm": 0.3415709435939789,
      "learning_rate": 1.2722713474990103e-05,
      "loss": 0.0176,
      "step": 13280
    },
    {
      "epoch": 2.622336227308603,
      "grad_norm": 0.2739887535572052,
      "learning_rate": 1.2656724297215258e-05,
      "loss": 0.0141,
      "step": 13290
    },
    {
      "epoch": 2.6243093922651934,
      "grad_norm": 0.237357035279274,
      "learning_rate": 1.2590735119440411e-05,
      "loss": 0.0182,
      "step": 13300
    },
    {
      "epoch": 2.6262825572217836,
      "grad_norm": 0.14784197509288788,
      "learning_rate": 1.2524745941665567e-05,
      "loss": 0.0191,
      "step": 13310
    },
    {
      "epoch": 2.628255722178374,
      "grad_norm": 0.17169784009456635,
      "learning_rate": 1.2458756763890722e-05,
      "loss": 0.0184,
      "step": 13320
    },
    {
      "epoch": 2.6302288871349644,
      "grad_norm": 0.18639607727527618,
      "learning_rate": 1.2392767586115878e-05,
      "loss": 0.0165,
      "step": 13330
    },
    {
      "epoch": 2.632202052091555,
      "grad_norm": 0.07608617842197418,
      "learning_rate": 1.2326778408341033e-05,
      "loss": 0.0096,
      "step": 13340
    },
    {
      "epoch": 2.634175217048145,
      "grad_norm": 0.2906302213668823,
      "learning_rate": 1.2260789230566188e-05,
      "loss": 0.0163,
      "step": 13350
    },
    {
      "epoch": 2.636148382004736,
      "grad_norm": 0.08143382519483566,
      "learning_rate": 1.2194800052791343e-05,
      "loss": 0.011,
      "step": 13360
    },
    {
      "epoch": 2.638121546961326,
      "grad_norm": 0.2944466769695282,
      "learning_rate": 1.2128810875016499e-05,
      "loss": 0.0095,
      "step": 13370
    },
    {
      "epoch": 2.640094711917916,
      "grad_norm": 0.35929927229881287,
      "learning_rate": 1.2062821697241652e-05,
      "loss": 0.0092,
      "step": 13380
    },
    {
      "epoch": 2.6420678768745067,
      "grad_norm": 0.21262089908123016,
      "learning_rate": 1.1996832519466808e-05,
      "loss": 0.0174,
      "step": 13390
    },
    {
      "epoch": 2.6440410418310973,
      "grad_norm": 0.2416955530643463,
      "learning_rate": 1.1930843341691963e-05,
      "loss": 0.0151,
      "step": 13400
    },
    {
      "epoch": 2.6460142067876875,
      "grad_norm": 0.12805184721946716,
      "learning_rate": 1.1864854163917118e-05,
      "loss": 0.0166,
      "step": 13410
    },
    {
      "epoch": 2.6479873717442777,
      "grad_norm": 0.26932504773139954,
      "learning_rate": 1.1798864986142272e-05,
      "loss": 0.014,
      "step": 13420
    },
    {
      "epoch": 2.6499605367008683,
      "grad_norm": 0.06870786845684052,
      "learning_rate": 1.1732875808367429e-05,
      "loss": 0.0151,
      "step": 13430
    },
    {
      "epoch": 2.6519337016574585,
      "grad_norm": 0.19767139852046967,
      "learning_rate": 1.1666886630592583e-05,
      "loss": 0.0125,
      "step": 13440
    },
    {
      "epoch": 2.653906866614049,
      "grad_norm": 0.16010425984859467,
      "learning_rate": 1.1600897452817738e-05,
      "loss": 0.013,
      "step": 13450
    },
    {
      "epoch": 2.6558800315706392,
      "grad_norm": 0.32565757632255554,
      "learning_rate": 1.1534908275042895e-05,
      "loss": 0.0107,
      "step": 13460
    },
    {
      "epoch": 2.6578531965272294,
      "grad_norm": 0.23246875405311584,
      "learning_rate": 1.1468919097268048e-05,
      "loss": 0.0134,
      "step": 13470
    },
    {
      "epoch": 2.65982636148382,
      "grad_norm": 0.2183486521244049,
      "learning_rate": 1.1402929919493204e-05,
      "loss": 0.0109,
      "step": 13480
    },
    {
      "epoch": 2.6617995264404106,
      "grad_norm": 0.30145344138145447,
      "learning_rate": 1.1336940741718359e-05,
      "loss": 0.0144,
      "step": 13490
    },
    {
      "epoch": 2.663772691397001,
      "grad_norm": 0.2687646448612213,
      "learning_rate": 1.1270951563943513e-05,
      "loss": 0.0138,
      "step": 13500
    },
    {
      "epoch": 2.665745856353591,
      "grad_norm": 0.2793508768081665,
      "learning_rate": 1.1204962386168668e-05,
      "loss": 0.0159,
      "step": 13510
    },
    {
      "epoch": 2.6677190213101816,
      "grad_norm": 0.1481231302022934,
      "learning_rate": 1.1138973208393824e-05,
      "loss": 0.0181,
      "step": 13520
    },
    {
      "epoch": 2.6696921862667717,
      "grad_norm": 0.023268157616257668,
      "learning_rate": 1.1072984030618979e-05,
      "loss": 0.0173,
      "step": 13530
    },
    {
      "epoch": 2.6716653512233624,
      "grad_norm": 0.20792435109615326,
      "learning_rate": 1.1006994852844134e-05,
      "loss": 0.0161,
      "step": 13540
    },
    {
      "epoch": 2.6736385161799525,
      "grad_norm": 0.2049769014120102,
      "learning_rate": 1.094100567506929e-05,
      "loss": 0.0146,
      "step": 13550
    },
    {
      "epoch": 2.675611681136543,
      "grad_norm": 0.1485389918088913,
      "learning_rate": 1.0875016497294445e-05,
      "loss": 0.012,
      "step": 13560
    },
    {
      "epoch": 2.6775848460931333,
      "grad_norm": 0.05914135277271271,
      "learning_rate": 1.08090273195196e-05,
      "loss": 0.0115,
      "step": 13570
    },
    {
      "epoch": 2.679558011049724,
      "grad_norm": 0.28223010897636414,
      "learning_rate": 1.0743038141744754e-05,
      "loss": 0.0112,
      "step": 13580
    },
    {
      "epoch": 2.681531176006314,
      "grad_norm": 0.22310878336429596,
      "learning_rate": 1.067704896396991e-05,
      "loss": 0.014,
      "step": 13590
    },
    {
      "epoch": 2.6835043409629042,
      "grad_norm": 0.0642433762550354,
      "learning_rate": 1.0611059786195064e-05,
      "loss": 0.0128,
      "step": 13600
    },
    {
      "epoch": 2.685477505919495,
      "grad_norm": 0.2693770229816437,
      "learning_rate": 1.054507060842022e-05,
      "loss": 0.0178,
      "step": 13610
    },
    {
      "epoch": 2.6874506708760855,
      "grad_norm": 0.2610405385494232,
      "learning_rate": 1.0479081430645375e-05,
      "loss": 0.0152,
      "step": 13620
    },
    {
      "epoch": 2.6894238358326756,
      "grad_norm": 0.13671740889549255,
      "learning_rate": 1.041309225287053e-05,
      "loss": 0.0135,
      "step": 13630
    },
    {
      "epoch": 2.691397000789266,
      "grad_norm": 0.12533332407474518,
      "learning_rate": 1.0347103075095684e-05,
      "loss": 0.0145,
      "step": 13640
    },
    {
      "epoch": 2.6933701657458564,
      "grad_norm": 0.11876009404659271,
      "learning_rate": 1.028111389732084e-05,
      "loss": 0.0143,
      "step": 13650
    },
    {
      "epoch": 2.6953433307024466,
      "grad_norm": 0.21502098441123962,
      "learning_rate": 1.0215124719545995e-05,
      "loss": 0.0166,
      "step": 13660
    },
    {
      "epoch": 2.697316495659037,
      "grad_norm": 0.1427627056837082,
      "learning_rate": 1.014913554177115e-05,
      "loss": 0.012,
      "step": 13670
    },
    {
      "epoch": 2.6992896606156274,
      "grad_norm": 0.2606082856655121,
      "learning_rate": 1.0083146363996306e-05,
      "loss": 0.015,
      "step": 13680
    },
    {
      "epoch": 2.701262825572218,
      "grad_norm": 0.19804596900939941,
      "learning_rate": 1.001715718622146e-05,
      "loss": 0.0123,
      "step": 13690
    },
    {
      "epoch": 2.703235990528808,
      "grad_norm": 0.08183110505342484,
      "learning_rate": 9.951168008446616e-06,
      "loss": 0.0135,
      "step": 13700
    },
    {
      "epoch": 2.7052091554853988,
      "grad_norm": 0.2591274380683899,
      "learning_rate": 9.88517883067177e-06,
      "loss": 0.0144,
      "step": 13710
    },
    {
      "epoch": 2.707182320441989,
      "grad_norm": 0.26346856355667114,
      "learning_rate": 9.819189652896925e-06,
      "loss": 0.0136,
      "step": 13720
    },
    {
      "epoch": 2.709155485398579,
      "grad_norm": 0.12612400949001312,
      "learning_rate": 9.75320047512208e-06,
      "loss": 0.0124,
      "step": 13730
    },
    {
      "epoch": 2.7111286503551697,
      "grad_norm": 0.16841620206832886,
      "learning_rate": 9.687211297347236e-06,
      "loss": 0.0114,
      "step": 13740
    },
    {
      "epoch": 2.7131018153117603,
      "grad_norm": 0.22613798081874847,
      "learning_rate": 9.62122211957239e-06,
      "loss": 0.013,
      "step": 13750
    },
    {
      "epoch": 2.7150749802683505,
      "grad_norm": 0.11304549127817154,
      "learning_rate": 9.555232941797545e-06,
      "loss": 0.0116,
      "step": 13760
    },
    {
      "epoch": 2.7170481452249406,
      "grad_norm": 0.16369353234767914,
      "learning_rate": 9.489243764022702e-06,
      "loss": 0.015,
      "step": 13770
    },
    {
      "epoch": 2.7190213101815313,
      "grad_norm": 0.33475548028945923,
      "learning_rate": 9.423254586247855e-06,
      "loss": 0.0151,
      "step": 13780
    },
    {
      "epoch": 2.7209944751381214,
      "grad_norm": 0.45987629890441895,
      "learning_rate": 9.357265408473011e-06,
      "loss": 0.0185,
      "step": 13790
    },
    {
      "epoch": 2.722967640094712,
      "grad_norm": 0.10954134911298752,
      "learning_rate": 9.291276230698166e-06,
      "loss": 0.0148,
      "step": 13800
    },
    {
      "epoch": 2.724940805051302,
      "grad_norm": 0.15479999780654907,
      "learning_rate": 9.22528705292332e-06,
      "loss": 0.0123,
      "step": 13810
    },
    {
      "epoch": 2.726913970007893,
      "grad_norm": 0.09977557510137558,
      "learning_rate": 9.159297875148475e-06,
      "loss": 0.0132,
      "step": 13820
    },
    {
      "epoch": 2.728887134964483,
      "grad_norm": 0.2997930645942688,
      "learning_rate": 9.093308697373632e-06,
      "loss": 0.0189,
      "step": 13830
    },
    {
      "epoch": 2.7308602999210736,
      "grad_norm": 0.16691330075263977,
      "learning_rate": 9.027319519598786e-06,
      "loss": 0.0185,
      "step": 13840
    },
    {
      "epoch": 2.7328334648776638,
      "grad_norm": 0.13537415862083435,
      "learning_rate": 8.961330341823941e-06,
      "loss": 0.0104,
      "step": 13850
    },
    {
      "epoch": 2.734806629834254,
      "grad_norm": 0.14806921780109406,
      "learning_rate": 8.895341164049097e-06,
      "loss": 0.0133,
      "step": 13860
    },
    {
      "epoch": 2.7367797947908445,
      "grad_norm": 0.25659647583961487,
      "learning_rate": 8.82935198627425e-06,
      "loss": 0.014,
      "step": 13870
    },
    {
      "epoch": 2.738752959747435,
      "grad_norm": 0.06471337378025055,
      "learning_rate": 8.763362808499407e-06,
      "loss": 0.0139,
      "step": 13880
    },
    {
      "epoch": 2.7407261247040253,
      "grad_norm": 0.18268834054470062,
      "learning_rate": 8.697373630724562e-06,
      "loss": 0.0119,
      "step": 13890
    },
    {
      "epoch": 2.7426992896606155,
      "grad_norm": 0.21357277035713196,
      "learning_rate": 8.631384452949718e-06,
      "loss": 0.0132,
      "step": 13900
    },
    {
      "epoch": 2.744672454617206,
      "grad_norm": 0.0991736575961113,
      "learning_rate": 8.565395275174871e-06,
      "loss": 0.0154,
      "step": 13910
    },
    {
      "epoch": 2.7466456195737963,
      "grad_norm": 0.22183260321617126,
      "learning_rate": 8.499406097400027e-06,
      "loss": 0.0191,
      "step": 13920
    },
    {
      "epoch": 2.748618784530387,
      "grad_norm": 0.31813129782676697,
      "learning_rate": 8.433416919625182e-06,
      "loss": 0.014,
      "step": 13930
    },
    {
      "epoch": 2.750591949486977,
      "grad_norm": 0.03070148080587387,
      "learning_rate": 8.367427741850337e-06,
      "loss": 0.0087,
      "step": 13940
    },
    {
      "epoch": 2.752565114443567,
      "grad_norm": 0.18668939173221588,
      "learning_rate": 8.301438564075491e-06,
      "loss": 0.0119,
      "step": 13950
    },
    {
      "epoch": 2.754538279400158,
      "grad_norm": 0.28163713216781616,
      "learning_rate": 8.235449386300648e-06,
      "loss": 0.0201,
      "step": 13960
    },
    {
      "epoch": 2.7565114443567484,
      "grad_norm": 0.17380179464817047,
      "learning_rate": 8.169460208525802e-06,
      "loss": 0.0148,
      "step": 13970
    },
    {
      "epoch": 2.7584846093133386,
      "grad_norm": 0.08370412141084671,
      "learning_rate": 8.103471030750957e-06,
      "loss": 0.0145,
      "step": 13980
    },
    {
      "epoch": 2.7604577742699288,
      "grad_norm": 0.234065979719162,
      "learning_rate": 8.037481852976114e-06,
      "loss": 0.0125,
      "step": 13990
    },
    {
      "epoch": 2.7624309392265194,
      "grad_norm": 0.1339370459318161,
      "learning_rate": 7.971492675201267e-06,
      "loss": 0.0193,
      "step": 14000
    },
    {
      "epoch": 2.7644041041831096,
      "grad_norm": 0.2844046652317047,
      "learning_rate": 7.905503497426423e-06,
      "loss": 0.0171,
      "step": 14010
    },
    {
      "epoch": 2.7663772691397,
      "grad_norm": 0.13324569165706635,
      "learning_rate": 7.839514319651578e-06,
      "loss": 0.0124,
      "step": 14020
    },
    {
      "epoch": 2.7683504340962903,
      "grad_norm": 0.18231989443302155,
      "learning_rate": 7.773525141876732e-06,
      "loss": 0.0166,
      "step": 14030
    },
    {
      "epoch": 2.770323599052881,
      "grad_norm": 0.21070025861263275,
      "learning_rate": 7.707535964101887e-06,
      "loss": 0.0151,
      "step": 14040
    },
    {
      "epoch": 2.772296764009471,
      "grad_norm": 0.33848240971565247,
      "learning_rate": 7.641546786327043e-06,
      "loss": 0.022,
      "step": 14050
    },
    {
      "epoch": 2.7742699289660617,
      "grad_norm": 0.18982887268066406,
      "learning_rate": 7.575557608552197e-06,
      "loss": 0.0115,
      "step": 14060
    },
    {
      "epoch": 2.776243093922652,
      "grad_norm": 0.22345341742038727,
      "learning_rate": 7.509568430777353e-06,
      "loss": 0.0201,
      "step": 14070
    },
    {
      "epoch": 2.778216258879242,
      "grad_norm": 0.12195982784032822,
      "learning_rate": 7.443579253002508e-06,
      "loss": 0.0148,
      "step": 14080
    },
    {
      "epoch": 2.7801894238358327,
      "grad_norm": 0.10622816532850266,
      "learning_rate": 7.377590075227662e-06,
      "loss": 0.0132,
      "step": 14090
    },
    {
      "epoch": 2.7821625887924233,
      "grad_norm": 0.2685045897960663,
      "learning_rate": 7.311600897452818e-06,
      "loss": 0.0136,
      "step": 14100
    },
    {
      "epoch": 2.7841357537490135,
      "grad_norm": 0.11256922036409378,
      "learning_rate": 7.245611719677973e-06,
      "loss": 0.0174,
      "step": 14110
    },
    {
      "epoch": 2.7861089187056036,
      "grad_norm": 0.1288548707962036,
      "learning_rate": 7.179622541903128e-06,
      "loss": 0.017,
      "step": 14120
    },
    {
      "epoch": 2.7880820836621942,
      "grad_norm": 0.3179453909397125,
      "learning_rate": 7.1136333641282834e-06,
      "loss": 0.0193,
      "step": 14130
    },
    {
      "epoch": 2.7900552486187844,
      "grad_norm": 0.3111022114753723,
      "learning_rate": 7.047644186353439e-06,
      "loss": 0.0131,
      "step": 14140
    },
    {
      "epoch": 2.792028413575375,
      "grad_norm": 0.07811938971281052,
      "learning_rate": 6.981655008578593e-06,
      "loss": 0.0142,
      "step": 14150
    },
    {
      "epoch": 2.794001578531965,
      "grad_norm": 0.20720623433589935,
      "learning_rate": 6.915665830803748e-06,
      "loss": 0.0135,
      "step": 14160
    },
    {
      "epoch": 2.795974743488556,
      "grad_norm": 0.19287055730819702,
      "learning_rate": 6.849676653028904e-06,
      "loss": 0.0143,
      "step": 14170
    },
    {
      "epoch": 2.797947908445146,
      "grad_norm": 0.16400209069252014,
      "learning_rate": 6.783687475254058e-06,
      "loss": 0.0173,
      "step": 14180
    },
    {
      "epoch": 2.7999210734017366,
      "grad_norm": 0.3002208173274994,
      "learning_rate": 6.717698297479213e-06,
      "loss": 0.0195,
      "step": 14190
    },
    {
      "epoch": 2.8018942383583267,
      "grad_norm": 0.09014256298542023,
      "learning_rate": 6.651709119704369e-06,
      "loss": 0.0111,
      "step": 14200
    },
    {
      "epoch": 2.803867403314917,
      "grad_norm": 0.18702973425388336,
      "learning_rate": 6.5857199419295235e-06,
      "loss": 0.0228,
      "step": 14210
    },
    {
      "epoch": 2.8058405682715075,
      "grad_norm": 0.17884549498558044,
      "learning_rate": 6.519730764154679e-06,
      "loss": 0.0154,
      "step": 14220
    },
    {
      "epoch": 2.807813733228098,
      "grad_norm": 0.15646474063396454,
      "learning_rate": 6.4537415863798346e-06,
      "loss": 0.0119,
      "step": 14230
    },
    {
      "epoch": 2.8097868981846883,
      "grad_norm": 0.13102948665618896,
      "learning_rate": 6.38775240860499e-06,
      "loss": 0.0131,
      "step": 14240
    },
    {
      "epoch": 2.8117600631412785,
      "grad_norm": 0.14287658035755157,
      "learning_rate": 6.321763230830144e-06,
      "loss": 0.0116,
      "step": 14250
    },
    {
      "epoch": 2.813733228097869,
      "grad_norm": 0.10068673640489578,
      "learning_rate": 6.2557740530552995e-06,
      "loss": 0.0136,
      "step": 14260
    },
    {
      "epoch": 2.8157063930544592,
      "grad_norm": 0.1365262269973755,
      "learning_rate": 6.189784875280454e-06,
      "loss": 0.0129,
      "step": 14270
    },
    {
      "epoch": 2.81767955801105,
      "grad_norm": 0.11082394421100616,
      "learning_rate": 6.123795697505609e-06,
      "loss": 0.0169,
      "step": 14280
    },
    {
      "epoch": 2.81965272296764,
      "grad_norm": 0.09722777456045151,
      "learning_rate": 6.057806519730764e-06,
      "loss": 0.0161,
      "step": 14290
    },
    {
      "epoch": 2.82162588792423,
      "grad_norm": 0.15831919014453888,
      "learning_rate": 5.991817341955919e-06,
      "loss": 0.0092,
      "step": 14300
    },
    {
      "epoch": 2.823599052880821,
      "grad_norm": 0.06172947585582733,
      "learning_rate": 5.925828164181075e-06,
      "loss": 0.0101,
      "step": 14310
    },
    {
      "epoch": 2.8255722178374114,
      "grad_norm": 0.139278843998909,
      "learning_rate": 5.859838986406229e-06,
      "loss": 0.016,
      "step": 14320
    },
    {
      "epoch": 2.8275453827940016,
      "grad_norm": 0.22554121911525726,
      "learning_rate": 5.793849808631385e-06,
      "loss": 0.0209,
      "step": 14330
    },
    {
      "epoch": 2.8295185477505918,
      "grad_norm": 0.2484096735715866,
      "learning_rate": 5.72786063085654e-06,
      "loss": 0.0131,
      "step": 14340
    },
    {
      "epoch": 2.8314917127071824,
      "grad_norm": 0.1159546971321106,
      "learning_rate": 5.661871453081695e-06,
      "loss": 0.0131,
      "step": 14350
    },
    {
      "epoch": 2.8334648776637725,
      "grad_norm": 0.4856140911579132,
      "learning_rate": 5.59588227530685e-06,
      "loss": 0.0181,
      "step": 14360
    },
    {
      "epoch": 2.835438042620363,
      "grad_norm": 0.19024819135665894,
      "learning_rate": 5.529893097532005e-06,
      "loss": 0.0171,
      "step": 14370
    },
    {
      "epoch": 2.8374112075769533,
      "grad_norm": 0.13641628623008728,
      "learning_rate": 5.46390391975716e-06,
      "loss": 0.0142,
      "step": 14380
    },
    {
      "epoch": 2.839384372533544,
      "grad_norm": 0.21215158700942993,
      "learning_rate": 5.397914741982315e-06,
      "loss": 0.0119,
      "step": 14390
    },
    {
      "epoch": 2.841357537490134,
      "grad_norm": 0.04571964219212532,
      "learning_rate": 5.33192556420747e-06,
      "loss": 0.013,
      "step": 14400
    },
    {
      "epoch": 2.8433307024467247,
      "grad_norm": 0.12653514742851257,
      "learning_rate": 5.265936386432625e-06,
      "loss": 0.0146,
      "step": 14410
    },
    {
      "epoch": 2.845303867403315,
      "grad_norm": 0.16948164999485016,
      "learning_rate": 5.1999472086577805e-06,
      "loss": 0.0152,
      "step": 14420
    },
    {
      "epoch": 2.847277032359905,
      "grad_norm": 0.22988007962703705,
      "learning_rate": 5.133958030882936e-06,
      "loss": 0.0136,
      "step": 14430
    },
    {
      "epoch": 2.8492501973164956,
      "grad_norm": 0.32976508140563965,
      "learning_rate": 5.067968853108091e-06,
      "loss": 0.02,
      "step": 14440
    },
    {
      "epoch": 2.8512233622730863,
      "grad_norm": 0.2692576050758362,
      "learning_rate": 5.001979675333245e-06,
      "loss": 0.0094,
      "step": 14450
    },
    {
      "epoch": 2.8531965272296764,
      "grad_norm": 0.32121795415878296,
      "learning_rate": 4.935990497558401e-06,
      "loss": 0.015,
      "step": 14460
    },
    {
      "epoch": 2.8551696921862666,
      "grad_norm": 0.5531915426254272,
      "learning_rate": 4.870001319783556e-06,
      "loss": 0.0113,
      "step": 14470
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.16009630262851715,
      "learning_rate": 4.804012142008711e-06,
      "loss": 0.0151,
      "step": 14480
    },
    {
      "epoch": 2.8591160220994474,
      "grad_norm": 0.1281985491514206,
      "learning_rate": 4.738022964233866e-06,
      "loss": 0.0138,
      "step": 14490
    },
    {
      "epoch": 2.861089187056038,
      "grad_norm": 0.15058527886867523,
      "learning_rate": 4.6720337864590206e-06,
      "loss": 0.0123,
      "step": 14500
    },
    {
      "epoch": 2.863062352012628,
      "grad_norm": 0.1749589592218399,
      "learning_rate": 4.606044608684176e-06,
      "loss": 0.0131,
      "step": 14510
    },
    {
      "epoch": 2.8650355169692188,
      "grad_norm": 0.272320955991745,
      "learning_rate": 4.540055430909331e-06,
      "loss": 0.016,
      "step": 14520
    },
    {
      "epoch": 2.867008681925809,
      "grad_norm": 0.21294894814491272,
      "learning_rate": 4.474066253134486e-06,
      "loss": 0.0136,
      "step": 14530
    },
    {
      "epoch": 2.8689818468823995,
      "grad_norm": 0.14320595562458038,
      "learning_rate": 4.408077075359642e-06,
      "loss": 0.0154,
      "step": 14540
    },
    {
      "epoch": 2.8709550118389897,
      "grad_norm": 0.15300911664962769,
      "learning_rate": 4.3420878975847966e-06,
      "loss": 0.0156,
      "step": 14550
    },
    {
      "epoch": 2.87292817679558,
      "grad_norm": 0.13415026664733887,
      "learning_rate": 4.276098719809951e-06,
      "loss": 0.0135,
      "step": 14560
    },
    {
      "epoch": 2.8749013417521705,
      "grad_norm": 0.130088210105896,
      "learning_rate": 4.210109542035107e-06,
      "loss": 0.0148,
      "step": 14570
    },
    {
      "epoch": 2.876874506708761,
      "grad_norm": 0.1932978332042694,
      "learning_rate": 4.1441203642602615e-06,
      "loss": 0.0113,
      "step": 14580
    },
    {
      "epoch": 2.8788476716653513,
      "grad_norm": 0.1743091344833374,
      "learning_rate": 4.078131186485416e-06,
      "loss": 0.0187,
      "step": 14590
    },
    {
      "epoch": 2.8808208366219414,
      "grad_norm": 0.20798859000205994,
      "learning_rate": 4.012142008710572e-06,
      "loss": 0.0132,
      "step": 14600
    },
    {
      "epoch": 2.882794001578532,
      "grad_norm": 0.14415673911571503,
      "learning_rate": 3.946152830935726e-06,
      "loss": 0.0132,
      "step": 14610
    },
    {
      "epoch": 2.884767166535122,
      "grad_norm": 0.11071168631315231,
      "learning_rate": 3.880163653160881e-06,
      "loss": 0.0139,
      "step": 14620
    },
    {
      "epoch": 2.886740331491713,
      "grad_norm": 0.12912684679031372,
      "learning_rate": 3.814174475386037e-06,
      "loss": 0.0202,
      "step": 14630
    },
    {
      "epoch": 2.888713496448303,
      "grad_norm": 0.16724665462970734,
      "learning_rate": 3.7481852976111918e-06,
      "loss": 0.0148,
      "step": 14640
    },
    {
      "epoch": 2.8906866614048936,
      "grad_norm": 0.08593952655792236,
      "learning_rate": 3.6821961198363473e-06,
      "loss": 0.0144,
      "step": 14650
    },
    {
      "epoch": 2.8926598263614838,
      "grad_norm": 0.23489218950271606,
      "learning_rate": 3.616206942061502e-06,
      "loss": 0.0138,
      "step": 14660
    },
    {
      "epoch": 2.8946329913180744,
      "grad_norm": 0.16719800233840942,
      "learning_rate": 3.550217764286657e-06,
      "loss": 0.0154,
      "step": 14670
    },
    {
      "epoch": 2.8966061562746646,
      "grad_norm": 0.1304095983505249,
      "learning_rate": 3.4842285865118126e-06,
      "loss": 0.0105,
      "step": 14680
    },
    {
      "epoch": 2.8985793212312547,
      "grad_norm": 0.16289284825325012,
      "learning_rate": 3.4182394087369673e-06,
      "loss": 0.018,
      "step": 14690
    },
    {
      "epoch": 2.9005524861878453,
      "grad_norm": 0.1651698797941208,
      "learning_rate": 3.3588491487396066e-06,
      "loss": 0.0173,
      "step": 14700
    },
    {
      "epoch": 2.902525651144436,
      "grad_norm": 0.10114960372447968,
      "learning_rate": 3.2928599709647617e-06,
      "loss": 0.0154,
      "step": 14710
    },
    {
      "epoch": 2.904498816101026,
      "grad_norm": 0.1546243578195572,
      "learning_rate": 3.2268707931899173e-06,
      "loss": 0.0162,
      "step": 14720
    },
    {
      "epoch": 2.9064719810576163,
      "grad_norm": 0.367824524641037,
      "learning_rate": 3.160881615415072e-06,
      "loss": 0.0177,
      "step": 14730
    },
    {
      "epoch": 2.908445146014207,
      "grad_norm": 0.0740402489900589,
      "learning_rate": 3.094892437640227e-06,
      "loss": 0.0142,
      "step": 14740
    },
    {
      "epoch": 2.910418310970797,
      "grad_norm": 0.06667552888393402,
      "learning_rate": 3.028903259865382e-06,
      "loss": 0.0153,
      "step": 14750
    },
    {
      "epoch": 2.9123914759273877,
      "grad_norm": 0.11232028901576996,
      "learning_rate": 2.9629140820905373e-06,
      "loss": 0.0073,
      "step": 14760
    },
    {
      "epoch": 2.914364640883978,
      "grad_norm": 0.176049143075943,
      "learning_rate": 2.8969249043156924e-06,
      "loss": 0.0133,
      "step": 14770
    },
    {
      "epoch": 2.916337805840568,
      "grad_norm": 0.11864084750413895,
      "learning_rate": 2.8309357265408476e-06,
      "loss": 0.0205,
      "step": 14780
    },
    {
      "epoch": 2.9183109707971586,
      "grad_norm": 0.17357183992862701,
      "learning_rate": 2.7649465487660027e-06,
      "loss": 0.0111,
      "step": 14790
    },
    {
      "epoch": 2.9202841357537492,
      "grad_norm": 0.13171596825122833,
      "learning_rate": 2.6989573709911574e-06,
      "loss": 0.015,
      "step": 14800
    },
    {
      "epoch": 2.9222573007103394,
      "grad_norm": 0.08150987327098846,
      "learning_rate": 2.6329681932163125e-06,
      "loss": 0.0143,
      "step": 14810
    },
    {
      "epoch": 2.9242304656669296,
      "grad_norm": 0.15505409240722656,
      "learning_rate": 2.566979015441468e-06,
      "loss": 0.0141,
      "step": 14820
    },
    {
      "epoch": 2.92620363062352,
      "grad_norm": 0.10117209702730179,
      "learning_rate": 2.5009898376666227e-06,
      "loss": 0.0133,
      "step": 14830
    },
    {
      "epoch": 2.9281767955801103,
      "grad_norm": 0.1991410255432129,
      "learning_rate": 2.435000659891778e-06,
      "loss": 0.0147,
      "step": 14840
    },
    {
      "epoch": 2.930149960536701,
      "grad_norm": 0.6295822262763977,
      "learning_rate": 2.369011482116933e-06,
      "loss": 0.0146,
      "step": 14850
    },
    {
      "epoch": 2.932123125493291,
      "grad_norm": 0.29810866713523865,
      "learning_rate": 2.303022304342088e-06,
      "loss": 0.019,
      "step": 14860
    },
    {
      "epoch": 2.9340962904498817,
      "grad_norm": 0.3739951550960541,
      "learning_rate": 2.237033126567243e-06,
      "loss": 0.0189,
      "step": 14870
    },
    {
      "epoch": 2.936069455406472,
      "grad_norm": 0.10080478340387344,
      "learning_rate": 2.1710439487923983e-06,
      "loss": 0.017,
      "step": 14880
    },
    {
      "epoch": 2.9380426203630625,
      "grad_norm": 0.1132168099284172,
      "learning_rate": 2.1050547710175534e-06,
      "loss": 0.0108,
      "step": 14890
    },
    {
      "epoch": 2.9400157853196527,
      "grad_norm": 0.12402667850255966,
      "learning_rate": 2.039065593242708e-06,
      "loss": 0.0161,
      "step": 14900
    },
    {
      "epoch": 2.941988950276243,
      "grad_norm": 0.2850383222103119,
      "learning_rate": 1.973076415467863e-06,
      "loss": 0.0144,
      "step": 14910
    },
    {
      "epoch": 2.9439621152328335,
      "grad_norm": 0.15372006595134735,
      "learning_rate": 1.9070872376930185e-06,
      "loss": 0.0125,
      "step": 14920
    },
    {
      "epoch": 2.945935280189424,
      "grad_norm": 0.09457927942276001,
      "learning_rate": 1.8410980599181736e-06,
      "loss": 0.0132,
      "step": 14930
    },
    {
      "epoch": 2.9479084451460142,
      "grad_norm": 0.14537517726421356,
      "learning_rate": 1.7751088821433285e-06,
      "loss": 0.014,
      "step": 14940
    },
    {
      "epoch": 2.9498816101026044,
      "grad_norm": 0.24414952099323273,
      "learning_rate": 1.7091197043684837e-06,
      "loss": 0.0148,
      "step": 14950
    },
    {
      "epoch": 2.951854775059195,
      "grad_norm": 0.1924954652786255,
      "learning_rate": 1.6431305265936388e-06,
      "loss": 0.0144,
      "step": 14960
    },
    {
      "epoch": 2.953827940015785,
      "grad_norm": 0.23776142299175262,
      "learning_rate": 1.5771413488187937e-06,
      "loss": 0.0146,
      "step": 14970
    },
    {
      "epoch": 2.955801104972376,
      "grad_norm": 0.15834742784500122,
      "learning_rate": 1.5111521710439488e-06,
      "loss": 0.0124,
      "step": 14980
    },
    {
      "epoch": 2.957774269928966,
      "grad_norm": 0.028467679396271706,
      "learning_rate": 1.445162993269104e-06,
      "loss": 0.0121,
      "step": 14990
    },
    {
      "epoch": 2.9597474348855566,
      "grad_norm": 0.2488415241241455,
      "learning_rate": 1.379173815494259e-06,
      "loss": 0.0202,
      "step": 15000
    },
    {
      "epoch": 2.9597474348855566,
      "eval_loss": 0.015242619439959526,
      "eval_runtime": 74.977,
      "eval_samples_per_second": 15.031,
      "eval_steps_per_second": 7.522,
      "step": 15000
    }
  ],
  "logging_steps": 10,
  "max_steps": 15204,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 2500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.5998715256832e+17,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
